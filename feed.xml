<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://fanpu.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://fanpu.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2024-11-21T03:32:04+00:00</updated><id>https://fanpu.io/feed.xml</id><title type="html">blank</title><subtitle>Homepage
</subtitle><entry><title type="html">Notes on ‘The Llama 3 Herd of Models’</title><link href="https://fanpu.io/blog/2024/llama-3.1-technical-report-notes/" rel="alternate" type="text/html" title="Notes on ‘The Llama 3 Herd of Models’" /><published>2024-08-07T00:00:00+00:00</published><updated>2024-08-07T00:00:00+00:00</updated><id>https://fanpu.io/blog/2024/llama-3.1-technical-report-notes</id><content type="html" xml:base="https://fanpu.io/blog/2024/llama-3.1-technical-report-notes/"><![CDATA[<h1 id="reading-recommendations">Reading Recommendations</h1>

<p>This is a long paper, but it’s full of gems. Here’s a reading recommendation guide:</p>

<ul>
  <li>Strapped on time: sections 1 (Introduction), 2 (General Overview). It’s just a couple of pages and provides a good overview.</li>
  <li>Love ML systems: 3.3 (Infrastructure, Scaling, Efficiency). Talks about on hardware, architecture, training challenges, parallelism optimizations</li>
  <li>How to train a coding model: 4.3.1 (Code). Covers how they targeted specific coding abilities and generated synthetic datasets to bootstrap the model</li>
  <li>Training model to perform tool use: 4.3.5 (Tool Use)</li>
  <li>Post-training framework: 4.1 (Modeling). Covers their pipeline for reward modeling, supervised finetuning, and direct preference optimization</li>
  <li>Extending to 128K context: 3.4.2 (Long Context Pre-Training) and 4.3.4 (Long Context)</li>
  <li>Why a 405B model: 3.2.1 (Scaling Laws)</li>
  <li>Optimizations for inference: 6 (Inference) on both pipeline parallelism and FP8 quantization, this is a short section</li>
  <li>Results and benchmarks: 5.1, 5.2 (Pre and Post-trained Language Model), 5.3 (Human Evaluations)</li>
  <li>Red teaming: 5.4.6 (Red Teaming)</li>
  <li>Multi-modality: 7 (Vision Experiments), 8 (Speech Experiments), 9.2 (Multimodality)</li>
</ul>

<h1 id="introduction">Introduction</h1>

<p>Introduces new set of models (8/70/405 B) that supports:</p>

<ul>
  <li>multilinguality</li>
  <li>coding</li>
  <li>reasoning</li>
  <li>tool usage</li>
</ul>

<p>Largest model:</p>

<ul>
  <li>405B parameters</li>
  <li>128k context window</li>
  <li>Has instruction fine-tuned version</li>
  <li>Pre-trained on 3.8 x \(10^{25}\) FLOPS</li>
</ul>

<p>Also introduced Llama Guard 3 model for input/output safety.</p>

<h1 id="pre-training">Pre-training</h1>

<h2 id="pre-training-data">Pre-Training Data</h2>

<h3 id="data-cleaning">Data Cleaning</h3>

<p>Knowledge cutoff end of 2023. To ensure high-quality tokens, performed:
de-duplication, data cleaning, removed domains known to contain large amounts of
PII, adult content.</p>

<p>Data cleaning:</p>

<ul>
  <li>extracts HTML content from web documents</li>
  <li>done carefully
for pages with math &amp; code content to preserve structure</li>
  <li>Markdown markers also removed</li>
</ul>

<p>De-duplication:</p>

<ul>
  <li>on the URL, duplication across documents, line-level de-duplication (common in boilerplate)</li>
</ul>

<p>Used heuristics to filter other low-quality documents: logs/error messages,
other adult websites, websites with excessive numbers of outlier tokens</p>

<p>Built a model-based classifier to sub-select high-quality tokens.</p>

<p>Built domain-specific pipelines to extract code &amp; math-relevant web pages,
including pages containing math deduction, pages containing code interleaved
with natural language.</p>

<p>Used similar approaches as the above for other languages.</p>

<h3 id="data-mix">Data Mix</h3>

<p>This ensures they have the right proportion of different data sources.
They ended up with:</p>

<ul>
  <li>50% general knowledge</li>
  <li>25% math &amp; reasoning</li>
  <li>17% code</li>
  <li>8% multilingual</li>
</ul>

<p>Knowledge classification: categorizes data to determine the data mix.
Used this to downsample data over-represented on the web like arts &amp; entertainment.</p>

<p>Scaling laws for data mix: trained several small models on data mix &amp; use that to predict the performance of large models on mix</p>

<p>Overview</p>

<ul>
  <li>15.6T multilingual tokens (compare 1.8T for Llama 2)</li>
  <li>Use 8K token context window initially, followed by continued pre-training
stage which increases supported context window to 128K tokens</li>
</ul>

<h3 id="multi-modality">Multi-modality</h3>

<h4 id="encoders">Encoders</h4>

<p>Separate encoders trained for images and speech.</p>

<p>Image encoder:</p>

<ul>
  <li>Trained on image-text pairs</li>
</ul>

<p>Speech encoder:</p>

<ul>
  <li>Self-supervised learning via masking</li>
  <li>Masked part reconstructed by discrete-token representation</li>
</ul>

<h4 id="adapters">Adapters</h4>

<p>TBD</p>

<h3 id="annealing-data">Annealing Data</h3>

<p>Performed annealing on small amounts of high-quality code and mathematical data.
Annealing here means increasingly upsampling these high-quality data over time.</p>

<p>Found improvements for Llama 3 8B on GSM8k and MATH, but not 405B.</p>

<h2 id="model-architecture">Model Architecture</h2>

<p>Architecture</p>

<ul>
  <li>Uses dense Transformer architecture instead of MoE for training stability</li>
  <li>Similar to Llama and Llama 2, performance gains mostly
from improvements in data quality &amp; diversity, and training scale</li>
  <li>Grouped query attention with 8 KV heads: improves inference speed, reduce size of KV cache during decoding</li>
  <li>Attention mask to prevent self-attention between different
documents (why not just put them in different sequences? maybe to take advantage of parallelism?). Limited impact during pre-training,
helpful for continued pre-training on long sequences</li>
  <li>RoPE for positional embeddings (500,000 base frequency hyperparameter instead of 10k in original paper, this is helpful for longer context), SwiGLU activation</li>
  <li>128K token vocabulary, based off <code class="language-plaintext highlighter-rouge">tiktoken</code> tokenizer and extra 28K non-English tokens. Tokenizer improves compression rate from 3.17 to 3.94 characters per token compared to Llama 2 tokenizer.</li>
  <li>Llama 3 405B: 126 layers (!!), model dimension 16,382, 128 attention heads</li>
</ul>

<h3 id="scaling-laws">Scaling Laws</h3>

<p>Scaling laws are nice for predicting loss, but not helpful
for understanding impact on downstream task performance.</p>

<p>To find relationship with downstream task performance they did:</p>

<ol>
  <li>Find correlation between compute-optimal model’s loss on downstream tasks and training FLOPs</li>
  <li>Find correlation between loss and downstream task accuracy,
using scaling law models</li>
</ol>

<p>The scaling laws suggest that given their compute
budget of \(3.8 \times 10^{25}\) FLOPs, a 402B
model with 16.55T tokens is optimal, which led to their 405B model.</p>

<p>They also found their predictions to be quite accurate
for the final downstream performance of their models.</p>

<h3 id="infrastructure-scaling-and-efficiency">Infrastructure, Scaling, and Efficiency</h3>

<p>Compute:</p>

<ul>
  <li>16K H100 GPUs, 700W TDP (thermal design power) with 80GB HBM3 (high bandwidth memory that allows for faster data transfer between CPU and GPU)</li>
  <li>Trained on Meta’s Grand Teton AI server platform, scheduling using MAST (Meta’s global-scale training scheduler)</li>
  <li>Each server: 8 GPUs connected by NVLink, 2 CPUs</li>
</ul>

<p>Storage:</p>

<ul>
  <li>Tectonic, Meta’s distributed file system</li>
  <li>240 PB storage over 7500 servers, 2TB/s sustainable throughput, 7TB/s peak throughput</li>
</ul>

<p>Network:</p>

<ul>
  <li>Llama 3 405B used RDMA over Converged Ethernet (RoCE) fabric</li>
  <li>Smaller models uses Nvidia Quantum2 Infiniband</li>
  <li>Both 400 Gbps interconnect</li>
</ul>

<h3 id="parallelism-for-model-scaling">Parallelism for Model Scaling</h3>

<p>Scaled parallelism as much as possible, so all of GPU’s model parameters,
optimizer states, gradients, and activations fit in HBM.</p>

<p>4D parallelism:</p>

<ul>
  <li>tensor parallelism</li>
  <li>pipeline parallelism</li>
  <li>context parallelism</li>
  <li>data parallelism</li>
</ul>

<p>Parallelism achieved BF16 Model FLOPs Utilization (MFU)
of 38-43%</p>

<h3 id="reliability-and-operational-challenges">Reliability and Operational Challenges</h3>

<ul>
  <li>
    <blockquote>
      <p>90% effective training time, even while supporting automated cluster maintenance (i.e Linux kernel upgrades)</p>
    </blockquote>
  </li>
  <li>At least one training interruption daily</li>
</ul>

<p>466 job interruptions</p>

<ul>
  <li>47 planned interruptions (i.e maintenance)</li>
  <li>419 unexpected: mostly GPU/host component failures,
suspected data corruption, unplanned maintenance</li>
  <li>Significant manual intervention only required 3 times, rest handled
by automation</li>
</ul>

<p>Debugging</p>

<ul>
  <li>PyTorch’s built-in NCCL flight recorder helped diagnose issues quickly at scale</li>
  <li>Mixed use of NVLink and RoCE complicated things</li>
</ul>

<p>Others</p>

<ul>
  <li>Higher mid-day temperatures impacted GPU dynamic voltage and frequency
scaling, causing diurnal 1-2% throughput variation throughout the day</li>
  <li>~10ks of GPUs with correlated increase/decrease in power consumption (i.e waiting for checkpointing) causes fluctuation
of power consumption on the order of ~10s megawatts, stretching limits of power grid</li>
</ul>

<h2 id="training-recipe">Training Recipe</h2>

<p>Initial pre-training:</p>

<ul>
  <li>AdamW optimizer</li>
  <li>Linear warm up, cosine LR schedule</li>
  <li>Start with lower batch size for training stability, increase
subsequently for efficiency</li>
  <li>Few loss spikes, no interventions needed to correct for training divergence</li>
  <li>Upsampled non-English and math data, downsampled low-quality data</li>
  <li>Added recent web data in final stages of pre-training
to advance model knowledge cut-off</li>
</ul>

<p>Long context pre-training:</p>

<ul>
  <li>To support 128K context window</li>
  <li>Don’t do long-context training earlier because of quadratic self-attention, too expensive</li>
  <li>Increased context length by successive adaptation over 6 stages from 8K to 128K, 800B training tokens</li>
</ul>

<p>Annealing:</p>

<ul>
  <li>On final 40M tokens, linearly annealed LR to 0, kept 128K context window</li>
  <li>Upsampled data source of very high quality</li>
  <li>Averaged model checkpoints during annealing to get final pre-trained model</li>
</ul>

<h1 id="post-training">Post-Training</h1>

<ul>
  <li>Several rounds of post-training, each starts with SFT followed by DPO</li>
  <li>Examples collected by human annotations or generated synthetically</li>
  <li>Custom</li>
</ul>

<h2 id="modeling">Modeling</h2>

<ul>
  <li>Uses reward model (RM) and language model (LM)</li>
  <li>RM trained by human-annotated preference data</li>
  <li>
    <p>Checkpoints aligned with DPO</p>
  </li>
  <li>Model supports tool use, which required designing multi-message chat protocol with special header and termination tokens</li>
</ul>

<h3 id="reward-modeling">Reward Modeling</h3>

<ul>
  <li>RM trained on top of pre-trained checkpoint</li>
  <li>Preference pairs of either (chosen, rejected) or (chosen, rejected, edited), where edited &gt; chosen &gt; rejected</li>
  <li>Filtered out preference data with similar responses</li>
</ul>

<h3 id="supervised-finetuning">Supervised Finetuning</h3>

<ul>
  <li>RM performs rejection sampling on human annotation prompts</li>
  <li>Fine-tune pre-trained LM on the model-generated samples that are accepted</li>
</ul>

<h3 id="direct-preference-optimization">Direct Preference Optimization</h3>

<ul>
  <li>Why not on-policy algorithms like PPO? DPO required less compute, performed better on instruction-following benchmarks</li>
  <li>Used most recent batches of preference data from best-performing
models during previous alignment rounds, ensures training data
conforms better to distribution of policy model being optimized</li>
</ul>

<p>Modified DPO:</p>

<ul>
  <li>Masked out formatting tokens (including header and termination tokens) in DPO loss, helps with stability. These tokens caused tail repetition or random termination tokens. Hypothesized due to these tokens being common in both chosen and rejected responses causes conflicting optimization objectives</li>
  <li>Added regularization with negative log-likelihood (NLL) loss</li>
</ul>

<h2 id="post-training-data">Post-training Data</h2>

<h3 id="preference-data">Preference Data</h3>

<ul>
  <li>Sample two responses from two different models for each user prompt, labelled by human annotators</li>
  <li>Annotators state strength of preference by 4 levels: significantly better, better, slightly better, marginally better</li>
  <li>Allow editing step after annotation to further improve response</li>
  <li>Only used responses significantly better or better for training</li>
</ul>

<h3 id="sft-data">SFT Data</h3>

<p>Finetuning data contains:</p>

<ul>
  <li>Prompts from human annotation collection with rejection-sampled (RS) responses</li>
  <li>Synthetic data targeting specific capabilities</li>
  <li>Small amounts of human-curated data</li>
</ul>

<p>Datasets:</p>

<ul>
  <li>General English</li>
  <li>Code</li>
  <li>Multilingual</li>
  <li>Exam-like</li>
  <li>Reasoning and tools</li>
  <li>Long context</li>
</ul>

<p>Rejection sampling:</p>

<ul>
  <li>Choose prompt from human annotation collection</li>
  <li>Sample 10-30 outputs from latest chat model policy</li>
  <li>Use RM to choose best candidate</li>
  <li>For later rounds of post-training, use system prompt to steer RS responses to conform with tone/style/formatting</li>
  <li>Uses PagedAttention to make RS efficient</li>
</ul>

<h3 id="data-processing-and-quality-control">Data Processing and Quality Control</h3>

<p>Most of training data is model-generated, requires careful cleaning and quality control</p>

<p>Data cleaning:</p>

<ul>
  <li>Rule-based data removal or modification strategies</li>
  <li>Balance proportion of such samples in dataset</li>
</ul>

<p>Data pruning:</p>

<ul>
  <li>Topic classification: Fine-tuned Llama 3 8B to a topic classifier</li>
  <li>Quality scoring: Use RM and Llama 3 checkpoint to rate content, keep examples marked as high quality by either RM or Llama. Both signals have high disagreement rates, and combining signals gives best recall on test set.</li>
  <li>Difficulty scoring: used Llama 3 70B to perform intention-tagging, where more intentions implies more complexity. Also used it to measure difficulty of dialogs</li>
  <li>Semantic deduplication: clustering using RoBERTa, sort by
quality score \(\times\) difficulty score, go through sorted examples by best and take only ones with maximum cosine similarity less than threshold</li>
</ul>

<h2 id="capabilities">Capabilities</h2>

<h3 id="code">Code</h3>

<p>Capabilities:</p>

<ul>
  <li>Code generation</li>
  <li>Documentation</li>
  <li>Debugging</li>
  <li>Review</li>
</ul>

<p>Targeted languages: Python, Java, Javascript, C/C++, Typescript, Rust, PHP, HTML/CSS, SQL, bash/shell</p>

<p>Improved capabilities via:</p>

<ul>
  <li>Training a code expert</li>
  <li>Generate synthetic data for SFT</li>
  <li>Improve formatting with system prompt steering</li>
  <li>Create quality filters to remove bad examples</li>
</ul>

<p>Expert training:</p>

<ul>
  <li>Train code expert to obtain high quality human annotations for code</li>
  <li>Approach similar to CodeLlama (scant on details, should probably check this paper)</li>
</ul>

<p>Synthetic data generation:</p>

<ul>
  <li>Faced issues in code generation: following instructions, code syntax errors, incorrect code generation, difficulty in fixing bugs</li>
  <li>Use Llama 3 and code expert to generate synthetic 2.7M dialogs for SFT</li>
</ul>

<p>During RS, used code specific system prompts to improve:</p>

<ul>
  <li>code readability</li>
  <li>documentation</li>
  <li>thoroughness</li>
  <li>specificity</li>
</ul>

<h4 id="synthetic-data-generation-execution-feedback">Synthetic data generation: execution feedback</h4>

<ul>
  <li>Distillation to smaller models helped, but not for 405B on its
own inputs</li>
  <li>Use execution feedback as source of truth, allow model to learn from own mistakes
    <ol>
      <li>Problem description generation: generate programming problem descriptions, use random code snippets as inspiration</li>
      <li>Solution generation: Prompt Llama 3 to solve problem, use CoT in comments, add programming guidelines in system prompt</li>
      <li>Correctness analysis: use static analysis (parser and linters),
and unit test generation (also by the model) and execution</li>
      <li>Error feedback and iterative self-correction: prompt model to revise solutions that fail, includes feedback from parser/linter/tester. Can modify code and unit test to accomodate new code. 20% of solutions that were incorrect could be self-corrected this way.</li>
      <li>Fine-tuning and iterative improvement: process iterated over multiple rounds, higher-quality synthetic data generated in each subsequent rounds</li>
    </ol>
  </li>
</ul>

<h4 id="synthetic-data-generation-programming-language-translation">Synthetic data generation: programming language translation</h4>

<ul>
  <li>Noted performance gap between popular vs less common programming languages, due to difference in dataset size</li>
  <li>Translate data from more common to less common languages</li>
  <li>Ensure quality via syntax parsing, compilation, execution</li>
</ul>

<h4 id="synthetic-data-generation-backtranslation">Synthetic data generation: backtranslation</h4>

<ul>
  <li>Some coding capabilities don’t benefit as much from execution feedback, i.e documentation &amp; explanation</li>
  <li>Generated 1.2M synthetic dialogs for code explanation, generation, documentation, debugging</li>
  <li>Done as follows:
    <ol>
      <li>Generate: Prompt Llama 3 to generate data corresponding to desired capability (i.e add comments to code)</li>
      <li>Backtranslate: Ask model to backtranslate synthetically generated data to original code (i.e generate code based on only comments)</li>
      <li>Filter: ask Llama 3 to determine quality of generated code with original code as reference. This self-verification step acts as a filter for good examples, only those with high scores are used for SFT</li>
    </ol>
  </li>
</ul>

<h3 id="tool-use">Tool Use</h3>

<p>Trained Llama 3 to use search engine (Brave), Python interpreter, Wolfram Alpha
API.</p>

<p>To train on tool use:</p>

<ul>
  <li>Start with training single-turn tool use, then tool use in dialog, and then multi-step tool use and data analysis</li>
  <li>All synthetically generated: first synthetic user prompts which require
calling out to tools, then the corresponding tool calls which are then executed,
and then the final answer to user prompt</li>
  <li>Multi-step tool use trained in a similar way synthetically</li>
  <li>User prompts are based on a provided file, and ask to summarize the contents of
the file, find and fix bugs, optimize a piece of code, perform data analysis or
visualization</li>
  <li>Augmented synthetic data with different system prompts to teach model to use tools
only when activated</li>
  <li>To avoid model using tools for simple queries, added dataset containing
queries of simple math/reasoning questions with tool use activated but without
using tools in response</li>
</ul>

<h3 id="factuality">Factuality</h3>

<p>To train the model to guard against hallucinations, they used a knowledge probe to find out what the model knows, and to generate training data of refusals for the things it doesn’t:</p>

<ol>
  <li>Extract a data snippet from the pre-training data.</li>
  <li>Generate a factual question about these snippets (context) by prompting Llama 3.</li>
  <li>Sample responses from Llama 3 to the question.</li>
  <li>Score the correctness of the generations using the original context as a reference and Llama 3 as a judge.</li>
  <li>Score the informativeness of the generations using Llama 3 as a judge.</li>
  <li>Generate a refusal for responses which are consistently informative and incorrect across the generations,
using Llama 3.</li>
</ol>

<p>But because pre-training data is not always factually correct, they also did this for
sensitive topics where contradictory/incorrect statements are prevalent</p>

<h3 id="steerability">Steerability</h3>

<p>Remainder to be continued…</p>

<!--
- Got human annotators to come up with different system prompts,

-->]]></content><author><name>fanpu</name></author><category term="machine-learning" /><summary type="html"><![CDATA[Notes on the new Llama 3.1 technical report. It's a long paper, but one that's well-written with lots of interesting technical details and design choices.]]></summary></entry><entry><title type="html">Playing Sound Voltex at Home: Setting Up Unnamed SDVX Clone with the Yuancon SDVX Controller</title><link href="https://fanpu.io/blog/2023/setting-up-yuancon-controller-sound-voltex/" rel="alternate" type="text/html" title="Playing Sound Voltex at Home: Setting Up Unnamed SDVX Clone with the Yuancon SDVX Controller" /><published>2023-09-02T00:00:00+00:00</published><updated>2023-09-02T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/setting-up-yuancon-controller-sound-voltex</id><content type="html" xml:base="https://fanpu.io/blog/2023/setting-up-yuancon-controller-sound-voltex/"><![CDATA[<p>Rhythm is just a $200 controller and some hopefully-not-too-complicated
open source software setup away!</p>

<p>This beginner’s guide will help to demystify the process of setting up Sound Voltex
at home using a custom SDVX controller using Unnamed SDVX Clone.</p>

<hr />

<p>My foray into rhythm games started way
back with <a href="https://lovelive-sif-global.bushimo.jp/">Love Live! School Idol Festival</a>.
While the game has sadly since shut down, other
titles I’ve played
include <a href="https://bang-dream-gbp-en.bushiroad.com/">BanG Dream!</a>
and <a href="https://projectsekai.fandom.com/wiki/Project_SEKAI_COLORFUL_STAGE!">Project SEKAI</a>.</p>

<p>When I visited Japan a few months ago in the summer, I discovered <a href="https://p.eagate.573.jp/game/sdvx/sv/p/index.html">Sound Voltex</a>, and instantly
fell in love with its unique control system and beautiful flashy graphics:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/sdvx/sdvx_and_me.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>
</figure>

<p>In Japan, you pay 100 yen (~$0.68 USD) to play two to three songs. You get to
play three songs if you don’t crash (i.e fail) any tracks, and two if you fail
on either of the first two guaranteed plays.</p>

<p>Rhythm games in general are sadly not as mainstream outside of Japan.
For instance, in Singapore I was only aware of a single arcade that had Sound Voltex cabs,
even though arcades are quite popular in general. Similarly, in NYC, there’s only a single 
small arcade called <a href="http://www.chinatownfair.biz/">Chinatown Fair</a> that has Sound Voltex.
So naturally I wanted to see if I could set it up at home to continue enjoying the game.</p>

<p>(Apparently, if you have a lot of disposable income and space in your living
room, you can also just buy an entire <a href="https://www.hadouken-arcade.com/products/sound-voltex-vivid-wave">previous-generation Sound Voltex
cabinet</a> for a
few thousand dollars)</p>

<h2 id="why-this-guide">Why This Guide</h2>
<p>I decided to write this guide since the setup process could seem somewhat daunting for
people who are interested in rhythm games but are not developers. Hopefully
now more people will also be able to play and enjoy this game.</p>

<p>The setup process is very straightforward on Windows, but has a few subtle
points on macOS and Linux that I’ll point out.</p>

<h2 id="setup-specification">Setup Specification</h2>
<p>This guide will use the following setup:</p>

<ul>
  <li>Game: <a href="https://github.com/Drewol/unnamed-sdvx-clone">unnamed-sdvx-clone</a>, commonly abbreviated USC</li>
  <li>Controller: <a href="https://yuancon.store/controller/sdvxblack">Yuancon SDVX controller</a>.</li>
</ul>

<p>While I performed the setup on macOS, the instructions are largely the same
for Linux based systems as well. In fact, if you are already 
regardless of which controller or OS you use.</p>

<h2 id="installing-unnamed-sdvx-clone">Installing Unnamed SDVX Clone</h2>

<h3 id="windows">Windows</h3>
<p>The setup process for Windows is very straightforward.
You should just download the <a href="https://drewol.me/Downloads/Game.zip">latest Windows build</a> as linked on the <a href="https://drewol.me/Downloads/Game.zip">Github page</a>, and run <code class="language-plaintext highlighter-rouge">usc-game.exe</code> to start the game.</p>

<h3 id="macos">macOS</h3>

<p>This is mostly just from the <a href="https://github.com/Drewol/unnamed-sdvx-clone#macos">official instructions</a>,
but with implicit points made explicit:</p>

<ol>
  <li>If you don’t have <a href="https://docs.brew.sh/">Homebrew</a> on your machine yet, install it by 
<a href="https://brew.sh/">following the instructions here</a>. Homebrew is a package management software.</li>
  <li>
    <p>If you don’t have <a href="https://git-scm.com/">git</a> yet, install it with Homebrew:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>git
</code></pre></div>    </div>

    <p>Git is a version control system (normally used for code). In our case, we use it mainly to obtain
the project dependencies.</p>
  </li>
  <li>
    <p>Clone the <code class="language-plaintext highlighter-rouge">unnamed-sdvx-clone</code> with <code class="language-plaintext highlighter-rouge">git</code>:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git clone https://github.com/Drewol/unnamed-sdvx-clone
</code></pre></div>    </div>

    <p>This will result in the game being downloaded to a <code class="language-plaintext highlighter-rouge">unnamed-sdvx-clone</code> folder
in your current working directory.</p>
  </li>
  <li>
    <p>Navigate into the new folder, and download the submodules of the project:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cd </span>unnamed-sdvx-clone
<span class="nv">$ </span>git submodule update <span class="nt">--init</span> <span class="nt">--recursive</span>
</code></pre></div>    </div>

    <p>This is necessary because the game has third-party dependencies, which are
tracked as <a href="https://github.com/Drewol/unnamed-sdvx-clone/blob/develop/.gitmodules">other Github repositories</a>.</p>
  </li>
  <li>
    <p>Install more dependencies required to build the project with Homebrew:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>cmake freetype libvorbis sdl2 libpng jpeg libarchive libiconv
</code></pre></div>    </div>

    <p>These are all open source libraries required for the following reasons:</p>
    <ul>
      <li><a href="https://cmake.org/"><code class="language-plaintext highlighter-rouge">cmake</code></a>: a popular build system used to compile the project</li>
      <li><a href="https://freetype.org/"><code class="language-plaintext highlighter-rouge">freetype</code></a>: for rendering fonts</li>
      <li><a href="https://xiph.org/vorbis/"><code class="language-plaintext highlighter-rouge">libvorbis</code></a>: audio compression</li>
      <li><a href="https://www.libsdl.org/"><code class="language-plaintext highlighter-rouge">sdl2</code></a>: get access to hardware inputs like keyboard, mouse, controller, etc</li>
      <li><a href="https://github.com/glennrp/libpng"><code class="language-plaintext highlighter-rouge">libpng</code></a>: for using/manipulating PNG images</li>
      <li><a href="https://www.ijg.org/"><code class="language-plaintext highlighter-rouge">jpeg</code></a>: for using/manipulating JPEG images</li>
      <li><a href="https://www.libarchive.org/"><code class="language-plaintext highlighter-rouge">libarchive</code></a>: compression library</li>
      <li><a href="https://www.gnu.org/software/libiconv/"><code class="language-plaintext highlighter-rouge">libiconv</code></a>: convert between different character encodings (i.e <a href="https://en.wikipedia.org/wiki/ISO/IEC_8859-1">ISO-8859-1</a> to <a href="https://en.wikipedia.org/wiki/UTF-8">UTF-8</a>)</li>
    </ul>
  </li>
  <li>
    <p>Configure the project using <code class="language-plaintext highlighter-rouge">cmake</code>. In this case, the project author
already kindly wrapped a script around this command, so we only have to run the
script:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./mac-cmake.sh
</code></pre></div>    </div>
  </li>
  <li>
    <p>Compile and build the project:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make
</code></pre></div>    </div>

    <p>This step could take a while. If you want to speed it up, you can run it and
specify the <code class="language-plaintext highlighter-rouge">-j</code> argument parallelize the compilation based on the number of
cores you have (use one less than your total number of cores):</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make <span class="nt">-j</span> 9
</code></pre></div>    </div>
  </li>
  <li>
    <p>Run the game from the <code class="language-plaintext highlighter-rouge">bin</code> folder:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cd </span>bin
<span class="nv">$ </span>./usc-game
</code></pre></div>    </div>

    <p>It is important to run it from the <code class="language-plaintext highlighter-rouge">./bin</code> folder and not the root of the
project directory, as some skins search for file dependencies in a relative
manner and will hence not be able to find it.</p>
  </li>
</ol>

<h3 id="linux">Linux</h3>
<p>Honestly if you’re on Linux, you should be able to figure it out by yourself 😊</p>

<h2 id="first-startup">First Startup</h2>

<p>On first startup, you should see this:</p>

<figure>

  

  <video src="/assets/img/posts/sdvx/sdvx-initial.webm" class="z-depth-1 center" width="400px" height="auto" autoplay="" loop="" muted="" />

  

</figure>

<p>For now, you can just use your mouse to interact with the game menu.</p>

<h2 id="configuring-the-controller">Configuring The Controller</h2>

<p>Let’s now setup our Yuancon controller!</p>

<ol>
  <li>
    <p>Quit the game, and unplug your SDVX controller if it is plugged in</p>
  </li>
  <li>
    <p>Hold the <code class="language-plaintext highlighter-rouge">START</code> and <code class="language-plaintext highlighter-rouge">BT-C</code> button simultaneously. The <code class="language-plaintext highlighter-rouge">START</code> button is the
diamond-shaped button at the top, while the BT-C is the third white button from
the left (it should also be labelled on the controller board).</p>

    <p>Then while still holding down both buttons, connect it to your computer.
This will put it in <a href="https://oniichan.wtf/help/index.html">Controller HID Mode</a>,
where the controller inputs as a gamepad.</p>
  </li>
  <li>
    <p>Start up the game again, and navigate to the <code class="language-plaintext highlighter-rouge">Settings</code> page.
Here, you want to do the following:</p>

    <ul>
      <li>Set <code class="language-plaintext highlighter-rouge">Button input mode</code> to <code class="language-plaintext highlighter-rouge">Controller</code></li>
      <li>Set <code class="language-plaintext highlighter-rouge">Laser input mode</code> to <code class="language-plaintext highlighter-rouge">Controller</code></li>
      <li>Adjust laser sensitivity accordingly (I like <code class="language-plaintext highlighter-rouge">1.875</code>)</li>
      <li>Click on each of the key bindings, and hit the corresponding
keys on your controller. I used the button on the
right side of the controller panel as my back button.</li>
    </ul>

    <p>You should have something that looks similar to this:</p>

    <p><img src="/assets/img/posts/sdvx/sdvx-settings.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" /></p>
  </li>
  <li>
    <p>Restart the game. You should now be able to use the knobs to cycle through
the menus, and the buttons to activate them!</p>
  </li>
</ol>

<h2 id="getting-songs">Getting Songs</h2>
<p>Right after setup, there are no songs to play yet. USC uses
the same chart format as <a href="https://www.kshootmania.com/en/">K-Shoot MANIA (KSM)</a></p>

<p>There are a few places you can get songs:</p>

<ul>
  <li><a href="https://ksm.dev/">Nautica</a> hosts community-created KSM charts. There is also a
  menu option to download these directly from within USC.</li>
  <li><a href="https://oniichan.wtf/help/songs.html">Converted SDVX Charts</a>: probably somewhat 
  questionable legally because of copyright and whatnot but a lot of people
  recommend and use it</li>
  <li><a href="https://www.reddit.com/r/kshootmania/wiki/gettingsongs/#wiki_getting_more_songs">This KSM FAQ page on Reddit</a> provides many useful links for downloading new songs</li>
</ul>

<p>Once you have downloaded the songs, unzip and extract them if necessary,
and copy them into <code class="language-plaintext highlighter-rouge">./bin/songs</code>.</p>

<h2 id="skinning-the-game">Skinning The Game</h2>

<p>The default skin works, but it is not very impressive:</p>

<figure>

  

  <video src="/assets/img/posts/sdvx/sdvx-default.webm" class="z-depth-1 center" width="400px" height="auto" autoplay="" loop="" muted="" />

  

</figure>

<p>Let’s try to re-create the original SDVX arcade experience with
skins. 
You can get skins for the game <a href="https://oniichan.wtf/help/skins.html">here</a>.
These are really high-effort and well-made, and huge thanks to the developers
and artists for making them.</p>

<p>Once you have downloaded the skin, extract and move them to <code class="language-plaintext highlighter-rouge">./bin/skins</code>. You
should then be able to select the skin under the <code class="language-plaintext highlighter-rouge">Skins</code> tab of the game
settings.</p>

<p>The UI of the skin for the game may change depending on whether your
monitor is in portrait or landscape mode. Orienting it vertically
is recommended for the best SDVX-like experience - the spaceship(?) at
the bottom only shows up when it’s vertical.</p>

<p>Some examples of the different skins are shown below. I know, they’re pretty!</p>

<p>(<em>Why are the previews so low-res? <a href="https://www.digitalocean.com/blog/its-all-about-the-bandwidth-why-many-network-intensive-services-select-digitalocean-as-their-cloud">Bandwidth costs add up!</a></em>)</p>

<h3 id="liqidwave">LiqidWave</h3>

<figure>

  

  <video src="/assets/img/posts/sdvx/vivid.webm" class="z-depth-1 center" width="400px" height="auto" autoplay="" loop="" muted="" />

  

</figure>

<p>If you run into errors about shaders when trying to play a song, see the <a href="#common-errors">Common
Errors</a> section below.</p>

<h3 id="experimentalgear">ExperimentalGear</h3>

<figure>

  

  <video src="/assets/img/posts/sdvx/experimental-gear.webm" class="z-depth-1 center" width="400px" height="auto" autoplay="" loop="" muted="" />

  

</figure>

<p>As a side note, if you find the default menu text for this skin too casual/unprofessional,
you can change it in <code class="language-plaintext highlighter-rouge">./bin/skins/ExperimentalGear/scripts/language/EN.lua</code>.</p>

<h3 id="heavenly-express">Heavenly Express</h3>

<figure>

  

  <video src="/assets/img/posts/sdvx/heavenly-express.webm" class="z-depth-1 center" width="400px" height="auto" autoplay="" loop="" muted="" />

  

</figure>

<h2 id="crew">Crew</h2>
<p>Not all skins come with a cast of crews, like the ExperimentalGear skin which
only comes with a boring empty <code class="language-plaintext highlighter-rouge">nothing</code> skin in
<code class="language-plaintext highlighter-rouge">./bin/skins/ExperimentalGear/textures/crew/anim</code>.</p>

<p>As crews are very important for our psychological safety and well-being,
fortunately we can just copy over the animations from other skins.
In HeavenlyExpress, you can find it in <code class="language-plaintext highlighter-rouge">./bin/skins/HeavenlyExpress-1.3.0/textures/_shared/crew</code>. Similarly, in LiqidWave they are stored in <code class="language-plaintext highlighter-rouge">./bin/skins/LiqidWave-1.5.0/textures/_shared/crew</code>.</p>

<figure>

  

  <video src="/assets/img/posts/sdvx/rasis.webm" class="z-depth-1 center" width="400px" height="auto" autoplay="" loop="" muted="" />

  

</figure>

<h2 id="conclusion">Conclusion</h2>
<p>If you’ve made it this far, congrats and thanks for reading!  I hope you’ll
enjoy the game as much as I do.  If you have any questions or run into problems,
feel free to ask in the comments section below.</p>

<h2 id="extras">Extras</h2>

<h3 id="aside-ksm-chart-formats">Aside: KSM Chart Formats</h3>
<p>KSM charts have a <code class="language-plaintext highlighter-rouge">.ksh</code> extensions. This can be a useful check to ensure
that any charts that you download are actually for this game.</p>

<p>The following is a snippet of the <code class="language-plaintext highlighter-rouge">ADV.ksh</code> (i.e advanced beatmap)
file for YOASOBI’s Idol (アイドル):</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">title</span><span class="o">=</span>アイドル
<span class="nv">artist</span><span class="o">=</span>YOASOBI /「推しの子」より
<span class="nv">effect</span><span class="o">=</span>AS
<span class="nv">jacket</span><span class="o">=</span>jk.jpg
<span class="nv">illustrator</span><span class="o">=</span>-
<span class="nv">difficulty</span><span class="o">=</span>challenge
<span class="nv">level</span><span class="o">=</span>10
<span class="nv">t</span><span class="o">=</span>166
<span class="nv">m</span><span class="o">=</span>music.ogg
<span class="nv">o</span><span class="o">=</span>0
<span class="nb">bg</span><span class="o">=</span>desert
<span class="nv">layer</span><span class="o">=</span>smoke
<span class="nv">po</span><span class="o">=</span>56024
<span class="nv">plength</span><span class="o">=</span>15000
<span class="nv">pfiltergain</span><span class="o">=</span>50
<span class="nv">filtertype</span><span class="o">=</span>peak
<span class="nv">chokkakuautovol</span><span class="o">=</span>0
<span class="nv">chokkakuvol</span><span class="o">=</span>50
<span class="nv">ver</span><span class="o">=</span>171
<span class="nt">--</span>
<span class="nv">beat</span><span class="o">=</span>4/4
0000|00|--
<span class="nt">--</span>
0000|00|0-
0000|00|:-
0000|00|o-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|o-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|P-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|P-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
<span class="nt">--</span>
0000|00|0-
0000|00|:-
<span class="nv">filtertype</span><span class="o">=</span>lpf1
0000|00|0o
0000|00|::
0000|00|o0
0000|00|::
</code></pre></div></div>

<h2 id="possible-errors-and-how-to-resolve">Possible Errors And How To Resolve</h2>
<p>Some errors I faced when trying to setup and configure the game.</p>

<h3 id="module-commonshared-not-found">module <code class="language-plaintext highlighter-rouge">commonShared</code> not found</h3>

<p>If you get a Lua error about not being able to load a <code class="language-plaintext highlighter-rouge">commonShared</code> package,
such as when using a custom skin:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>14:45:10][Error] Lua error: ...clone/bin/skins/HeavenlyExpress-1.3.0/scripts/common.lua:2: module <span class="s1">'commonShared'</span> not found:
	no field package.preload[<span class="s1">'commonShared'</span><span class="o">]</span>
	no file <span class="s1">'/usr/local/share/lua/5.3/commonShared.lua'</span>
	no file <span class="s1">'/usr/local/share/lua/5.3/commonShared/init.lua'</span>
	no file <span class="s1">'/usr/local/lib/lua/5.3/commonShared.lua'</span>
	no file <span class="s1">'/usr/local/lib/lua/5.3/commonShared/init.lua'</span>
	no file <span class="s1">'./commonShared.lua'</span>
	no file <span class="s1">'./commonShared/init.lua'</span>
	no file <span class="s1">'/Users/fanpu/unnamed-sdvx-clone/bin/skins/HeavenlyExpress-1.3.0/scripts/commonShared.lua'</span>
	no file <span class="s1">'skins/HeavenlyExpress-1.3.0/textures/_shared/scripts/commonShared.lua'</span>
	no file <span class="s1">'/usr/local/lib/lua/5.3/commonShared.so'</span>
	no file <span class="s1">'/usr/local/lib/lua/5.3/loadall.so'</span>
	no file <span class="s1">'./commonShared.so'</span>

</code></pre></div></div>

<p>You are likely running the game from the root of the project directory (i.e
<code class="language-plaintext highlighter-rouge">./bin/usc-game</code>), instead of from within the <code class="language-plaintext highlighter-rouge">./bin</code> directory itself.</p>

<h3 id="heavenlyexpress-skin-could-not-load-shaders">HeavenlyExpress Skin: Could not load shaders</h3>

<p>If you are using the HeavenlyExpress skin, you may run into the following
error after selecting a track to play:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Shader Error: 
Could not load shaders skins/HeavenlyExpress-1.3.0/shaders/holdbutton.vs 
and skins/HeavenlyExpress-1.3.0/shaders/holdbutton.fs
</code></pre></div></div>

<p>You may also get logs like this:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>14:58:37][Error] Shader program compile log <span class="k">for</span> /Users/fanpu/unnamed-sdvx-clone/bin/skins/HeavenlyExpress-1.3.0/shaders/holdbutton.vs: ERROR: 0:6: <span class="s1">'varying'</span> : syntax error: syntax error

<span class="o">[</span>14:58:37][Error] Shader program compile log <span class="k">for</span> /Users/fanpu/unnamed-sdvx-clone/bin/skins/HeavenlyExpress-1.3.0/shaders/holdbutton.fs: ERROR: 0:10: <span class="s1">'varying'</span> : syntax error: syntax error

<span class="o">[</span>14:58:37][Error] Failed to load vertex shader <span class="k">for </span>material from /Users/fanpu/unnamed-sdvx-clone/bin/skins/HeavenlyExpress-1.3.0/shaders/holdbutton.vs
</code></pre></div></div>

<p>The shaders were probably written a long time ago, since
the <code class="language-plaintext highlighter-rouge">varying</code> keyword has been deprecated since OpenGL 3.3.
It was previously used as a qualifier for variables that communicate
between the vertex shader and the fragment shader, that is now
replaced by the <code class="language-plaintext highlighter-rouge">in</code> and <code class="language-plaintext highlighter-rouge">out</code> qualifiers to provide a more clear distinction of
data flow between shaders.</p>

<p>To fix this, modify the two files and change the <code class="language-plaintext highlighter-rouge">varying</code>
keyword to <code class="language-plaintext highlighter-rouge">out</code> in both files:</p>

<p>In file <code class="language-plaintext highlighter-rouge">bin/skins/HeavenlyExpress-1.3.0/shaders/holdbutton.vs</code>:</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#version 330
#extension GL_ARB_separate_shader_objects : enable
</span><span class="n">layout</span><span class="p">(</span><span class="n">location</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="n">in</span> <span class="n">vec2</span> <span class="n">inPos</span><span class="p">;</span>
<span class="n">layout</span><span class="p">(</span><span class="n">location</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="n">in</span> <span class="n">vec2</span> <span class="n">inTex</span><span class="p">;</span>

<span class="n">out</span> <span class="n">vec4</span> <span class="n">position</span><span class="p">;</span> <span class="c1">// update here</span>

<span class="n">out</span> <span class="n">gl_PerVertex</span>
<span class="p">{</span>
        <span class="n">vec4</span> <span class="n">gl_Position</span><span class="p">;</span>
<span class="p">};</span>

<span class="p">...</span><span class="n">rest</span> <span class="n">of</span> <span class="n">file</span> <span class="n">omitted</span><span class="p">...</span>
</code></pre></div></div>

<p>In file <code class="language-plaintext highlighter-rouge">bin/skins/HeavenlyExpress-1.3.0/shaders/holdbutton.fs</code>:</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#version 330
#extension GL_ARB_separate_shader_objects : enable
</span>
<span class="n">layout</span><span class="p">(</span><span class="n">location</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="n">in</span> <span class="n">vec2</span> <span class="n">fsTex</span><span class="p">;</span>
<span class="n">layout</span><span class="p">(</span><span class="n">location</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="n">out</span> <span class="n">vec4</span> <span class="n">target</span><span class="p">;</span>

<span class="n">uniform</span> <span class="n">sampler2D</span> <span class="n">mainTex</span><span class="p">;</span>
<span class="n">uniform</span> <span class="kt">float</span> <span class="n">objectGlow</span><span class="p">;</span>

<span class="n">out</span> <span class="n">vec4</span> <span class="n">position</span><span class="p">;</span> <span class="c1">// update here</span>

<span class="p">...</span><span class="n">rest</span> <span class="n">of</span> <span class="n">file</span> <span class="n">omitted</span><span class="p">...</span>
</code></pre></div></div>

<p>Restart the game and you should be good now.</p>

<h3 id="experimentalgear-custom-skin-does-not-change">ExperimentalGear Custom Skin Does Not Change</h3>

<p>I faced issues where it appeared that the value that I set in the settings page
for the skin to use was not being saved. I resolved
this by manually editing the config file in
<code class="language-plaintext highlighter-rouge">./bin/skins/ExperimentalGear/skin.cfg</code>.</p>]]></content><author><name>fanpu</name></author><category term="general" /><category term="rhythm-games" /><summary type="html"><![CDATA[Rhythm is just a $200 controller and some hopefully-not-too-complicated open source software setup away! This beginner's guide will help to demystify the process of setting up Sound Voltex at home using a custom SDVX controller using Unnamed SDVX Clone.]]></summary></entry><entry><title type="html">Creating Trackback Requests for Static Sites</title><link href="https://fanpu.io/blog/2023/creating-trackback-requests/" rel="alternate" type="text/html" title="Creating Trackback Requests for Static Sites" /><published>2023-09-01T00:00:00+00:00</published><updated>2023-09-01T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/creating-trackback-requests</id><content type="html" xml:base="https://fanpu.io/blog/2023/creating-trackback-requests/"><![CDATA[<p>In this article, I will show you how you can generate trackback requests to
external websites to link back to your static site like
<a href="https://jekyllrb.com/">Jekyll</a> or <a href="https://gohugo.io/">Hugo</a>.
I decided to write this article after realizing how there is almost no
information online about how to make DIY trackback requests when I was
trying to set it up.</p>

<h2 id="what-is-trackback">What is Trackback?</h2>
<p>From <a href="">Wikipedia</a>:</p>

<blockquote>
  <p>A trackback allows one website to notify another about an update. It is one
of four types of linkback methods for website authors to request notification
when somebody links to one of their documents. This enables authors to keep
track of who is linking to their articles. Some weblog software, such as
SilverStripe, WordPress, Drupal, and Movable Type, supports automatic pingbacks
where all the links in a published article can be pinged when the article is
published. The term is used colloquially for any kind of linkback.</p>
</blockquote>

<p>Essentially, it is a mechanism for other websites to know that you mentioned them,
with the hope that they’ll notice you and possibly mention you as well.
It helps to increase the visibility and discoverability of your website.</p>

<h2 id="use-case">Use Case</h2>
<p>My use case was to send trackbacks to <a href="https://info.arxiv.org/help/trackback.html">arXiv</a>,
so that specific arXiv papers will know that my blog post mentioned them, and readers
can also check it out as an additional resource. In particular, each of my <a href="summaries">paper summary</a> posts is based around a paper, and it would be nice if they could be linked from the respective arXiv paper abstract pages.</p>

<p>In arXiv, there is a blog link section that will track websites that made trackback
requests for a given paper:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/trackback_post/trackback_blog_link.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>
</figure>

<p>Unfortunately, if you try to search for anything about trackbacks and/or
pingbacks, most of what you’ll get are articles about how to disable them on
popular blogging platforms like WordPress due to <a href="https://blog.hubspot.com/website/trackback-spam">widespread misuse and spam</a>, or
otherwise how to configure them.</p>

<p>There was also a 7-year old <a href="https://superuser.com/questions/1098682/how-to-send-trackback-to-arxiv-papers-from-a-jekyll-blog">StackOverflow post</a> about how to
create trackback requests for arXiv, essentially the same problem I was facing. 
Sadly, it currently has a grand total of 0 answers and 0 comments. I hope this
article might be useful if the author is still facing the issue.</p>

<h2 id="manually-creating-trackback-requests">Manually Creating Trackback Requests</h2>
<p>The convenience of CMS blogging software like
<a href="https://wordpress.org/documentation/article/trackbacks-and-pingbacks/">WordPress</a>
is that it supports features like automated trackbacks and pingbacks for content
that you create. Static site generators are not capable of this, since by design they
are static and stateless. This means that we have to make such requests manually,
which is fortunately not too difficult!</p>

<p>Here’s a very simple script for doing it. In this example, the target URL
is for the arXiv trackback endpoint.</p>

<p>Before reading or running the code, please note that you <strong>SHOULD NOT</strong> test or
experiment on this with trackback listener URLs and spam them. You should only
make requests if they are legitimate and you have a genuine reason for letting
them know about your blog post.  Trackback spam is a serious issue and part of
why they have become so unpopular and unmanageable is due to the high volumes of
spam.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td class="code"><pre><span class="kn">import</span> <span class="n">requests</span>

<span class="c1"># Replace with your own data
</span><span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">title</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">My Awesome Blog Post</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">url</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">https://my-blog.com/post/</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">blog_name</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">My Awesome Blog</span><span class="sh">'</span>
<span class="p">}</span>

<span class="c1"># Replace with actual Trackback destination URL
</span><span class="n">trackback_url</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">https://foo.bar/trackback/post_id</span><span class="sh">'</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span><span class="n">trackback_url</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>

<span class="k">if</span> <span class="n">response</span><span class="p">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Trackback successful!</span><span class="sh">"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Trackback failed with status code: </span><span class="si">{</span><span class="n">response</span><span class="p">.</span><span class="n">status_code</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">response</span><span class="p">.</span><span class="n">content</span><span class="p">.</span><span class="nf">decode</span><span class="p">())</span>
</pre></td></tr></tbody></table></code></pre></figure>

<p>A successful response has the <code class="language-plaintext highlighter-rouge">error</code> field set to <code class="language-plaintext highlighter-rouge">0</code>:</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="cp">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span>
<span class="nt">&lt;response&gt;</span>
  <span class="nt">&lt;error&gt;</span>0<span class="nt">&lt;/error&gt;</span>
<span class="nt">&lt;/response&gt;</span></code></pre></figure>

<p>If an error occured, the <code class="language-plaintext highlighter-rouge">error</code> field is set to <code class="language-plaintext highlighter-rouge">1</code>:</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="cp">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span>
<span class="nt">&lt;response&gt;</span>
  <span class="nt">&lt;error&gt;</span>1<span class="nt">&lt;/error&gt;</span>
  <span class="nt">&lt;message&gt;</span>(some error message)<span class="nt">&lt;/message&gt;</span>
<span class="nt">&lt;/response&gt;</span></code></pre></figure>

<h2 id="conclusion">Conclusion</h2>
<p>And that’s all there is to creating Trackback requests! It’s actually quite
simple, and is just not terribly well-documented.</p>

<p>As a final parting word, a reminder again to please use it <em>responsibly</em> and <em>stay
away from any behavior that could be constituted as spamming</em>.</p>]]></content><author><name>fanpu</name></author><category term="code" /><category term="general" /><summary type="html"><![CDATA[A simple guide on creating manual Trackback requests for static sites to increase visibility and discoverability]]></summary></entry><entry><title type="html">A Unified Framework for High-Dimensional Analysis of M-Estimators with Decomposable Regularizers: A Guided Walkthrough</title><link href="https://fanpu.io/blog/2023/high-dimensional-analysis-of-m-estimators/" rel="alternate" type="text/html" title="A Unified Framework for High-Dimensional Analysis of M-Estimators with Decomposable Regularizers: A Guided Walkthrough" /><published>2023-07-14T00:00:00+00:00</published><updated>2023-07-14T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/high-dimensional-analysis-of-m-estimators</id><content type="html" xml:base="https://fanpu.io/blog/2023/high-dimensional-analysis-of-m-estimators/"><![CDATA[\[\newcommand{\rcal}{\mathcal{R}}
    \newcommand{\lcal}{\mathcal{L}}
    \newcommand{\mcal}{\mathcal{M}}
    \newcommand{\mocal}{\overline{\mathcal{M}}}
    \newcommand{\mocalp}{\overline{\mathcal{M}}^\perp}
    \newcommand{\mcalp}{\mathcal{M}^\perp}
    \newcommand{\sse}{\subseteq}
    \newcommand{\kl}{\kappa_{\lcal}}
    \newcommand{\tl}{\tau_{\lcal}}
    \newcommand{\ts}{\theta^*}
    \newcommand{\hd}{\widehat{\Delta}}
    \newcommand{\thatn}{\hat{\theta}_n}
    \newcommand{\that}{\hat{\theta}}
    \newcommand{\thatlambda}{\widehat{\theta}_{\lambda_n}}
    \newcommand{\thatl}{\thatlambda}
    \newcommand{\rs}{\rcal^*}
    \newcommand{\ctriplet}{ \C(\mcal, \mocalp; \ts) }
    \newcommand{\fcal}{\mathcal{F}}
    \newcommand{\kbb}{\mathbb{K}}
\newcommand{\dotprod}[2]{\langle #1, #2 \rangle}
    \DeclareMathOperator*{\argmin}{arg\,min}\]

<h1 id="introduction">Introduction</h1>

<p>In high-dimensional statistical inference, it is common for the number of
parameters \(p\) to be comparable to or greater than the sample size \(n\).
However, for an estimator \(\thatn\) to be consistent in such a regime,
meaning that it converges to the true parameter \(\theta\),
it is necessary to make additional low-dimensional
assumptions on the model.
Examples of such constraints that have been well-studied include
linear regression with sparsity constraints, estimation of structured covariance
or inverse covariance matrices, graphical model selection, sparse principal
component analysis (PCA), low-rank matrix estimation, matrix decomposition problems
and estimation of sparse additive nonparametric models <a href="https://arxiv.org/abs/1010.2731">(Negahban et al., 2009)</a>.</p>

<p>In recent years, there has been a flurry of work on each of these individual specific cases.
However, the authors of the paper in discussion poses the question of whether there is a way
of unifying these analysis to understand all of such estimators in a common framework,
and answers it in the affirmative. They showed that it is possible to bound
the squared difference between any regularized \(M\)-estimator and its true
parameter by (1) the decomposability of the regularization function, and (2)
restricted strong convexity of the loss function. We will call this the “main theorem”
in the remainder of the blog post, and this is referred to as “Theorem 1” in <a href="https://arxiv.org/abs/1010.2731">(Negahban et al., 2009)</a>.</p>

<p>In the remainder of the paper, we will develop the tools necessary to deeply
understand and prove the result. Notation used will be consistent with the
original paper for expositional clarity.</p>

<h1 id="background">Background</h1>

<p>In this section, we develop some of the necessary background and notation to build up to the proof.</p>

<h2 id="regularized-m-estimators">Regularized \(M\)-estimators</h2>

<p>\(M\)-estimators (\(M\) for “maximum likelihood-type”) are solutions that minimize the sum of loss functions \(\rho\):
\begin{align}
    \that \in \argmin_\theta \sum_{i=1}^n \rho(x_i, \theta).
\end{align}</p>

<p>If we add a regularization term \(\rcal\) to penalize complexity of the model, scaled by weights \(\lambda\), the method is known as a regularized \(M\)-estimator:
\begin{align}
    \that \in \argmin_\theta \sum_{i=1}^n \rho(x_i, \theta) + \lambda \rcal(\theta).
\end{align}</p>

<div class="example">
    <div class="theorem-title">Example
        
        
            (Lasso Program)
        
    </div>
    <div class="theorem-contents">
        
    The Lasso program is an example of a regularized \( M \)-estimator, where a
    \( \ell_1 \) regularization penalty is applied:
    $$
        \that \in \argmin_{\theta \in \mathbb{R}^d} \left\{
        \frac{1}{2n} \| y - \bX \theta \|_2^2 + \lambda_n \| \theta \|_1
        \right\}.
    $$
  
    </div>
</div>

<h2 id="dual-norms">Dual Norms</h2>

<div class="definition">
    <div class="theorem-title">Definition
        
        
            (Dual Norms)
        
    </div>
    <div class="theorem-contents">
        
    Let \(\rcal\) be a norm induced by an inner product
    \(\dotprod{\cdot}{\cdot}\). Then the dual norm of \(\rcal\)
    is defined as
    $$
        \rs(v) \coloneqq \sup_{u \in \mathbb{R}^p \setminus \left\{ 0 \right\}}
        \frac{ \dotprod{u}{v} }{\rcal (u)} = \sup_{\rcal(u) \leq 1} \dotprod{u}{v}.
    $$
  
    </div>
</div>

<div class="example">
    <div class="theorem-title">Example
        
        
            (\(\ell_1\) and \(\ell_\infty\) norms are dual norms)
        
    </div>
    <div class="theorem-contents">
        
  We will show that the dual of the \( \ell_1 \) norm is the \( \ell_\infty \) norm.

Well, to see that \( \rs(v) \leq \| v \|_\infty \), observe that
        \begin{align*}
            \rs(v)
             &amp; = \sup_{\| u \|_1 \leq 1} \dotprod{u}{v}                                        \\
             &amp; = \sup_{\| u \|_1 \leq 1} \sum_{k=1}^p | u_k | | v_k |                          \\
             &amp; \leq \sup_{\| u \|_1 \leq 1} \left( \sum_{k=1}^p | u_k | \right) \| v \|_\infty \\
             &amp; = | v |_\infty   \tag{since \( \| u \|_1 \leq 1 \) }.
        \end{align*}
        For the opposite direction,

        \begin{align*}
            \sup_{\| u \|_1 \leq 1} \dotprod{u}{v}
             &amp; = \sup_{\| u \|_1 \leq 1} \sum_{k=1}^p |u_k| |v_k|                               \\
             &amp; \geq 1 \cdot |v_j| \tag{
             set \( j = \argmax_j |v_j|, u = \be_j \)
             } \\
             &amp; = \| v \|_\infty,
        \end{align*}
        hence we have equality.

  
    </div>
</div>

<h2 id="subspace-compatibility-constant">Subspace Compatibility Constant</h2>

<p>The subspace compatibility constant measures how much the regularizer \(\rcal\) can change
with respect to the error norm  \(\| \cdot \|\) restricted to the subspace \(\mcal\).
This concept will show up later in showing that the restricted strong convexity
condition will hold with certain parameters.</p>

<p>The subspace compatibility constant is defined as follows:</p>

<div class="definition">
    <div class="theorem-title">Definition
        
        
            (Subspace Compatibility Constant)
        
    </div>
    <div class="theorem-contents">
        
    For any subspace \( \mcal \) of \( \mathbb{R}^p \), the <i>subspace compatibility constant</i>
    with respect to the pair \( (\rcal, \| \cdot \|) \) is given by

    $$
        \varPsi (\mcal) \coloneqq \sup_{u \in \mcal \setminus \left\{ 0 \right\}} \frac{\rcal(u)}{\| u \|}.
    $$
    
    </div>
</div>

<p>It can be thought of as the Lipschitz constant of the regularizer with respect to the error norm
restricted to values in \(\mcal\),
by considering the point where it can vary the most.</p>

<h2 id="projections">Projections</h2>
<p>Define the projection operator
\begin{align}
    \Pi_{\mcal}(u) \coloneqq \argmin_{v \in \mcal} | u - v |
\end{align}
to be the projection of \(u\) onto the subspace \(\mcal\).
For notational brevity, we will use the shorthand \(u_{\mcal} = \Pi_{\mcal}(u)\).</p>

<p>One property of the projection operator is that it is non-expansive, meaning that
\begin{align}
    | \Pi(u) - \Pi(v) | \leq | u - v | \label{eq:non-expansive}
\end{align}
for some error norm \(\| \cdot \|\). In other words, it has Lipschitz constant 1.</p>

<h1 id="problem-formulation">Problem Formulation</h1>

<p>In our setup, we define the following quantities:</p>

<ul>
  <li>\(Z_1^n \coloneqq \left\{ Z_1, \cdots, Z_n \right\}\) \(n\) i.i.d observations
      drawn from distribution \(\mathbb{P}\) with some parameter \(\theta^*\),</li>
  <li>\(\mathcal{L}: \mathbb{R}^p \times \mathcal{Z}^n \to \mathbb{R}\) a convex and differentiable loss function, such that \(\mathcal{L}(\theta; Z_1^n)\) returns the loss of \(\theta\) on observations \(Z_1^n\),</li>
  <li>\(\lambda_n &gt; 0\): a user-defined regularization penalty,</li>
  <li>\(\mathcal{R} : \mathbb{R}^p \to \mathbb{R}_+\) a norm-based regularizer.</li>
</ul>

<p>The purpose of the regularized \(M\)-estimator is then to solve for the convex optimization problem</p>

\[\begin{align} \label{eq:opt}
    \widehat{\theta}_{\lambda_n} \in \argmin_{\theta \in \mathbb{R}^p} \left\{
    \mathcal{L}(\theta; Z_1^n) + \lambda_n \mathcal{R} (\theta) \right\},
\end{align}\]

<p>and we are interested in deriving bounds on
\(\begin{align}
    \| \thatlambda - \theta^* \|
\end{align}\)
for some error norm \(\| \cdot \|\) induced by an inner product \(\langle \cdot, \cdot \rangle\) in \(\mathbb{R}^p\).</p>

<h1 id="decomposability-of-the-regularizer-mathcalr">Decomposability of the Regularizer \(\mathcal{R}\)</h1>

<p>The first key property in the result is decomposability of our norm-based regularizer \(\rcal\).
Working in the ambient \(\mathbb{R}^p\), define \(\mcal \sse \mathbb{R}^p\) to be the model subspace that captures
the constraints of the model that we are working with (i.e \(k\)-sparse vectors),
and denote \(\mocal\) to be its closure, i.e the union of \(\mcal\) and all of its limit points.
In addition, denote \(\mocalp\) to be the orthogonal complement of \(\mocal\), namely</p>

\[\begin{align}
    \mocalp \coloneqq \left\{ v \in \mathbb{R}^p \mid \langle u, v \rangle = 0 \text{ for all \( u \in \mocal \) }
    \right\}.
\end{align}\]

<p>We call this the perturbation subspace, as they represent perturbations away from the model subspace \(\mocal\).
The reason why we need to consider \(\mocal\) instead of \(\mcal\) is because there are some special cases
of low-rank matrices and nuclear norms where it could be possible that \(\mcal\) is strictly contained in \(\mocal\).</p>

<p>Now we can introduce the property of decomposability:</p>

<div class="definition">
    <div class="theorem-title">Definition
        
        
            (Regularizer Decomposability)
        
    </div>
    <div class="theorem-contents">
        
      Given a pair of subspaces \( \mcal \sse \mocal \), a norm-based regularizer
    \( \rcal \) is <i>decomposable</i> with respect to \( (\mocal, \mocalp) \) if

    $$
        \rcal(\theta + \gamma) = \rcal(\theta) + \rcal(\gamma)
    $$

    for all \( \theta \in \mcal \) and \( \gamma \in \mocalp \).
  
    </div>
</div>

<p>Since \(\rcal\) is a norm-based regularizer, by the triangle inequality property of norms we know that always
\begin{align}
    \rcal(\theta + \gamma) \leq \rcal(\theta) + \rcal(\gamma),
\end{align}
and hence this is a stronger condition which requires tightness in the
inequality when we are specifically considering elements in the closure of the
model subspace and its orthogonal complement.</p>

<p>Decomposability of the regularizer is important as it allows us to penalize deviations \(\gamma\)
away from the model subspace in \(\mcal\) to the maximum extent possible.
We are usually interested to find model subspaces that are small, with a large orthogonal complement.
We will see in the main theorem that when this is the case, we will obtain better rates for estimating
\(\theta^*\).</p>

<p>There are many natural contexts that admit regularizers which are decomposable with respect to subspaces,
and the following example highlights one such case.</p>

<div class="example">
    <div class="theorem-title">Example
        
        
            (\( s \)-sparse Vectors)
        
    </div>
    <div class="theorem-contents">
        
      Consider estimating the parameters \( \that \) with \( \ell_1 \)-regularization in \( \mathbb{R}^p \) where we assume that
    the model is \( s \)-sparse. Then for any set \( S \sse [p] \) where \( |S| = s \),
    we can define our model subspace \( \mcal \) as

    \[
    \begin{align*}
        \mcal(S) \coloneqq \left\{ \theta \in \mathbb{R}^p \mid \theta_j = 0 \quad \forall j \not\in S \right\},
    \end{align*}
    \]

    i.e all the vectors in \( \mathbb{R}^p \) that only has support in \( S \). In this case, \( \mcal = \mocal \),
    and our orthogonal complement \( \mocalp \) is just

    \[
    \begin{align*}
        \mocalp(S) \coloneqq \left\{ \gamma \in \mathbb{R}^p \mid \gamma_j = 0 \quad \forall j \in S \right\}.
    \end{align*}
    \]

    Then this setup is decomposable:

    \[
    \begin{align*}
        \| \theta + \gamma \|_1 = \| \theta_S + \gamma_{S^c} \|_1 = \| \theta_S \|_1 + \| \gamma_{S^c} \| = \| \theta \|_1 + \| \gamma \|_1
    \end{align*}
    \] 

    by the Pythagorean theorem.
  
    </div>
</div>

<h2 id="role-of-decomposability">Role of Decomposability</h2>

<figure id="fig-1">
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/high-dimensional-analysis-of-m-estimators/c_illust.webp" class="z-depth-1 center" width="500px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption"><i>Figure 1.</i>
      
        A visualization of \( \ctriplet \).  The shaded area represents the set
        \( \ctriplet \), i.e all values of \( \theta \) that satisfies the inequality of
        the set in Lemma 1. 
    
    </figcaption>
</figure>

<p>Decomposability is important because it allows us to bound the error of the estimator.
This is given in the following result, which is known as Lemma 1 in <a href="https://arxiv.org/abs/1010.2731">(Negahban et al., 2009)</a>:</p>

<div class="lemma" id="lemma-1">
    <div class="theorem-title">Lemma
        
        
            (Lemma 1 in 
  <a href="https://arxiv.org/abs/1010.2731">
    (Negahban et al., 2009)
  </a>)
        
    </div>
    <div class="theorem-contents">
        
    Suppose that \( \lcal \) is a convex and differentiable function, and consider
    any optimal solution \( \that \) to the optimization problem
    with a strictly positive regularization parameter satisfying

    $$
    \begin{align*}
        \lambda_n \geq 2 \rcal^* (\nabla \lcal (\ts; Z_1^n)).
    \end{align*}
    $$

    Then for any pair \( (\mcal, \mocalp) \) over which \( \rcal \) is decomposable,
    the error \( \hd = \thatlambda - \ts  \) belongs to the set

    $$
    \begin{align*} \label{eq:c}
        \C(\mcal, \mocalp; \ts) \coloneqq \left\{  \Delta \in \mathbb{R}^p \mid
        \rcal(\Delta_{\mocalp}) \leq 3 \rcal (\Delta_{\mocal}) + 4 \rcal (\ts_{\mcalp})
        \right\}.
    \end{align*}
    $$
  
    </div>
</div>

<p>Recall from the <a href="#projections">Projections Section</a> that
\(\Delta_{\mocalp}\) represents the projection of \(\Delta\) onto \(\mocalp\), and similarly
for the other quantities.
Due to space constraints, we are unable to prove Lemma <a href="#lemma-1">Lemma 1</a> in this survey,
but it is very important in the formulation of restricted strong convexity, and in proving
<a href="#thm-1">Theorem 1</a>.</p>

<p><a href="#fig-1">Figure 1</a> provides a visualization of \(\ctriplet\) in \(\mathbb{R}^3\) in the
sparse vectors setting. In this case, \(S = \left\{ 3 \right\}\) with \(|S|=1\),
and so the projection of \(\Delta\) onto the model subspace only has non-zero
values on the third coordinate, and its orthogonal complement is where the third
coordinate is zero. Formally,</p>

\[\begin{align}
    \mcal(S) = \mocal(S) &amp; = \left\{ \Delta \in \mathbb{R}^3 \mid \Delta_1 = \Delta_2 = 0 \right\}, \\
    \mocalp(S)           &amp; = \left\{ \Delta \in \mathbb{R}^3 \mid \Delta_3 = 0 \right\}.
\end{align}\]

<p>The vertical axis of <a href="#fig-1">Figure 1</a> denotes the third coordinate,
and the horizontal plane denotes the first two coordinates.
The shaded area
represents the set \(\ctriplet\), i.e all values of \(\theta\) that satisfies the inequality
of the set in <a href="#lemma-1">Lemma 1</a>.</p>

<p><a href="#fig-1">Figure 1(a)</a> shows the special case
when \(\ts \in \mcal\). In this scenario, \(\rcal (\ts_{\mcalp}) = 0\), and so</p>

\[\begin{align*}
    \C(\mcal, \mocalp; \ts) = \left\{  \Delta \in \mathbb{R}^p \mid
    \rcal(\Delta_{\mocalp}) \leq 3 \rcal (\Delta_{\mocal}) \right\},
\end{align*}\]

<p>which is a cone.</p>

<p>However, in the general setting where \(\ts \not\in \mcal\),
then \(\rcal (\ts_{\mcalp}) &gt; 0\), and the set \(\ctriplet\) will become a star-shaped set
like what is shown in <a href="#fig-1">Figure 1(b)</a>.</p>

<h1 id="restricted-strong-convexity-rsc-of-the-loss-function">Restricted Strong Convexity (RSC) of the Loss Function</h1>

<figure id="fig-2">
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/high-dimensional-analysis-of-m-estimators/curvature.webp" class="z-depth-1 center" width="500px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption"><i>Figure 2.</i>
      
        An illustration of the role of curvature in guaranteeing that
        \( \hd = \thatlambda - \ts \) is small when \( \lcal(\thatlambda) - \lcal(\ts) \) is small.
    
    </figcaption>
</figure>

<p>In a classical setting, as the number of samples \(n\) increases, the difference
in loss \(d \lcal = |\lcal(\thatlambda) - \lcal(\ts)|\) will converge to zero.
However, the convergence in loss by itself is insufficient to also ensure
the convergence in parameters, \(\hd = \thatlambda - \ts\). Instead, it also
depends on the curvature of the loss function \(\lcal\).</p>

<p><a href="#fig-2">Figure 2</a> illustrates the importance of curvature.
In <a href="#fig-2">Figure 2(a)</a>, \(\lcal\) has high curvature, and so
having a small \(d\lcal\) also implies a small \(\hd\). On the other hand,
in <a href="#fig-2">Figure 2(b)</a>, \(\lcal\) has an almost flat landscape
near \(\thatlambda\), and hence even when \(d \lcal\) is small,
\(\hd\) could still be large.</p>

<p>Consider performing a Taylor expansion of \(\lcal\) around \(\ts\):</p>

\[\begin{align}
    \lcal(\ts + \Delta)
     &amp; = \lcal(\ts) + \dotprod{\nabla \lcal(\ts)}{\Delta}
    + \underbrace{\frac{1}{2} \Delta^T \nabla^2 \lcal(\ts) \Delta + \dots}_{\delta \lcal(\Delta, \ts)}.
\end{align}\]

<p>Then we can rearrange and write the error of the first-order Taylor series expansion at \(\ts\) as</p>

\[\begin{align*}
    \delta \lcal(\Delta, \ts) = \lcal(\ts + \Delta) - \lcal(\ts) -
    \dotprod{\nabla \lcal(\ts)}{\Delta}.
\end{align*}\]

<p>The first-order Taylor approximation is a linear approximation, and hence the error
\(\delta \lcal(\Delta, \ts)\), which is dominated by the quadratic term, can capture the curvature
about \(\ts\).</p>

<p>As such, one way to show that \(\lcal\) has good curvature about \(\ts\) is to show that
\(\delta \lcal(\Delta, \ts) \geq \kappa \|\Delta \|^2\) holds for all \(\Delta\) in
a neighborhood of \(\ts\). This is because we are enforcing a lower bound on its quadratic growth.</p>

<p>This leads us to the definition of restricted strong convexity:</p>

<div class="definition">
    <div class="theorem-title">Definition
        
        
            (Restricted Strong Convexity)
        
    </div>
    <div class="theorem-contents">
        
    The loss function satisfies a <i>restricted strong convexity</i> (RSC)
    condition with curvature \( \kl &gt; 0 \) and tolerance function \( \tl \) if
    \begin{align*}
        \delta \lcal(\Delta, \ts) \geq \kl \| \Delta \|^2 - \tl^2(\ts)
    \end{align*}
    for all \( \Delta \in \ctriplet \).
  
    </div>
</div>

<p>We only need to consider error terms \(\Delta \in \ctriplet\), since Lemma \ref{lemma:1}
guarantees us that the error term will only lie in that set.</p>

<p>In many statistical models, restricted strong convexity holds with \(\tl = 0\), however, it is required in more general settings, such as generalized linear models.</p>

<h1 id="proof-of-theorem-1">Proof of Theorem 1</h1>
<p>We can now state and prove the main result of the paper.
This will hold under the decomposability of the regularizer (G1), and the
restricted strong convexity of the loss function (G2).</p>

<ul>
  <li>
    <p><strong>(G1)</strong>
      The regularizer \(\rcal\) is a norm and is decomposable
      with respect to the subspace pair \((\mcal, \mocalp)\), where \(\mcal \sse \mocalp\).</p>
  </li>
  <li>
    <p><strong>(G2)</strong>
      The loss function \(\lcal\) is convex and differentiable, and satisfies restricted strong convexity
      with curvature \(\kl\) and tolerance \(\tl\).</p>
  </li>
</ul>

<div class="theorem" id="thm-1">
    <div class="theorem-title">Theorem
        
            1 in (Negahban et al., 2009)
        
        
            (Bounds for General Models)
        
    </div>
    <div class="theorem-contents">
        
      Under conditions (G1) and (G2),
    consider the convex optimization problem (\ref{eq:opt})
    based on a strictly positive positive regularization constant
    \( \lambda_n \geq 2 \rs (\nabla \lcal (\ts)) \). Then any optimal solution
    \( \thatlambda \) to the convex program (\ref{eq:opt}) satisfies the bound
    \begin{align*}
        \| \thatlambda - \ts \|^2 \leq 9 \frac{\lambda_n^2}{\kl^2} \Psi^2(\mocal)
        + \frac{\lambda_n}{\kl} \left( 2 \tl^2 (\ts) + 4 \rcal (\ts_{\mcal^{\perp}}) \right).
    \end{align*}
  
    </div>
</div>

<p>We will rely on the following lemmas that will be stated without proof due to space constraints:</p>

<div class="lemma">
    <div class="theorem-title">Lemma
        
            3 in (Negahban et al., 2009)
        
        
            (Deviation Inequalities)
        
    </div>
    <div class="theorem-contents">
        
    For any decomposable regularizer and \( p \)-dimensional
    vectors \( \ts \) and \( \Delta \), we have
    \begin{align*}
        \rcal(\ts + \Delta) - \rcal(\ts) \geq
        \rcal(\Delta_{\mocalp}) - \rcal(\Delta_{\mocal}) - 2 \rcal(\ts_{\mcal^{\perp}}).
    \end{align*}
    Moreover, as long as \( \lambda_n \geq 2 \rs (\nabla \lcal(\ts)) \) and \( \lcal \) is convex, we have
    \begin{align*}
        \lcal(\ts + \Delta) - \lcal(\ts) \geq - \frac{\lambda_n}{2} [\rcal(\Delta_{\mocal}) + \rcal(\Delta_{\mocalp})].
    \end{align*}
  
    </div>
</div>

<div class="lemma">
    <div class="theorem-title">Lemma
        
            4 in (Negahban et al., 2009)
        
        
    </div>
    <div class="theorem-contents">
        
    If \( \fcal(\Delta) &gt; 0 \) for all vectors \( \Delta \in \mathbb{K}(\delta) \), then
    \( \| \hd \| \leq \delta \).
  
    </div>
</div>

<p>Note that this was similar to our previous analysis on restricted strong
convexity where we only really need to consider error terms restricted to
\(\ctriplet\) due to <a href="#lemma-1">Lemma 1</a>.  Therefore, it suffices to show
\(\fcal(\Delta) &gt; 0\) to obtain a bound on \(\| \hd \| = \| \thatlambda - \ts\|\), 
which completes the proof of Theorem 1.</p>

<p>Define \(\fcal : \mathbb{R}^p \to \mathbb{R}\) by</p>

\[\begin{align}
    \fcal(\Delta) \coloneqq \lcal(\ts + \Delta) - \lcal(\ts) + \lambda_n \left\{
    \rcal(\ts + \Delta) - \rcal(\ts)
    \right\},
\end{align}\]

<p>and define the set</p>

\[\begin{align}
    \mathbb{K}(\delta) \coloneqq \ctriplet \cap \left\{ \| \Delta \| = \delta \right\}.
\end{align}\]

<p>Take any \(\Delta \in \kbb\). Then</p>

\[\begin{align}
    \fcal(\Delta)
    =    &amp; \lcal(\ts + \Delta) - \lcal(\ts) + \lambda_n \left\{
    \rcal(\ts + \Delta) - \rcal(\ts) \right\} \tag{by definition} \\
    \geq &amp; \langle  \nabla \lcal (\ts), \Delta \rangle + \kl \| \Delta \|^2 - \tl^2(\ts) + \lambda_n \left\{
    \rcal(\ts + \Delta) - \rcal(\ts) \right\} \\
    &amp; \qquad \text{(by restricted strong convexity:
        \(\delta \lcal(\Delta, \ts) \geq \kl \| \Delta \|^2 - \tl^2(\ts)\),} \\
    &amp; \qquad \text{ and
    \( \delta \lcal(\Delta, \ts) = \lcal(\ts + \Delta) - \lcal(\ts) -
        \dotprod{\nabla \lcal(\ts)}{\Delta} \) ) } \\
    \geq &amp; \langle  \nabla \lcal (\ts), \Delta \rangle + \kl \| \Delta \|^2 - \tl^2(\ts) + \lambda_n \left\{
    \rcal(\Delta_{\mocalp}) - \rcal(\Delta_{\mocal}) - 2 \rcal(\ts_{\mcal^{\perp}})
    \right\} \\
    &amp; \qquad \text{(by Lemma 3)}.
    \label{thm-deriv:1}
\end{align}\]

<p>We lower bound the first term as
\(\langle  \nabla \lcal (\ts), \Delta \rangle \geq - \frac{\lambda_n}{2}
    \rcal(\Delta)\):</p>

\[\begin{align}
    | \langle  \nabla \lcal (\ts), \Delta \rangle |
    \leq                                             &amp; \rs(\nabla \lcal(\ts)) \rcal(\Delta) &amp; \text{(Cauchy-Schwarz using dual norms \( \rcal \) and \( \rs \))} \\
    \leq                                             &amp; \frac{\lambda_n}{2} \rcal(\Delta) &amp; \text{Theorem 1 assumption: \( \lambda_n \geq 2 \rs (\nabla \lcal(\ts)) \))},
\end{align}\]

<p>and hence,</p>

\[\begin{align}
    \langle  \nabla \lcal (\ts), \Delta \rangle \geq &amp; - \frac{\lambda_n}{2}
    \rcal(\Delta).
\end{align}\]

<p>So applying to (\ref{thm-deriv:1}),</p>

\[\begin{align}
    \fcal(\Delta)
    \geq &amp; \kl \| \Delta \|^2 - \tl^2(\ts) + \lambda_n \left\{
    \rcal(\Delta_{\mocalp}) - \rcal(\Delta_{\mocal}) - 2 \rcal(\ts_{\mcal^{\perp}})
    \right\} - \frac{\lambda_n}{2} \rcal(\Delta)                                                                                                                                       \\
    \geq &amp; \kl \| \Delta \|^2 - \tl^2(\ts) + \lambda_n \left\{
    \rcal(\Delta_{\mocalp}) - \rcal(\Delta_{\mocal}) - 2 \rcal(\ts_{\mcal^{\perp}})
    \right\} - \frac{\lambda_n}{2} (\rcal(\Delta_{\mocalp}) + \rcal(\Delta_{\mocal})) \\
    &amp; \qquad \text{(Triangle inequality: \( \rcal(\Delta) \leq \rcal(\Delta_{\mocalp}) + \rcal(\Delta_{\mocal}) \))} \\
    =    &amp; \kl \| \Delta \|^2 - \tl^2(\ts) + \lambda_n \left\{
    \frac{1}{2}\rcal(\Delta_{\mocalp}) -
    \frac{3}{2}\rcal(\Delta_{\mocal}) - 2 \rcal(\ts_{\mcal^{\perp}})
    \right\} \\
    &amp; \qquad \text{(Moving terms in)} \\
    \geq &amp; \kl \| \Delta \|^2 - \tl^2(\ts) + \lambda_n \left\{
    -
    \frac{3}{2}\rcal(\Delta_{\mocal}) - 2 \rcal(\ts_{\mcal^{\perp}})
    \right\} \\
    &amp; \qquad \text{(Norms always non-negative)} \\
    = &amp; \kl \| \Delta \|^2 - \tl^2(\ts) - \frac{\lambda_n }{2} \left\{
    3 \rcal(\Delta_{\mocal}) + 4 \rcal(\ts_{\mcal^{\perp}})
    \right\} \label{eq:r-delta-lb} .
\end{align}\]

<p>To bound the term \(\rcal(\Delta_{\mocal})\),
recall the definition of subspace compatibility:</p>

\[\begin{align}
    \varPsi (\mcal) \coloneqq \sup_{u \in \mcal \setminus \left\{ 0 \right\}} \frac{\rcal(u)}{\| u \|}, \label{eq:r-delta-ub}
\end{align}\]

<p>and hence</p>

\[\begin{align}
    \rcal(\Delta_{\mocal}) \leq \varPsi(\mocal) \| \Delta_{\mocal} \|.
\end{align}\]

<p>To upper bound \(\| \Delta_{\mocal} \|\), we have</p>

\[\begin{align}
    \| \Delta_{\mocal} \|
        &amp; = \| \Pi_{\mocal} (\Delta) - \Pi_{\mocal}(0) \| &amp; \text{(Since \(0 \in \mocal \), \( \Pi_{\mocal}(0) = 0 \)) }     \\
        &amp; \leq \| \Delta - 0 \| &amp; \text{(Projection operator is non-expansive, see Equation \ref{eq:non-expansive})} \\
        &amp; = \| \Delta \|,
\end{align}\]

<p>which substituting into Equation (\ref{eq:r-delta-ub}) gives</p>

\[\begin{align}
    \rcal(\Delta_{\mocal}) \leq \varPsi(\mocal) \| \Delta \|.
\end{align}\]

<p>Now we can use this result to lower bound
Equation \ref{eq:r-delta-lb}:</p>

\[\begin{align}
    \fcal (\Delta)
    \geq &amp; \kl \| \Delta \|^2 - \tl^2(\ts) - \frac{\lambda_n }{2} \left\{
    3 \varPsi(\mocal) \| \Delta \|
    + 4 \rcal(\ts_{\mcal^{\perp}})
    \right\}. \label{eq:strict-psd}
\end{align}\]

<p>The RHS of the inequality in Equation \ref{eq:strict-psd} has a strictly
positive definite quadratic form in \(\| \Delta \|\), and hence by taking
\(\| \Delta \|\) large, it will be strictly positive.
To find such a sufficiently large \(\| \Delta \|\), write</p>

\[\begin{align}
    a &amp; = \kl,                                                     \\
    b &amp; = \frac{3\lambda_n}{2} \varPsi (\mocal),                  \\
    c &amp; = \tau_{\lcal}^2 (\ts) + 2 \lambda_n \rcal(\ts_{\mcalp}), \\
\end{align}\]

<p>such that we have</p>

\[\begin{align}
    \fcal (\Delta)
        &amp; \geq a \| \Delta \|^2 - b \| \Delta \| - c.
\end{align}\]

<p>Then the square of the rightmost intercept is given by the squared quadratic formula</p>

\[\begin{align}
    \| \Delta \|^2
        &amp; = \left( \frac{-(-b) + \sqrt{b^2 - 4a(-c)}}{2a} \right)^2                                                 \\
        &amp; = \left( \frac{b + \sqrt{b^2 + 4ac}}{2a} \right)^2                                                 \\
        &amp; \leq \left( \frac{\sqrt{b^2 + 4ac}}{a} \right)^2 &amp; \text{($b \leq \sqrt{b^2 + 4ac}$)}                                              \label{eq:coarse-bound}  \\
        &amp; = \frac{b^2 + 4ac}{a^2}                                                 \\
        &amp; = \frac{9 \lambda_n^2 \varPsi^2 (\mocal)}{4 \kl^2}
    + \frac{ 4 \tau_{\lcal}^2 (\ts) + 8 \lambda_n \rcal(\ts_{\mcalp}) }{\kl}. &amp; \text{(Substituting in \(a, b, c\))} \\
\end{align}\]

<p>In <a href="https://arxiv.org/abs/1010.2731">(Negahban et al., 2009)</a>, they were able to show an upper bound of</p>

\[\begin{align}
    \| \Delta \|^2
        &amp; \leq \frac{9 \lambda_n^2 \varPsi^2 (\mocal)}{\kl^2} +
    \frac{\lambda_n}{\kl} \left\{
    2\tau_{\lcal}^2 (\ts) + 4 \rcal(\ts_{\mcalp})
    \right\}, \label{eq:ub}
\end{align}\]

<p>but I did not manage to figure out how they managed to produce a \(\lambda_n\)
term beside the \(\tl^2(\ts)\) term. All other differences are just 
constant factors. It may be due to an overly coarse
bound on my end applied in Equation \ref{eq:coarse-bound}, but it
is unclear to me how the \(\lambda_n\) term can be applied on only
the \(\tl^2(\ts)\) term without affecting the \(\rcal(\ts_{\mcalp})\) term.</p>

<p>With Equation \ref{eq:ub}, we can hence apply Lemma 4 in <a href="https://arxiv.org/abs/1010.2731">(Negahban et al., 2009)</a>
to obtain the desired result that</p>

\[\begin{align}
    \| \thatlambda - \ts \|^2 \leq 9 \frac{\lambda_n^2}{\kl^2} \Psi^2(\mocal)
    + \frac{\lambda_n}{\kl} \left( 2 \tl^2 (\ts) + 4 \rcal (\ts_{\mcal^{\perp}}) \right).
\end{align}\]

<p>This concludes the proof.</p>

<h1 id="conclusion">Conclusion</h1>
<p>In the <a href="#proof-of-theorem-1">proof of Theorem 1</a>, we saw how
the bound is derived from the two key ingredients of the decomposability
of the regularizer, and restricted strong convexity of the loss function.
The decomposability of the regularizer allowed us to ensure that the
error vector \(\hd\) will stay in the set \(\ctriplet\). This condition
is then required in Lemma 4 of <a href="https://arxiv.org/abs/1010.2731">(Negahban et al., 2009)</a>, which allows us
to bound \(\| \hd \|\) given that \(\fcal(\Delta) &gt; 0\). In one of the
steps where we were lower bounding \(\fcal(\Delta)\) in the proof,
we made use of the properties of restricted strong convexity.</p>

<p><a href="#thm-1">Theorem 1</a> provides a family of bounds for each decomposable
regularizer under the choice of \((\mcal, \mocalp)\).
The authors of <a href="https://arxiv.org/abs/1010.2731">(Negahban et al., 2009)</a> were able to use
<a href="#thm-1">Theorem 1</a> to rederive both existing known results,
and also derive new results on low-rank matrix estimation using the nuclear
norm, minimax-optimal rates for noisy matrix completion, and noisy matrix
decomposition. The reader is encouraged to refer to <a href="https://arxiv.org/abs/1010.2731">(Negahban et al., 2009)</a>
for more details on the large number of corrollaries of <a href="#thm-1">Theorem 1</a>.</p>

<h1 id="acknowledgments">Acknowledgments</h1>
<p>I would like to thank my dear friend <a href="https://www.linkedin.com/in/josh-abrams-78a4a6134/">Josh
Abrams</a>
for helping to review and provide valuable suggestions for this post!</p>

<h1 id="citations">Citations</h1>
<ol>
  <li>Negahban, S., Yu, B., Wainwright, M. J., and Ravikumar, P. <a href="https://proceedings.neurips.cc/paper_files/paper/2009/file/dc58e3a306451c9d670adcd37004f48f-Paper.pdf">A unified
framework for high-dimensional analysis of m-estimators with decomposable
regularizers</a>.
In Bengio, Y., Schuurmans, D., Lafferty, J., Williams, C., and Culotta, A.
(eds.), Advances in Neural Information Processing Systems, volume 22. Curran
Associates, Inc., 2009. 
URL https://proceedings.neurips.cc/paper_files/paper/2009/file/dc58e3a306451c9d670adcd37004f48f-Paper.pdf.</li>
</ol>]]></content><author><name>fanpu</name></author><category term="statistics" /><category term="machine-learning" /><summary type="html"><![CDATA[Imagine doing high-dimensional statistical inference, but instead of repeatedly studying different settings with specific low-dimensional constraints (such as linear regression with sparsity constraints, or estimation of structured covariance matrices), there is a method for performing a unified analysis using appropriate notions. Well, you're in luck! 'A Unified Framework for High-Dimensional Analysis of \( M \)-Estimators with Decomposable Regularizers' by Negahban, Ravikumar, Wainwright, and Yu shows that the \( \ell_2 \) difference between any regularized \(M\)-estimator and its true parameter can be bounded if the regularization function is decomposable, and the loss function satisfies restricted strong convexity. The goal of this post is to provide intuition for the result and develop sufficient background for understanding the proof of this result, followed by a walkthrough of the proof itself.]]></summary></entry><entry><title type="html">The CMU Steam Tunnels and Wean 9</title><link href="https://fanpu.io/blog/2023/cmu-steam-tunnels/" rel="alternate" type="text/html" title="The CMU Steam Tunnels and Wean 9" /><published>2023-06-16T00:00:00+00:00</published><updated>2023-06-16T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/cmu-steam-tunnels</id><content type="html" xml:base="https://fanpu.io/blog/2023/cmu-steam-tunnels/"><![CDATA[<p>If you’re curious about the infamous steam tunnels at CMU, or what the views
from the roof of Wean Hall looks like, this is for you! The week after course
finals concluded, <a href="https://www.cmu.edu/student-affairs/slice/">CMU SLICE</a>
(Student Leadership, Involvement, and Civic Engagement) organized an Underground
Steam Tunnels Tour as a Senior Week event. I was technically not
a senior as I am a graduate student, but they were nice enough to let me join.</p>

<p>Before I continue, let me warn readers that you are not allowed to enter the
steam tunnels by yourself. Please sign up for an official tour by SLICE that
will be led by a facilities engineer. From <a href="https://www.cmu.edu/student-affairs/theword/community-policies/steam-tunnels.html">The Word Student
Handbook</a>:</p>

<blockquote class="block-danger">
  <h4 id="steam-tunnels">Steam Tunnels</h4>
  <p>Because of the danger to all who enter them, the steam tunnels are locked and
anyone found in the tunnels will be subject to serious disciplinary action
and/or criminal action. The University Police are responsible for keeping the
tunnels locked and apprehending anyone who trespasses in them.</p>
</blockquote>

<h1 id="the-steam-tunnels">The Steam Tunnels</h1>
<p>We met at the fence, and all of us had to sign a waiver and don a helmet (the
same white helmet that was used by builders during Spring Carnival booth).</p>

<p>We proceeded to the basement of Margaret Morrison Hall, and the engineer guiding
the expedition shared some history about how the Margaret Morrison basement was
enhanced to be flood-resistant after a flooding incident a few decades ago
caused water to also flood into the steam tunnels.</p>

<p>We were warned that the tunnels will be hot and claustrophobic, that we should
not touch any pipes as they will be extremely hot, and to not poke at any
asbestos for obvious reasons.  He then unlocked an unmarked door, and let us
into the tunnels proper:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/cmu_steam_tunnels/main_tunnel.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Inside the steam tunnel!
    </figcaption>
</figure>

<p>It was initially still quite cool near the door, but the temperature
began rising as we went further in. Some sections of the pipes were
hissing and you could really feel the warmth emanating from them.
At some point I was slightly afraid that a pipe beside me might burst.</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/cmu_steam_tunnels/phone_box.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      A phone box in the tunnel. Hopefully no one ever had to use it.
    </figcaption>
</figure>

<p>At some point, there was a fork where the tunnel on the left fork became very
short and narrow. We took the right fork.</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/cmu_steam_tunnels/side_tunnel.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      The short and narrow left fork of the tunnel
    </figcaption>
</figure>

<p>It was generally quite well-lit, until we were brought to
a section of the tunnel where we had to ascend a rusty ladder
to reach a cavern, which was unlit. It was known as the
CFA cavern as it is located right under the steps of CFA:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/cmu_steam_tunnels/cfa_cavern.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      The CFA cavern, with flash photography
    </figcaption>
</figure>

<p>Apparently at some point in the past, a very resourceful CFA student
decided to make this their home. Not only was rent cheap (free!), 
but it was also very close to the CFA building! However, they were
found by campus police and booted out.</p>

<p>I would not say that it was the most ideal living arrangement. There were
plastic bottles strewn everywhere, and stalactites growing down from the
ceiling. The air was very damp and musty, and would probably do something bad to
your lungs if you stayed in there long enough. It was surprisingly much cooler
than the steam tunnels right below it though.</p>

<p>We then went back down into the tunnels, and continued on:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/cmu_steam_tunnels/another_tunnel.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      More tunnels!
    </figcaption>
</figure>

<p>As it got close to the end of the tunnels, we were each handed chalk 
that can be used for leaving our mark in the tunnel. 
Since public vandalism is <a href="https://en.wikipedia.org/wiki/Vandalism_Act#Michael_Fay_(1994)">punishable by
caning</a> in my
home country, of course I was not going to pass on
this wonderful opportunity to defile the steam tunnels to
my heart’s content:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/cmu_steam_tunnels/graffiti.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      SLICE-sanctioned vandalism
    </figcaption>
</figure>

<p>We then emerged from an exit deep inside Doherty Hall, which
was nice as it was beginning to get rather uncomfortable and claustrophobic. Whew!</p>

<h1 id="roof-of-wean">Roof of Wean</h1>
<p>If you thought there were only 8 levels in Wean, then you
will learn something new today. We took the freight elevator
from the corner of Wean to floor PH (penthouse?), AKA Wean 9.</p>

<p>Wean 9 was essentially a huge storeroom for CMU FMS (Facility Management
Services). There were all sorts of supplies and tools,
and even spare doors for classrooms. It made me realize just how much
maintenance it took to operate a campus.</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/cmu_steam_tunnels/wean_9.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Our guide leading us through Wean 9
    </figcaption>
</figure>

<p>We were finally brought to a door that led to the roof of Wean Hall, and had to
adjust our eyes for a few seconds to the new blinding sunlight.
It was beautiful!</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/cmu_steam_tunnels/hammerschlag.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      A majestic view of Hammerschlag Hall. I wish I could take my graduation pictures from here.
    </figcaption>
</figure>

<p>Everyone got busy snapping photos, myself included. To my knowledge this is the
only place on campus where you can take a side-by-side photo with the
Hammerschlag radio tower:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/cmu_steam_tunnels/roof_photo.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      The Hammerschlag tower, which houses the Carnegie Tech Radio Club
  (W3VC) and contains both repeaters and transmitters.
    </figcaption>
</figure>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/cmu_steam_tunnels/cic.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      An interesting view of CIC and Tepper
    </figcaption>
</figure>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/cmu_steam_tunnels/gates.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Gates, which is usually perceived to tower over all other campus buildings in its vicinity, look short from here
    </figcaption>
</figure>

<p>There was some open space on the roof, and I thought it would be pretty cool if
they opened an open-air cafe here. It has pretty nice panoramic views of the entire campus.</p>

<p>And that’s it for the tour!</p>

<h1 id="acknowledgments">Acknowledgments</h1>
<p>I would like to thank <a href="https://www.cmu.edu/student-affairs/slice/">SLICE</a> for organizing this trip, my friend <a href="https://www.linkedin.com/in/justin-sun-92b691169/">Justin
Sun</a> who also went on this
little adventure with me for proofreading this post, and <a href="https://www.linkedin.com/in/joseph-x-li/">Joey Li</a>
for pointing out a mistake in the post, where I previously erroneously claimed
that WRCT 88.3FM was also broadcast from Hammerschlag tower.</p>]]></content><author><name>fanpu</name></author><category term="general" /><category term="cmu" /><summary type="html"><![CDATA[If you're curious about the infamous steam tunnels at CMU, or what the views from the roof of Wean Hall looks like, this post is for you!]]></summary></entry><entry><title type="html">CMU 15712 Advanced Operating Systems and Distributed Systems Course Review</title><link href="https://fanpu.io/blog/2023/advanced-operating-systems-course-review/" rel="alternate" type="text/html" title="CMU 15712 Advanced Operating Systems and Distributed Systems Course Review" /><published>2023-06-09T00:00:00+00:00</published><updated>2023-06-09T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/advanced-operating-systems-course-review</id><content type="html" xml:base="https://fanpu.io/blog/2023/advanced-operating-systems-course-review/"><![CDATA[<p>This semester (Spring 2023), I took <a href="https://www.cs.cmu.edu/~15712/">15-712 Advanced Operating Systems and
Distributed Systems</a> under professor <a href="http://www.cs.cmu.edu/~gibbons/">Phil
Gibbons</a> and his TA and also PhD advisee <a href="http://nicebowlofsoup.com/">Val
Choung</a>.</p>

<p>This class exceeded my expectations significantly.
I found it especially meaningful and apt since this was my last systems class before I
graduate, and the topics and discussions from class helped to unify all the
systems concepts that I had learnt from previous classes into a nice package
informed by common underlying principles: from distributed systems, to
networking, databases, filesystems, operating systems, and even machine learning
systems.</p>

<h1 id="the-first-lecture">The First Lecture</h1>
<p>The first lecture went through 2 Wisdom Papers, which no one was expected
to have read yet as it was the first class. You can refer
to the <a href="https://www.cs.cmu.edu/~15712/lectures/01-intro.pdf">slides here</a> if you are curious.</p>

<p>The first paper, <a href="https://www.cs.cmu.edu/~15712/papers/mythicalmanmonth00fred.pdf">Mythical Man-Month: Essays on Software
Engineering</a>
is a book by Turing-award winner Fred Brooks. It is about many of his observations
and principles on software engineering based on his own vast experiences. What
really brought it home to me was that a couple of them were also things that I
had some suspicions about previously, but never really thought it was universally
applicable, and thought they were simply artifacts of the way I approached things.</p>

<p>For instance, one of the principles is “Plan to Throw One Away”, meaning that
one should first build a worthwhile system in a short amount of time, and then
re-build a better second version with the benefit of hindsight. This is because
one would end up having to re-build the system anyway after being confronted
with change and feedback, and also due to the following observation on program
maintenance:</p>

<blockquote>
  <p>“Program maintenance is an entropy-increasing
process, and even its most skillful execution only
delays the subsidence of the system into unfixable
obsolescence”</p>
</blockquote>

<p>This had many parallels with my own experiences. For instance, my group ended up
having 4 major re-writes of our kernel during 15-410, and I also did a complete
re-write of my CloudFS filesystem for my 18-746 project. Similarly, many of my
internship projects were also re-writes and improvements on design of existing
systems that had accumulated too much technical debt. It does seem
a lot more reasonable to plan for this eventual change to begin with.</p>

<p>The paper also contained a lot of other great advice, such as the
importance of conceptual integrity to separate architecture
from implementation, structuring a team in a “surgical” fashion to drive software
development where the best programmer leads the most critical development
work like a surgeon and directs others on the other aspects, and of
course the famous Brook’s law:</p>

<blockquote>
  <p>“Adding manpower to a late
software project makes it later”</p>
</blockquote>

<p>The second paper, <a href="https://www.cs.cmu.edu/~15712/papers/hamming86.pdf">You and Your
Research</a> by Richard Hamming
(of Hamming code fame), talks about how to become a great scientist. 
The following two slides gives a good sense of the spirit of the paper:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/adv_os/slide_1.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      How to be a Great Scientist (1)
    </figcaption>
</figure>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/adv_os/slide_2.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      How to be a Great Scientist (2)
    </figcaption>
</figure>

<p>I mention the first lecture and the two papers that were discussed here not
simply because they were interesting, but because they helped to set the tone
and expectations for the rest of the semester going forward. The message is clear: this is going to be a practical and useful class that will help you on your journey to becoming great systems designers and researchers.</p>

<h1 id="course-content">Course Content</h1>

<p>The class took us on a whirlwind tour through many <a href="https://www.sigops.org/awards/hof/">SIGOPS
Hall of Fame papers</a>, which the award
description states was “instituted in 2005 to recognize the most influential
Operating Systems papers that were published at least ten years in the past”.
Reading through the papers helped to consolidate a lot of the knowledge that I
learned in previous systems classes, and it was cool to see how decades ago many
of these ideas that were once unappreciated or heavily criticized now form the
bedrock of many of the systems that we use today.</p>

<p>In addition to the Hall of Fame papers, there were also several relatively
recent papers that the course staff thought were conceptually interesting
and promising.</p>

<p>The following sections will go through each of the modules and
the required papers that you will read (refer to the <a href="https://www.cs.cmu.edu/~15712/syllabus.html">course website</a>
if you are also interested in the optional papers), and a short description
of what the paper is about so you can get a pretty good sense of what is
covered. A cool thing to note is that the scope of all the papers will
touch almost all the systems classes offered at CMU.</p>

<h2 id="part-1-concurrency-ordering-races">Part 1: Concurrency, Ordering, Races</h2>
<ul>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/birrell84.pdf">Implementing Remote Procedure Calls (Birrell’84), SigOps HoF paper</a> - introduced the now-standard design of RPC calls with interfaces and caller/callee stubs for distributed communication.</li>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/lamport78.pdf">Time, Clocks, and the Ordering of Events in a Distributed System (Lamport’78),	SigOps HoF paper</a> - introduced Lamport clocks, the foundation for ordering distributed systems today</li>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/chandy85.pdf">Distributed Snapshots: Determining Global States of Distributed Systems (Chandy’85), SigOps HoF paper</a> - how to snapshot a consistent global state in a distributed system</li>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/li19.pdf">Efficient Scalable Thread-Safety-Violation Detection (Li’19), SOSP’19 best paper</a> - using active testing to discover and reproduce concurrency bugs</li>
</ul>

<h2 id="part-2-file-systems-and-disks">Part 2: File Systems and Disks</h2>
<ul>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/mckusick84.pdf">A Fast File System for UNIX (McKusick’84), SigOps HoF paper</a> - addresses many of the problems
of the original Unix filesystem by introducing the Fast File System (FFS),
and many of its ideas are now staple in modern filesystems like the Linux <code class="language-plaintext highlighter-rouge">ext*</code> filesystems</li>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/howard88.pdf">Scale and Performance in a Distributed File System (Howard’88), SigOps HoF paper</a> - introduces the Andrew File System (AFS) that significantly improved on NFS in terms of scalability. AFS was developed at CMU and is still widely used today.</li>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/rosenblum92.pdf">The Design and Implementation of a Log-Structured File System (Rosenblum’92), SigOps HoF paper</a> - 
introduced log-structured filesystems that support high write throughput which addresses the problem of disk traffic being dominated by slow writes
on traditional filesystems</li>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/patterson88.pdf">A Case for Redundant Arrays of Inexpensive Disks (RAID) (Patterson’88), SigOps HoF paper</a> - introduced RAID, solved problem of how to get cheap fault tolerance</li>
</ul>

<h2 id="part-3-transactions-and-databases">Part 3: Transactions and Databases</h2>
<ul>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/kung81.pdf">On Optimistic Methods for Concurrency Control (Kung’81), SigOps HoF paper</a> - introduced optimistic concurrency control, now standard in many database environments
with low contention and high throughput requirements</li>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/franklin97.pdf">Concurrency Control and Recovery (Franklin’97)</a> - survey paper on concurrency
control and recovering from crashes in database systems (write-ahead logging, ARIES)</li>
</ul>

<h2 id="part-4-fault-tolerance">Part 4: Fault Tolerance</h2>
<ul>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/paxos-simple.pdf">Paxos (Lamport’01), SigOps HoF paper</a> - simplified version of his original theatrical <a href="https://www.cs.cmu.edu/~15712/papers/part-time-parliament.pdf">The Part-Time Parliament</a> paper that was mostly ignored, introduced how to get replicated logs
among unreliable (but not Byzantine) nodes</li>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/castro99.pdf">Practical Byzantine Fault Tolerance (Castro’99)</a> - distributed consensus but in the
presence of Byzantine faults (i.e a fraction of the nodes can collude and behave maliciously)</li>
</ul>

<h2 id="part-5-os-kernels-and-virtual-machines">Part 5: OS Kernels and Virtual Machines</h2>
<ul>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/liedtke95.pdf">Microkernels (Liedtke’95), SigOps HoF paper</a> - the first demonstration of an
efficient microkernel designed with a very extreme minimality principle,
where as much OS functionality is moved outside of the microkernel
as possible, including even its memory manager, pagers, device drivers, software TLBs, etc.</li>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/klein09.pdf">seL4: Formal Verification of an OS Kernel (Klein’09), SigOps HoF paper</a> - first paper to perform a formal, machine-checked verification of a microkernel using the Isabelle/HOL theorem prover</li>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/waldspurger02.pdf">Memory Resource Management in VMware ESX Server (Waldspurger’02), SigOps HoF paper</a> - introduced many great ideas for hypervisor memory management, like memory ballooning, idle tax, and transparent page sharing that are now commonplace in modern virtual machines</li>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/clements15.pdf">The Scalable Commutativity Rule: Designing Scalable Software for Multicore Processors (Clements’15), SOSP’13 best paper</a> - addresses
the problem of deciding whether there exists a scalable implementation (with respect to number of processors) of a program based on a restricted form of commutativity of the interfaces that it uses
called SIM commutativity (<strong>S</strong>tate-dependent, <strong>I</strong>nterface-based, <strong>M</strong>onotonic)</li>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/baumann09.pdf">The Multikernel: A new OS architecture for scalable multicore systems (Baumann’09), SigOps HoF paper</a> - solves the problem 
of modern operating systems not being able to take advantage of the current trend of increasing core counts due to the inherent limitations of the shared-memory kernel design,
by instead re-framing the OS as a distributed system split among different cores with event-driven execution, replicated state, and a hardware-neutral structure</li>
</ul>

<h2 id="part-6-big-data-systems">Part 6: Big Data Systems</h2>
<ul>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/decandia07.pdf">Dynamo: Amazon’s Highly Available Key-value Store (DeCandia’07), SigOps HoF paper</a> - the secret behind how
Amazon can support very high availability with eventual consistency due to
extreme business requirements (i.e users should never fail to add an item to
their shopping carts), by incorporating established techniques like consistent
hashing, sloppy quorums, gossip-based membership protocols, etc</li>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/corbett12.pdf">Spanner: Google’s Globally-Distributed Database (Corbett’12), SigOps HoF paper</a> - built using lessons
from <a href="https://cloud.google.com/bigtable">Google Bigtable</a>, Spanner powers Google as their globally replicated transactional database system 
with 5 nines of availability with several novel ideas like TrueTime to quantify uncertainty in wall clock time and distributed transactions</li>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/qiao21.pdf">Pollux: Co-adaptive Cluster Scheduling for Goodput-Optimized Deep Learning (Qiao’21), OSDI’21 best paper</a> -
introduces a new notion of goodput that combines throughput and statistical efficiency to evaluate the performance of schedulers for training deep learning systems, 
with a practical implementation that optimizes both cluster-wide and per-job parameters called Pollux</li>
</ul>

<h2 id="part-7-emerging-platforms">Part 7: Emerging Platforms</h2>
<ul>
  <li><a href="https://www.cs.cmu.edu/~15712/papers/kim21.pdf">LineFS: Efficient SmartNIC Offload of a Distributed File System with Pipeline Parallelism (Kim’21), SOSP’21 best paper</a> - optimizing the performance of distributed file systems (DFS) by decomposing DFS operations into pipelined stages and offloading networked stages to a SmartNIC asynchronously</li>
</ul>

<h1 id="takeaways-from-the-class">Takeaways From The Class</h1>
<p>Here are my thoughts on the key takeaways from the class.</p>

<h2 id="class-discussion">Class Discussion</h2>
<p>As a seminar-based class, one of the most surprising things for me was how fun
and valuable the class discussions were.  It was especially enlightening to
hear the comments of Ph.D. students who are working in systems and other fields
in computer science, who often had very different critiques and opinions of
the papers than what I had come up with, which often led me to wonder how they
got their perspectives and what their background is like. 
This was particularly true when someone mentioned glaring deficiencies and
problems with the paper that I had completely not even thought of.</p>

<p>However, one thing that made me sad was that attendance in class
started to fall after the halfway point of the semester. This
included quite a few of the students who used to give very insightful
and interesting responses and so the diversity of perspectives of the
discussions as a whole suffered.</p>

<p>While attendance is not strictly enforced, actively participating in the
discussions and being engaged in lectures is one of the most valuable
takeaways from this class, and positively impacts not just you but also
your classmates, and so I would strongly encourage anyone interested in the
class to attend all the lectures that you can.</p>

<h2 id="tribal-knowledge">Tribal Knowledge</h2>
<p>Another aspect of the class that I really appreciated was how Phil taught us a
lot of the spirit and tribal knowledge of doing CS research during his lively
lectures. These were often presented as off-hand remarks while presenting the
context or background of a paper, and provided insight into the zeitgeist of the
time, the motivations and challenges that the paper authors faced, and what the
authors went on to do in the future based on the impact (or lack of impact at
that time) of their work.</p>

<p>As someone who has not done a long-term research project with a faculty member
but am thinking about possibly doing a Ph.D. in the future, all of these were
very valuable wisdom which are not things that you can pick up easily yourself
from reading past papers or books. In fact, it almost felt as if I had my own
advisor at times.</p>

<h2 id="witness-the-evolution-of-systems-research">Witness the Evolution of Systems Research</h2>
<p>As you read through the papers, you almost feel as if you are being put into the
driver’s seat and can see how systems research has matured and evolved over the
past few decades. Seminal papers of the past tackled the most
general problems, although many of them lacked implementations or proper benchmarks
that would surely be grounds to be red-flagged and rejected from any systems
conference today. Many of the more recent papers strive to anticipate and build
for future changes in the computation landscape, have solid replicable
implementations and evaluations, and are a lot more careful about anticipating
and providing rebuttals for criticisms.</p>

<h2 id="personal-attention-for-projects">Personal Attention for Projects</h2>
<p>I also really appreciated the personal attention that Phil and Val gave to us
by meeting with us every other week for our course projects. 
This is especially so if you consider that many advisors already have trouble
meeting their own Ph.D. students for an hour a week, whereas in this case the
course staff dedicated half an hour every two weeks for every single group in
the class (there were around 10), which I thought was some real dedication.
I will admit that I did not live up to my end of the bargain by spending
as much time on the project as I would have wanted to (compared to when I took 15-410).
One could always give excuses for anything so you don’t have to listen to mine,
but if I had to reflect on it, it was due to a combination of high
workloads from other classes, the fact that this was not the highest priority for
the members in our group (my project partners were both quite busy with
their own research and I was busy with other classes), and some unexpected
obstacles in our project that forced us back to the drawing boards a few times
(our project interim report was drastically different from our initial
proposal).</p>

<h2 id="fantastic-course-staff">Fantastic Course Staff</h2>
<p>Phil is a really good lecturer. He is very clear, the class pacing is great, and
the lecture slides are polished. He is very approachable and respectful
towards students, and puts in great effort to give a good and satisfying answer
to every question.</p>

<p>Feedback for projects is prompt (there was no feedback for the paper summaries),
and the midterms were graded fairly quickly.</p>

<p>Overall it is clear that the class is pedagogically mature and has benefited
from many rounds of feedback during past iterations.  It is rich in content,
is accessible and yet challenging to students from a wide range of backgrounds,
and will prepare one well for building systems in the future, be it in 
academia or industry.</p>
<h1 id="course-structure">Course Structure</h1>
<p>There are three main components to the class: paper summaries,
projects, and exams.</p>

<h2 id="1-paper-summaries">1. Paper Summaries</h2>
<p>Before each lecture, the class is assigned a required reading and an optional reading. A paper summary of the required reading must be submitted before
the class, which will discuss both readings.</p>

<p>The paper summary will contain 3 things:</p>
<ol>
  <li>The 3 most important things in the paper,</li>
  <li>1 most glaring deficiency of the paper (even highly celebrated papers have faults!),</li>
  <li>A conclusion on how you will use lessons from this paper to inform you on how
you will build systems in the future.</li>
</ol>

<p>It took me on average 2-4 hours to read each paper and around 15 minutes for the summary.</p>

<p>The lectures for this class are front-loaded, meaning that during the first
two-thirds of the semester, you will meet 3 times a week for 80 minutes each,
while there will be no lectures at all during the final third of the semester,
and so “on average” throughout the semester you will meet twice a week. This is so that
students have enough knowledge and content to begin working on their course
projects early on in the semester.</p>

<p>There will be 3 short breaks in each lecture, where all students will get into
breakout groups and share and discuss among themselves one of the prompts
for the paper based on their paper summaries. Afterwards, all groups
are invited to share what they thought.</p>

<p>Reading and writing the paper summaries are the only “homework” you will get in
this class.</p>

<h2 id="2-course-project">2. Course Project</h2>
<p>There is also a semester-long course project with a significant systems
component in groups of three. This will begin in earnest after a third of the
semester, and all the project groups met with Phil and the TA Val once every two
weeks.  The deliverables include a project proposal, an interim report, a final
presentation, and a final report. The course project will be the
largest constituent of your final grade.</p>

<h2 id="3-midterms">3. Midterms</h2>
<p>Finally, there are two midterm exams, which are taken during class time.
The first is taken in the middle of the semester, and the second is taken
after all lectures have concluded.</p>

<p>Each midterm will cover content from a shortlisted selection of 10
of the required readings. There will be 9 questions on the midterm,
which covers 9 of the 10 papers, and you are only required to answer 7 of
the problems.</p>

<p>The course staff will also provide two past year exams to practice on, though
some of the readings may have changed since.</p>

<p>It admittedly does seem quite daunting to have to study and be familiar with 10
papers spanning very different topics. I did not have time to actually re-read
all 10 papers to prepare for the midterm, and so the way I prepared was to go
through all the lecture slides again, re-read the most important sections of the
paper, and skim through the rest. Afterward, I attempted the past exams to fill
in any gaps that I may have missed. This strategy allowed me to do fairly well
on the exam.</p>

<h1 id="workload">Workload</h1>
<p>The class has a moderate workload for a systems class. Expect to spend 10-12 hours 
a week on the readings and paper summaries while lectures are ongoing, probably
a couple more hours once the projects get into motion midway through the
semester, and for it to consume a significant portion of your existence in the
last two weeks before the final presentations.</p>

<p>It is a far less demanding and stressful class than the legendary <a href="https://www.cs.cmu.edu/~410/">15-410/605
Operating System Design and Implementation</a> class, 
so don’t let the “advanced” in the course title scare you off from taking this class.
After all, most people taking this class are Ph.D. students who have their
own research to work on and can’t exactly spend all their time on courses,
unlike undergraduates.</p>

<h1 id="our-course-project-and-reflections">Our Course Project, and Reflections</h1>
<p>Our course project was on the automated optimal scheduling of data in dynamic neural
networks over heterogeneous GPUs for inference tasks in a pipeline-parallelism
fashion. This means that when a model is too large to fit on a single GPU
but instead has to be distributed across multiple GPUs, we aim to solve the problem
of finding the optimal way to perform this split in the presence of dynamism
in the network. In our case we focused on input dynamism, meaning that the
sizes of the inputs can vary, which can result in different execution times in different
segments of the network. We built a system called <code class="language-plaintext highlighter-rouge">DynPartition</code>, 
a reinforcement-learning based scheduler that uses Deep-Q Learning to learn
the optimal way of performing this split.</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/adv_os/presentation.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Giving our final project presentation in the Panther Hollow conference room at CIC
    </figcaption>
</figure>

<p>We had some positive empirical results on our benchmarks, but will require
additional future work to verify the generality of these results. Overall, I
thought it was a great experience working with PhD students and to learn from
their working styles and approach to solving problems. It was also really cool
to see the breadth and depth of projects presented by the other teams during the
final presentation, which was structured like a conference.</p>

<h1 id="is-this-class-suitable-for-me">Is This Class Suitable For Me?</h1>
<p>I cannot recommend this course enough to anyone who has sufficient
background and have an interest in building systems, or systems research.</p>

<p>You should be sufficiently prepared for the class if you have taken
<a href="https://www.cs.cmu.edu/~410/">15-410 Operating System Design and Implementation</a>,
or any other equivalent rigorous operating systems design class in your undergraduate college.
Most papers draw heavily on low-level concepts from operating systems and assume
that the reader is familiar with them, and therefore familiarity with these ideas
is critical to understanding the papers.</p>

<p>I don’t feel any of the other classes are as critical, as any new concepts can
be picked up relatively easily. For instance, a good grasp of considerations
involved in operating systems design means that it’s not too hard to also
understand the challenges involved in filesystems or virtual machine design.
Having taken other classes would definitely still help to make the papers more
approachable though. For instance, the Pollux paper was not very approachable for
people who did not have prior exposure to machine learning systems, which led to the
course staff deciding not to include that as one of the papers tested for the
second midterm.</p>

<p>When I took the class, all the students were either Masters or Ph.D. students.
Strong undergraduates with sufficient background would also definitely do well
in the class.</p>

<h1 id="why-i-took-this-class">Why I Took This Class</h1>
<p>I had to take a systems class this semester to fulfill my graduation
requirements for the MSCS program. I initially did include this class in my
shortlist of systems classes to take, but then thought it was just going to be a
paper reading class (not that I had been in one of such classes before, but it
just did not sound very interesting and felt like something I could do by myself
asynchronously after I graduate) and therefore was quite hesitant to take it.</p>

<p>As such, during registration week I settled on <a href="https://www.cs.cmu.edu/~418/">15-618 Parallel Computer Architecture and
Programming</a>,
since it included topics on GPU programming that aligned with my current
interests in machine learning. However, I did not feel like the class was
sufficiently challenging for me after the first lecture, as it was a bit too
slow-paced and simple for my liking as I already had exposure to most of the
topics from other system classes that I had taken. I decided to switch
to 15-712, and I knew immediately that it was the right class for me after the
first lecture.</p>

<p>In a sense, this class was a hidden gem and I was really glad that I ended up
taking it.</p>

<h1 id="acknowledgments">Acknowledgments</h1>
<p>I would like to express my gratitude to <a href="https://adbforlife.github.io/">Albert
Gao</a> for helping to proofread this article, who
took the class with me this semester.</p>]]></content><author><name>fanpu</name></author><category term="courses" /><category term="cmu" /><category term="systems" /><summary type="html"><![CDATA[15-712 Advanced OS was an excellent seminar-based graduate course that took us on a whirlwind tour through many of the most seminal SigOps Hall of Fame papers across several systems domains. It will prepare you to be a great systems designer and researcher. In this post, I will share my experience in the class, the course structure and content, what I thought were the biggest takeaways, and who this class might be suitable for.]]></summary></entry><entry><title type="html">Score-Based Diffusion Models</title><link href="https://fanpu.io/blog/2023/score-based-diffusion-models/" rel="alternate" type="text/html" title="Score-Based Diffusion Models" /><published>2023-06-07T00:00:00+00:00</published><updated>2023-06-07T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/score-based-diffusion-models</id><content type="html" xml:base="https://fanpu.io/blog/2023/score-based-diffusion-models/"><![CDATA[<p>\(\newcommand{\E}{\mathbb{E}}
    \newcommand{\bone}{\boldsymbol{1}}
    \newcommand{\bbeta}{\boldsymbol{\beta}}
    \newcommand{\bdelta}{\boldsymbol{\delta}}
    \newcommand{\bepsilon}{\boldsymbol{\epsilon}}
    \newcommand{\blambda}{\boldsymbol{\lambda}}
    \newcommand{\bomega}{\boldsymbol{\omega}}
    \newcommand{\bpi}{\boldsymbol{\pi}}
    \newcommand{\bphi}{\boldsymbol{\phi}}
    \newcommand{\bvphi}{\boldsymbol{\varphi}}
    \newcommand{\bpsi}{\boldsymbol{\psi}}
    \newcommand{\bsigma}{\boldsymbol{\sigma}}
    \newcommand{\btheta}{\boldsymbol{\theta}}
    \newcommand{\btau}{\boldsymbol{\tau}}
    \newcommand{\ba}{\boldsymbol{a}}
    \newcommand{\bb}{\boldsymbol{b}}
    \newcommand{\bc}{\boldsymbol{c}}
    \newcommand{\bd}{\boldsymbol{d}}
    \newcommand{\be}{\boldsymbol{e}}
    \newcommand{\boldf}{\boldsymbol{f}}
    \newcommand{\bg}{\boldsymbol{g}}
    \newcommand{\bh}{\boldsymbol{h}}
    \newcommand{\bi}{\boldsymbol{i}}
    \newcommand{\bj}{\boldsymbol{j}}
    \newcommand{\bk}{\boldsymbol{k}}
    \newcommand{\bell}{\boldsymbol{\ell}}
    \newcommand{\bm}{\boldsymbol{m}}
    \newcommand{\bn}{\boldsymbol{n}}
    \newcommand{\bo}{\boldsymbol{o}}
    \newcommand{\bp}{\boldsymbol{p}}
    \newcommand{\bq}{\boldsymbol{q}}
    \newcommand{\br}{\boldsymbol{r}}
    \newcommand{\bs}{\boldsymbol{s}}
    \newcommand{\bt}{\boldsymbol{t}}
    \newcommand{\bu}{\boldsymbol{u}}
    \newcommand{\bv}{\boldsymbol{v}}
    \newcommand{\bw}{\boldsymbol{w}}
    \newcommand{\bx}{\boldsymbol{x}}
    \newcommand{\by}{\boldsymbol{y}}
    \newcommand{\bz}{\boldsymbol{z}}
    \newcommand{\bA}{\boldsymbol{A}}
    \newcommand{\bB}{\boldsymbol{B}}
    \newcommand{\bC}{\boldsymbol{C}}
    \newcommand{\bD}{\boldsymbol{D}}
    \newcommand{\bE}{\boldsymbol{E}}
    \newcommand{\bF}{\boldsymbol{F}}
    \newcommand{\bG}{\boldsymbol{G}}
    \newcommand{\bH}{\boldsymbol{H}}
    \newcommand{\bI}{\boldsymbol{I}}
    \newcommand{\bJ}{\boldsymbol{J}}
    \newcommand{\bK}{\boldsymbol{K}}
    \newcommand{\bL}{\boldsymbol{L}}
    \newcommand{\bM}{\boldsymbol{M}}
    \newcommand{\bN}{\boldsymbol{N}}
    \newcommand{\bP}{\boldsymbol{P}}
    \newcommand{\bQ}{\boldsymbol{Q}}
    \newcommand{\bR}{\boldsymbol{R}}
    \newcommand{\bS}{\boldsymbol{S}}
    \newcommand{\bT}{\boldsymbol{T}}
    \newcommand{\bU}{\boldsymbol{U}}
    \newcommand{\bV}{\boldsymbol{V}}
    \newcommand{\bW}{\boldsymbol{W}}
    \newcommand{\bX}{\boldsymbol{X}}
    \newcommand{\bY}{\boldsymbol{Y}}
    \newcommand{\bZ}{\boldsymbol{Z}}
    \newcommand{\boldf}{\boldsymbol{f}}
    \newcommand{\bpi}{\boldsymbol{\pi}}
    \newcommand{\btheta}{\boldsymbol{\theta}}
    \DeclareMathOperator{\tr}{tr}
    \newcommand{\pdata}{p_{\text{data}}(\bx)}
    \newcommand{\st}{\mathbf{s}_\mathbf{\theta}}
    \newcommand{\xt}{\tilde{\bx}}
    \newcommand{\stx}{\mathbf{s}_\mathbf{\theta}(\bx)}
    \newcommand{\sdx}{\mathbf{s}_\text{data}(\bx)}
    \newcommand{\stxt}{\mathbf{s}_\mathbf{\theta}(\xt, \sigma)}
    \newcommand{\pv}{p_{\bv}}
    \newcommand{\score}{\nabla_\bx \log \pdata}
    \newcommand{\bov}{\bar{\beta}}\)
<em>Joint work with <a href="https://www.linkedin.com/in/owen-wang/">Owen Wang</a>.</em></p>

<p>There has recently been a flurry of work in score-based
diffusion models as part of the broader area of generative models.
This is due to the recent success of such score-based methods,
which has achieved results comparable to the state-of-the-art
of generative adversarial networks (GANs).</p>

<p>Past techniques in generative modeling have either relied on the
approximation of the partition function of the probability density, or the
combination of an implicit network representation of the probability density
and adversarial training.
The former suffers from having to either constrain the model
to make the partition function tractable, or otherwise relies on
approximations with surrogate losses that may be inaccurate,
and the latter suffers from training instability and mode collapse.</p>

<p>Score-based diffusion models try to address the cons of both approaches, and
instead, use score-matching to learn a model of the gradient of the log of the
probability density function.  This allows it to avoid computing the partition
function completely.</p>

<p>One of the first such approaches that rely on using score-matching to
perform generative modeling does so by generating new samples via Langevin
dynamics <a href="https://arxiv.org/abs/1907.05600">(Song &amp; Ermon, 2019)</a>.
A key observation
is that naively applying score-matching is that the model of score function will
be inaccurate in areas of low density with respect to the data distribution,
which results in improper Langevin dynamics in low-density
areas. The solution that was proposed is the injection of noise into the data,
which provides
additional training signal and increases the dimensionality
of the data.</p>

<p>The next major step introduced in 
<a href="https://arxiv.org/abs/2011.13456">(Song et al., 2021)</a>
is to perturb the data using a diffusion process
which is a form of a stochastic differential equation (SDEs).
The SDE is then reversed using annealed Langevin dynamics
in order to recover the generative process, where the reversal
process makes use of score matching.</p>

<p>Other recent refinements that have been proposed include
re-casting the objective as a Schrödinger bridge problem,
which is an entropy-regularized optimal transport problem.
The advantage of this approach is that it allows for fewer
diffusion steps to be taken during the generative process.</p>

<h1 id="survey-of-results">Survey of Results</h1>

<p>We will be primarily focusing on the paper
<a href="https://arxiv.org/abs/1907.05600">Generative Modeling by Estimating Gradients of the Data Distribution (Song &amp; Ermon, 2019)</a>.</p>

<p>In this section, we provide the necessary background, provide
derivations for important results,
and explain the key ideas of score matching for diffusion
models as proposed in the papers.</p>

<h2 id="motivation-for-score-matching">Motivation for Score Matching</h2>

<h3 id="limitations-of-likelihood-based-approaches">Limitations of Likelihood-Based Approaches</h3>
<p>Score matching is motivated by the limitations of likelihood-based
methods. In likelihood-based methods, we use a parameterized model
\(f_\theta(\bx) \in \mathbb{R}\) and attempt it to recover the parameters \(\theta\) that best
explains the observed data. For instance, in energy-based models,
the probability mass function \(p_\theta(\bx)\) would be given as
\begin{align}
    p_\theta(\bx) = \frac{\exp(-f_\theta(\bx))}{Z_\theta},
\end{align}
where \(Z_\theta\) is the normalizing constant that causes the
distribution to integrate to 1, i.e
\begin{align}
    Z_\theta = \int \exp(-f_\theta(\bx)) \, d \bx.
\end{align}
The goal then is to maximize the log likelihood of the observed data \(\{\bx_i\}_i^N\),
given by
\begin{align}
    \max_\theta \sum_{i=1}^N \log p_\theta (\bx_i).
\end{align}</p>

<p>It is often computationally intractable to compute the partition
function \(Z_\theta\) unless there
are restrictions on what the model can be, since there are usually
at least an exponential number of possible configurations.
Examples of models where the partition function can be
efficiently computed include
causal convolutions in autoregressive models, and
invertible networks in normalizing flow models
However, such architecture restrictions are very
undesirable as they limit the expressiveness of the models.</p>

<p>A likelihood-based approach that tries to avoid computing
the partition function is variational inference.
In variational inference, we use the Evidence Lower
Bound (ELBO) as a surrogate objective,
where the approximation error is the smallest
Kullback-Leibler divergence between the true distribution
and a distribution that can be parameterized by our model.</p>

<h3 id="limitations-of-adversarial-based-approaches">Limitations of Adversarial-Based Approaches</h3>
<p>Adversarial-based approaches, like generative adversarial networks (GANs), have
been shown to suffer from both instability in training and mode collapse.</p>

<p>Training GANs can be viewed as finding a Nash equilibrium
for a two-player non-cooperative game between
the discriminator and the generator. Finding a Nash
equilibrium is PPAD-complete which is computationally
intractable, and therefore methods like gradient-based
optimization techniques are used instead. However,
the highly non-convex and high-dimensional optimization
landscape means that small perturbations in the parameters of
either player can change the cost function of the other
player, which results in non-convergence.</p>

<p>Another problem with training GANs is that when either the
generator or discriminator becomes significantly better
than the other, then the learning signal for the other
player becomes very weak. For generators,
this is when the discriminator is always able to tell
it apart. For discriminators, this is when the generator
performs so well it can hardly do better than random guessing.</p>

<p>Finally, a common failure mode of GANs is mode collapse,
where the generator only learns to produce a set of very similar
outputs from a single mode instead of from all the modes.
This is due to the non-convexity of the optimization landscape.</p>

<h2 id="score-matching">Score Matching</h2>

<p>Score matching is a non-likelihood-based method to perform sampling
on an unknown data distribution, and seeks to address
many of the limitations of likelihood-based methods and
adversarial methods. This is achieved
by learning the score of the probability density function,
formally defined below:</p>

<div class="definition">
    <div class="theorem-title">Definition
        
        
            (Score Function)
        
    </div>
    <div class="theorem-contents">
        
    The score function of a distribution \( \pdata \) is given by
    \begin{align*}
        f(\bx) = \nabla_\bx \log \pdata.
    \end{align*}
  
    </div>
</div>

<p>In practice, we try to learn the score function using a neural
network \(\stx\) parameterized by \(\theta\).</p>

<p>The objective of score matching is to minimize the Fisher
Divergence between the score function and the score network:</p>

\[\begin{align} \label{eq:score-matching-target-fisher-div}
    \argmin_\theta \frac{1}{2} \mathbb{E}_{\pdata} \left[
        \| \stx - \nabla_\bx \log \pdata \|_2^2
        \right].
\end{align}\]

<p>However, the main problem here is that we do not know
\(\nabla_\bx \log \pdata\), since it depends on knowing
what \(\pdata\) is.</p>

<p><a href="http://jmlr.org/papers/v6/hyvarinen05a.html">(Hyvärinen, 2005)</a>
showed that Equation \ref{eq:score-matching-target-fisher-div}
is equivalent to Equation \ref{eq:score-matching-target} below:</p>

\[\begin{align} \label{eq:score-matching-target}
    \argmin_\theta \frac{1}{2} \mathbb{E}_{\pdata} \left[
        \tr \left( \nabla_\bx \stx \right) +
        \frac{1}{2} \| \stx \|_2^2
        \right].
\end{align}\]

<p>We can now compute this using Monte Carlo methods by sampling from \(\pdata\),
since it only depends on knowing \(\stx\).</p>

<h2 id="sliced-score-matching">Sliced Score Matching</h2>

<p>It is computationally difficult to compute the trace term 
\(\tr \left( \nabla_\bx \stx \right)\)
in Equation \ref{eq:score-matching-target} when \(\bx\) is high-dimensional.
This motivates another alternative cheaper approach for score matching,
called sliced score matching <a href="http://arxiv.org/abs/1905.07088">(Song et al., 2019)</a>.</p>

<p>In sliced score matching, we sample random vectors from some distribution \(\pv\) (such as the
multivariate standard Gaussian) in order to optimize an analog of the Fisher Divergence:</p>

\[\begin{align}
    L(\btheta, \pv) = \frac{1}{2} \mathbb{E}_{\pv} \mathbb{E}_{\pdata} \left[ (\bv^T \stx - \bv^T \sdx)^2 \right]
\end{align}\]

<p>We observe that</p>

\[\begin{align}
    L(\btheta; \pv) &amp;= \frac{1}{2} \mathbb{E}_{\pv} \mathbb{E}_{\pdata} \left[ (\bv^T \stx - \bv^T \sdx)^2 \right]\\
    &amp;=\frac{1}{2} \mathbb{E}_{\pv} \mathbb{E}_{\pdata} \left[ (\bv^T \stx )^2 + (\bv^T \sdx)^2 - 2(\bv^T \stx )(\bv^T \sdx) \right]\\
    &amp;= \mathbb{E}_{\pv} \mathbb{E}_{\pdata} \left[ \frac{1}{2}(\bv^T \stx )^2 - (\bv^T \stx )(\bv^T \sdx) \right] + C\\
\end{align}\]

<p>where the \(\sdx\) term is absorbed into \(C\) as it doesn’t depend on \(\theta\).
Now note</p>

\[\begin{align}
 &amp; -\mathbb{E}_{\pv} \mathbb{E}_{\pdata}\left[(\bv^T \stx )(\bv^T \sdx) \right] \\
=&amp; -\mathbb{E}_{\pv} \int \left[(\bv^T \stx )(\bv^T \sdx)  \pdata d\bx\right]\\
=&amp; -\mathbb{E}_{\pv}  \left[\int(\bv^T \stx )(\bv^T\nabla_{\bx}\log \pdata)\pdata d\bx\right] \\
=&amp; -\mathbb{E}_{\pv}  \left[\int(\bv^T \stx )(\bv^T\nabla_{\bx}\pdata)d\bx\right] \\
=&amp; -\mathbb{E}_{\pv}  \left[\int(\bv^T \stx )(\bv^T\nabla_{\bx}\pdata)d\bx\right] \\
=&amp; -\mathbb{E}_{\pv}  \left[\sum_{i}\int(\bv^T \stx )(v_i\frac{\partial \pdata}{\partial x_i})d\bx\right] \\
=&amp; \mathbb{E}_{\pv}  \left[\int \bv^T\stx\bv \cdot \pdata d\bx\right] \\
=&amp; \mathbb{E}_{\pv}\mathbb{E}_{\pdata}\left[\bv^T\stx\bv \right]
\end{align}\]

<p>where line 16 is obtained by applying multivariate integration by
parts. This finally yields the equivalent objective:</p>

\[\begin{align}
    J(\btheta; \pv) &amp;= \mathbb{E}_{\pv} \mathbb{E}_{\pdata} \left[ \bv^T \nabla_\bx \stx \bv + \frac{1}{2} \| \stx \|_2^2 \right]
\end{align}\]

<p>which no longer has a dependence on the unknown \(\nabla_{bx}\sdx\). This leads to the unbiased estimator:</p>

\[\begin{align}
\hat J_{N,M}(\btheta; \pv) &amp;=\frac{1}{N}\frac{1}{M}\sum_{i= 1}^N\sum_{j=1}^M \left[\bv_{ij}^T\nabla_{\bx}\mathbf{s}_\mathbf{\btheta}(\bx_i)\bv_{ij} + \frac{1}{2} \|\mathbf{s}_\mathbf{\btheta}(\bx_i)\|_2^2\right]
\end{align}\]

<p>where for each data point \(\bx_i\) we draw \(M\) projection vectors from \(\pv\).</p>

<p><a href="http://arxiv.org/abs/1905.07088">(Song et al., 2019)</a> showed that under some
regularity conditions, sliced score matching is an asymptotically consistent
estimator:</p>

\[\begin{align}
   \hat \btheta_{N,M} \overset{p}{\to} \btheta^* \text { as } \mathbb{N} \to \infty
\end{align}\]

<p>where</p>

\[\begin{align}
    \btheta^* &amp;= \underset{\btheta}{\text{argmin  }} J(\btheta; \pv), \\
    \hat \btheta_{N,M} &amp;= \underset{\btheta}{\text{argmin  }} \hat J_{N,M}(\btheta; \pv).
\end{align}\]

<p>Sliced score matching is computationally more efficient, since it now only involves Hessian-vector
products, and continues to work well in high dimensions.</p>

<h2 id="sampling-with-langevin-dynamics">Sampling with Langevin Dynamics</h2>

<p>Once we have trained a score network, we can sample from the data distribution
via Langevin dynamics. Langevin dynamics is a Markov Chain Monte Carlo
method of sampling from a stationary distribution, where we can efficiently
take gradients with respect to the probability of our samples \(\bx\).
We satisfy this criteria since we have the trained score network.</p>

<p>In Langevin dynamics, we start from some initial point \(\bx_0 \sim \bpi(\bx)\) sampled from some
prior distribution \(\bpi\), and then iteratively obtain updated points based on the
following recurrence:
\begin{align}
    \xt_t = \xt_{t-1} + \frac{\epsilon}{2} \nabla_\bx \log p(\xt_{t-1}) + \sqrt{\epsilon} \bz_t,
\end{align}
where \(\bz_t \sim \mathcal{N}(0, I)\). The addition of the Gaussian noise is required, or otherwise
the process simply converges to the nearest mode instead of converging to a stationary distribution.</p>

<p>It can be shown that as \(\epsilon \to 0\) and \(T \to \infty\), we have that the distribution
of the process \(\xt_T\) converges to \(\pdata\) 
<a href="https://dl.acm.org/doi/10.5555/3104482.3104568">(Welling &amp; Teh, 2011)</a>.</p>

<h2 id="challenges-of-langevin-dynamics">Challenges of Langevin Dynamics</h2>
<p>Langevin dynamics does not perform well with multi-modal distributions with poor conductance,
since it will tend to stay in a single mode, which causes long mixing times.
This is particularly a problem when the modes have disjoint supports, since there is very weak
gradient information in the region where there is no support.</p>

<h2 id="challenges-of-score-matching-for-generative-modeling">Challenges of Score Matching for Generative Modeling</h2>

<h3 id="the-manifold-hypothesis">The Manifold Hypothesis</h3>
<p>The manifold hypothesis postulates that real-world data often lies in a low-dimensional manifold
embedded in a high-dimensional space. This has been empirically observed in many datasets.</p>

<p>This poses problems for score matching.
The first problem that the manifold hypothesis poses is that the score 
\(\score\) becomes undefined if \(\bx\) actually just lies in a low-dimensional manifold.
The second problem is that the estimator in Equation \ref{eq:score-matching-target} is only consistent when
the support of \(\pdata\) is that of the whole space.</p>

<p>In order to increase the dimension of the data to match that of the ambient space,
<a href="http://jmlr.org/papers/v6/hyvarinen05a.html">(Hyvärinen, 2005)</a>
proposed injecting small amounts of Gaussian
noise into the data, such that now the data distribution has full support.
As long as the perturbation is sufficiently small (\(\mathcal{N}(0, 0.0001)\) was used in their paper),
it is almost indistinguishable to humans.</p>

<h3 id="low-data-density-regions">Low Data Density Regions</h3>
<p>The other problem with score matching is that it may not be able to learn
the score function in areas of low data density. This is due to the lack
of samples drawn from these regions, resulting in the Monte Carlo estimation
to have high variance.</p>

<h2 id="noise-conditional-score-networks-ncsn">Noise Conditional Score Networks (NCSN)</h2>

<p>The challenges mentioned in the previous sections are addressed
by Noise Conditional Score Networks (NCSN).</p>

<p>In NCSN, we define a geometric sequence of \(L\) noise levels
\({\left\{ \sigma_i \right\}}_{i=1}^L\), with the property
that \(\frac{\sigma_1}{\sigma_2} = \frac{\sigma_{L-1}}{\sigma_L}  &gt; 1\).
Each of these noise levels correspond to Gaussian noise that
will be added to perturb the data distribution, i.e
\(q_{\sigma_i} \sim \pdata + \mathcal{N}(0, \sigma_i)\).</p>

<p>We augment the score network to also take the noise level \(\sigma\) into
account, which is called the NCSN \(\stxt\).
The goal of NCSN is then to estimate the score conditioned on the
noise level. Once we have a trained NCSN, we use a similar
apporach as simulated annealing in Langevin sampling,
where we begin with a large noise level in order
to cross the different modes easily, before gradually
annealing down the noise to achieve convergence.</p>

<p>The denoising score matching objective for each noise level \(\sigma_i\) is given 
as</p>

\[\begin{align}
    \ell(\theta; \sigma) \triangleq \frac{1}{2} \mathbb{E}_{\pdata} \mathbb{E}_{\xt \sim \mathcal{N}(\bx, \sigma^2 I)} \left[ \left\| \stxt + \frac{\xt - \bx}{\sigma^2} \right\|_2^2 \right],
\end{align}\]

<p>and the unified objective for denoising across all levels is given as</p>

\[\begin{align}
    \mathcal{L}\left(\theta; \left\{ \sigma_i\right\}_{i=1}^L \right)
     \triangleq \frac{1}{L} \sum_{i=1}^L \lambda(\sigma_i) \ell(\theta; \sigma_i).
\end{align}\]

<h2 id="score-based-generative-modeling-through-stochastic-differential-equations-song-et-al-2021">Score-Based Generative Modeling through Stochastic Differential Equations <a href="https://arxiv.org/abs/2011.13456">(Song et al., 2021)</a></h2>

<p>We can extend the idea of having a finite number of noise scales
to having an infinite continuous number of such noise scales by modeling the
process as a diffusion process, which can be formalized as a 
stochastic differential equation (SDE). Such an SDE is given in the 
following form:</p>

\[\begin{align}
    d\bx = \boldf(\bx, t) \, dt + g(t) \, d\bw.
\end{align}\]

<p>Here, \(\boldf\) represents the drift coefficient,
which models the deterministic part of the SDE, and determines the rate
at which the process \(d\bx\) is expected to change over time on average.
\(g(t)\) is called the diffusion coefficient, which represents the random
part of the SDE, and determines the magnitude of the noising process
over time. Finally, \(\bw\) is Brownian motion. Thus \(g(t) \, d \bw\)
represents the noising process.</p>

<p>We want our diffusion process to be such that \(\bx(0) \sim p_0\) is 
the original data distribution, and 
\(\bx(T) \sim p_T\) is the Gaussian noise distribution that is independent
of \(p_0\). 
Then since every SDE has a corresponding reverse SDE, we can start
from the final noise distribution and run the reverse-time SDE in order
to recover a sample from \(p_0\), given by the following process:</p>

\[\begin{align}
d \bx = [\boldf (\bx, t) - g(t)^2 \nabla_{\bx} \log_{p_t} (\bx) ] \, dt + g(t) \,d \overline{w},
\end{align}\]

<p>where \(\overline{w}\) is Brownian motion that flows backwards in time from \(T\) to \(0\), and \(dt\) is an infinitesimal negative timestep.</p>

<p>The objective function for score matching for the SDE is then given by</p>

\[\begin{align}
    \argmin_{\theta} \mathbb{E}_t 
    \left[ 
    \lambda (t) \mathbb{E}_{\bx(0)} \mathbb{E}_{\bx (t) \mid \bx(0)} \left[ 
    \| \bs_\theta (\bx(t), t) - \nabla_{\bx(t)} \log p_{0t}(\bx (t) \mid \bx(0)) \|_2^2
    \right]
    \right].
\end{align}\]

<h3 id="score-based-generative-modeling-techniques">Score-based Generative Modeling Techniques</h3>

<p><a href="https://arxiv.org/abs/2011.13456">(Song et al., 2021)</a> covers two score-based generative models that uses SDEs to 
perform generative modeling.
The first is called score matching with Langevin dynamics (SMLD), which performs score estimation
at different noise scales and then performs sampling using Langevin dynamics with decreasing
noise scales. 
The second is denoising diffusion probabilistic modeling (DDPM)</p>

<p><a href="https://arxiv.org/abs/2006.11239">(Ho et al., 2020)</a>,
which uses a parameterized Markov chain that is trained with a re-weighted
variant of the evidence lower bound (ELBO), which is an instance of variational
inference. The Markov chain is trained to reverse the noise diffusion process,
which then allows sampling from the chain using standard Markov Chain Monte Carlo techniques.</p>

<p><a href="https://arxiv.org/abs/2011.13456">(Song et al., 2021)</a> shows that SMLD and DDPM actually corresponds to 
discretizations of the Variance Exploding (VE) and Variance Preserving (VP) SDEs, which
is the focus of the next two section. We believe expanding on this will be illuminating as
it highlights the connections between
SDEs and the discretized approaches that are used in practice.</p>

<h3 id="smld-as-discretization-of-variance-exploding-ve-sde">SMLD As Discretization of Variance Exploding (VE) SDE</h3>
<p>Recall that we use a geometric sequence of \(L\) noise levels 
\({\left\{ \sigma_i \right\}}_{i=1}^L\).
that is added to the data distribution</p>

<p>We can recursively define the distribution for each noise level \(i\) by incrementally adding noise:</p>

\[\begin{align}
    \bx_i = \bx_{i-1} + \sqrt{\sigma_i^2 - \sigma_{i-1}^2} \bz_{i-1}, \qquad \qquad i = 1, \dots, L,
\end{align}\]

<p>where \(\bz_{i-1} \sim \mathcal{N}(\mathbf{0}, \bI)\), and \(\sigma_0 = 0\) so \(\bx_0 \sim \pdata\).</p>

<p>If we view the noise levels as gradually changing in time, then the continuous time limit
of the process is given by the following SDE:
\begin{align}
    \bx(t + \Delta t) = \bx(t) + \sqrt{\sigma^2 (t + \Delta t ) - \sigma^2 (t)} \bz(t) \approx \bx(t) + 
    \sqrt{\frac{d [\sigma^2 (t)]}{dt} \Delta t } \bz (t),
\end{align}
where the approximation holds when \(\Delta t \ll 1\). If we take \(\Delta t \to 0\),
we recover the VE SDE:
\begin{align}
   d \bx = \sqrt{\frac{d [\sigma^2 (t)]}{dt} } d \bw,
\end{align}
which causes the variance of \(d \bx(t)\) to go to infinity as \(t \to \infty\) due to its geometric growth,
hence its name.</p>

<h3 id="ddpm-as-discretization-of-variance-preserving-vp-sde">DDPM As Discretization of Variance Preserving (VP) SDE</h3>
<p>Similarly, the Markov chain of the perturbation kernel of DDPM is given by
\begin{align}
    \bx_i = \sqrt{1 - \beta_i} \bx_{i-1} + \sqrt{\beta_i} \bz_{i-1}, \qquad i = 1, \cdots, L,
\end{align}
where \(\left\{ \beta_i \right\}_{i=1}^L\) are the noise scales,
and if we take \(L \to \infty\) with scaled noise scales \(\overline{\beta_i} = N \beta_i\), we get
\begin{align}
    \bx_i = \sqrt{1 - \frac{\bov_i}{N} } \bx_{i-1} + \sqrt{ \frac{\bov_i}{N} } \bz_{i-1}, \qquad i = 1, \cdots, L.
\end{align}
Now taking limits with \(L \to \infty\), we get
\begin{align}
    \bx(t + \Delta t) \approx \bx(t) - \frac{1}{2} \beta(t) \Delta t \bx(t) + \sqrt{\beta(t) \Delta t} \bz(t),
\end{align}
where the approximation comes from the second degree Taylor expansion of \(\sqrt{1 - \beta(t + \Delta t) \Delta t}\). Then taking the limit of \(\Delta t \to 0\), we obtain the VP SDE
\begin{align}
    d \bx = - \frac{1}{2} \beta(t) \bx dt + \sqrt{\beta(t)} d \bw.
\end{align}
This process thus has bounded variance since \(\beta_i\) is bounded.</p>

<h1 id="experiments">Experiments</h1>
<p>We conduct the following preliminary series of experiments, based on released work by <a href="https://arxiv.org/abs/1907.05600">(Song &amp; Ermon, 2019)</a>.</p>

<h2 id="investigating-the-manifold-hypothesis">Investigating the manifold hypothesis</h2>

<figure id="fig-1">
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/score-based-diffusion-models/sample_dist.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption"><i>Figure 1.</i>
      
        Comparison between true data density and sampling
    
    </figcaption>
</figure>

<p>In this experiment, we have plotted the true data density of a toy distribution
along with samples drawn in three ways. The i.i.d samples are drawn directly
from the underlying distribution and we can see that more samples are drawn in
the area of high data density. However, applying Langevin dynamics without
annealing, we see that there is an almost equal number of points in the top left
and bottom right corners. This is evidence that the sampling method doesn’t
conform to the true distribution. Finally, by injecting and decreasing the
amount of noise through the annealing process, we can recover a representative
sample of the distribution.</p>

<h2 id="importance-of-annealing-when-sampling-via-langevin-dynamics">Importance of annealing when sampling via Langevin Dynamics</h2>

<p>To better visualize the effects of annealing when sampling via Langevin Dynamics, we generated images from a model trained on the CelebA dataset. We first tried applying Langevin Dynamics with a fixed noise and then used annealing to gradually decrease the noise.</p>

<figure id="fig-2">
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/score-based-diffusion-models/annealing_ablation.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption"><i>Figure 2.</i>
      
        Langevin Dynamics with no annealing (top) and annealing (bottom)
    
    </figcaption>
</figure>

<p>Figure 2 shows that the results with annealing are significantly clearer and more varied, matching the performance of GANs in 2019.</p>

<figure id="fig-3">
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/score-based-diffusion-models/left_right.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption"><i>Figure 3.</i>
      
        Closer comparison of no annealing (left) and annealing (right)
    
    </figcaption>
</figure>

<p>We notice that the image generated without annealing manages to produce the structure of a human face but fails to capture finer details such as the hair, and the surrounding backdrop. There is also little variation in color between different samples. This is in agreement with our theory that without annealing, Langevin dynamics cannot properly explore regions of lower data density.</p>

<h2 id="effect-of-noise-parameters-for-annealed-langevin-dynamics">Effect of noise parameters for annealed Langevin Dynamics</h2>
<p>We also investigated the effect of changing the lowest noise standard deviation \(\sigma\) while keeping the number of different noises injected fixed at \(10\). The 10 noise values are determined by an interpolation in log scale.</p>

<figure id="fig-4">
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/score-based-diffusion-models/vary_sigma.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption"><i>Figure 4.</i>
      
        Left to right: \( \sigma_{\text{end}} = \{0.1, 0.01, 0.001\} \)
    
    </figcaption>
</figure>

<p>Our experiment shows that the effect of starting, ending, and the interval between noise values has a significant effect on the convergence of annealed Langevin sampling.</p>

<h1 id="discussion-and-future-work">Discussion and Future Work</h1>
<p>Having completed a survey of score-based diffusion models, and having
run some experiments on them, we now turn our attention to discussing the
pros and cons of this approach.</p>

<p>As mentioned previously in this paper, the main draw of 
score-based diffusion models is that it has shown to be capable of generating impressive
high-quality samples that is on-par with the state-of-the-art with GANs.
We hence focus on its limitations and how they might be overcome, drawing 
from work in <a href="https://arxiv.org/abs/2209.02646">(Cao et al., 2022)</a>.</p>

<h2 id="computation-cost">Computation Cost</h2>
<p>A common refrain of score-based diffusion model is the high computational
complexity in both training and sampling. This is because it requires 
thousands of small diffusion steps in order to ensure that the forward
and reverse SDEs hold in their approximations
<a href="https://arxiv.org/abs/2202.09671">(Zheng et al., 2022)</a>.
If the diffusion steps are too large,
then the Gaussian noise assumption may not hold, resulting in poor score
estimates.
This makes it significantly more expensive than other generative methods like
GANs and VAEs.  To this end, there are some directions being explored to improve
its computation cost.</p>

<p>The first technique seeks to reduce the number of sampling steps required by a
method known as knowledge distillation <a href="http://arxiv.org/abs/1710.07535">(Lopes et al., 2017)</a>.
In knowledge distillation, knowledge is transferred from a larger and more
complex model (called the teacher), to one that is smaller and simpler (called
the student).  This technique has found success in other domains such as image
classification, and has also been shown to result in improvements in diffusion
models 
<a href="https://arxiv.org/abs/2202.00512">(Salimans &amp; Ho, 2022)</a>. It would be interesting to see how far we
can take this optimization.</p>

<p>Another technique known as truncated diffusion probabilistic modeling (TDPM)
<a href="https://arxiv.org/abs/2202.09671">(Zheng et al., 2022)</a>.
In this approach, instead of considering the diffusion process until it becomes pure noise,
the process is stopped once it reaches a hidden noisy-data distribution that 
can be learnt by an auto-encoder by adversarial training. Then in order to produce
samples, a sample is first drawn from the learnt noisy-data distribution,
before being passed through the reverse-SDE diffusion steps.</p>

<p>It also suffers from poor explainability and interpretability, but this is a
common problem across other generative models.</p>

<p><a href="https://arxiv.org/abs/2011.13456">(Song et al., 2021)</a> also notes that it is currently difficult to tune
the myriad of hyperparameters introduced by the choice of noise levels and specific
samplers chosen, and new methods to automatically select and tune these hyperparameters
would make score-based diffusion models more easily deployable in practice.</p>

<h2 id="modality-diversity">Modality Diversity</h2>
<p>Diffusion models have mostly only seen applications for generating image data,
and its potential for generating other data modalities has not been as thoroughly 
investigated.
<a href="https://arxiv.org/abs/2107.03006">(Austin et al., 2021)</a> introduces 
Discrete Denoising Diffusion Probabilistic Models (D3PMs), which develops a
diffusion process for corrupting text data into noise. It would be interesting
to see how well diffusion models can be stretched to perform compared to
state-of-the-art transformer models in text generation.</p>

<h2 id="dimensionality-reduction">Dimensionality Reduction</h2>
<p>Dimensionality reduction is another technique that can be used to speed up
training and sampling speeds of diffusion models.
Diffusion models are typically trained directly in data space.
<a href="https://arxiv.org/abs/2106.05931">(Vahdat et al., 2021)</a>
instead proposes for them to be trained in latent space, which results in
dimensionality reduction in the representation learnt, and also potentially
increases the expressiveness of the framework.
In a similar vein, 
<a href="https://arxiv.org/abs/2211.16032">(Zhang et al., 2022)</a>
argues that due to redundancy in spatial data, it is not necessary
to learn in data space, and instead proposes a 
dimensionality-varying diffusion process (DVDP), where
the dimensionality of the signal is dynamically adjusted during
the both the diffusion and denoising process.</p>

<h1 id="conclusion">Conclusion</h1>
<p>We showed that score matching presents a promising new direction
for generative models, which avoids many of the limitations of other
approaches such as training instability and mode collapse in GANs,
and poor approximation guarantees in variational inference. While
score matching has several flaws, such as suffering from the manifold
hypothesis and requiring an expensive Langevin dynamics process in order
to draw samples, successive work has done well in addressing these limitations
to make score matching on diffusion models a viable contender to displace
GANs as the state-of-the-art for generative modeling.</p>

<p>Our experiments in this blog post help to provide empirical context to the theoretical results we have derived. Most notably, we have shown how annealing is an essential part of sampling via Langevin dynamics.</p>

<p>Finally, we discuss some future directions that can help to improve
the viability of using score-based diffusion models, which includes improving
its computational cost in both training and sampling and increasing the
diversity of applicable modalities.</p>

<h1 id="citation">Citation</h1>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{zeng2023diffusion,
  title   = {Score-Based Diffusion Models},
  author  = {Fan Pu Zeng and Owen Wang},
  journal = {fanpu.io},
  year    = {2023},
  month   = {Jun},
  url     = {https://fanpu.io/blog/2023/score-based-diffusion-models/}
}
</code></pre></div></div>

<h1 id="references">References</h1>
<ul>
  <li>Austin, J., Johnson, D. D., Ho, J., Tarlow, D., and van den Berg, R. 
<a href="https://arxiv.org/abs/2107.03006">Structured denoising diffusion models in discrete state-spaces.</a> CoRR, abs/2107.03006, 2021.</li>
  <li>Cao, H., Tan, C., Gao, Z., Chen, G., Heng, P.-A., and Li, S. Z. 
<a href="https://arxiv.org/abs/2209.02646">A survey on generative diffusion model</a>, 2022.</li>
  <li>Ho, J., Jain, A., and Abbeel, P.  <a href="https://arxiv.org/abs/2006.11239">Denoising diffusion probabilistic
models</a>.  CoRR, abs/2006.11239, 2020. URL
https://arxiv.org/abs/2006.11239.</li>
  <li>Hyva ̈rinen, A. <a href="http://jmlr.org/papers/v6/hyvarinen05a.html">Estimation of non-normalized statistical models by score matching</a>. Journal of Machine Learning Research, 6(24):695–709, 2005.</li>
  <li>Lopes, R. G., Fenu, S., and Starner, T. <a href="http://arxiv.org/abs/1710.07535">Data-free knowledge distillation for deep neural networks</a>. CoRR, abs/1710.07535,
2017.</li>
  <li>Salimans, T. and Ho, J. <a href="https://arxiv.org/abs/2202.00512">Progressive distillation for fast sampling of diffusion models</a>. CoRR, abs/2202.00512, 2022.</li>
  <li>Song, Y. and Ermon, S. 
<a href="http://arxiv.org/abs/1907.05600">Generative modeling by estimating gradients of the data distribution</a>. CoRR, abs/1907.05600, 2019.</li>
  <li>Song, Y., Garg, S., Shi, J., and Ermon, S. 
<a href="http://arxiv.org/abs/1905.07088">Sliced score matching: A scalable approach to density and score estimation</a>. CoRR,
abs/1905.07088, 2019. URL http://arxiv.org/abs/1905.07088.</li>
  <li>Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole,
B. <a href="https://arxiv.org/abs/2011.13456">Score-based generative modeling through stochastic differential
equations</a>. ICLR, abs/1907.05600, 2021.</li>
  <li>Vahdat, A., Kreis, K., and Kautz, J. <a href="https://arxiv.org/abs/2106.05931">Score-based generative modeling in latent space</a>, 2021.</li>
  <li>Welling, M. and Teh, Y. W. <a href="https://dl.acm.org/doi/10.5555/3104482.3104568">Bayesian learning via stochastic gradient langevin dynamics</a>. In Proceedings of the 28th International Conference on International Conference on Machine Learning, ICML’11, pp. 681–688, Madison, WI, USA, 2011. Omnipress. ISBN 9781450306195.</li>
  <li>Zhang, H., Feng, R., Yang, Z., Huang, L., Liu, Y., Zhang, Y., Shen, Y., Zhao, D., Zhou, J., and Cheng, F. <a href="https://arxiv.org/abs/2211.16032">Dimensionality-varying diffusion process</a>, 2022.</li>
  <li>Zheng, H., He, P., Chen, W., and Zhou, M. <a href="https://arxiv.org/abs/2202.09671">Truncated diffusion probabilistic models and diffusion-based adversarial auto-encoders</a>, 2022.</li>
</ul>]]></content><author><name>fanpu</name></author><category term="machine-learning" /><summary type="html"><![CDATA[Score-based diffusion models are a promising direction for generative models, as they improve on both likelihood-based approaches like variational autoencoders, as well as adversarial methods like Generative Adversarial Networks (GANs). In this blog post, we survey recent developments in the field centered around the line of results developed in (Song & Ermon, 2019), analyze the current strengths and limitations of score-based diffusion models, and discuss possible future directions that can address its drawbacks. Joint work with Owen Wang.]]></summary></entry><entry><title type="html">The Art of LaTeX: Common Mistakes, and Advice for Typesetting Beautiful, Delightful Proofs</title><link href="https://fanpu.io/blog/2023/latex-tips/" rel="alternate" type="text/html" title="The Art of LaTeX: Common Mistakes, and Advice for Typesetting Beautiful, Delightful Proofs" /><published>2023-01-02T00:00:00+00:00</published><updated>2023-01-02T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/latex-tips</id><content type="html" xml:base="https://fanpu.io/blog/2023/latex-tips/"><![CDATA[<p>When was the first time you had to use <a href="https://www.latex-project.org/">LaTeX</a>?
If you are like most people, it was probably suddenly forced upon you during
your first math or CS class where you had to start writing proofs, with minimal
guidance on how to get started other than something along the lines of “hey,
check out this link on how to get things setup, and here are some basic
commands, now go wild!”.</p>

<p>Unfortunately, this meant that while many people have good operational knowledge
of LaTeX and can get the job done, there are still many small mistakes and
best practices which are not followed, which are not corrected by TAs
as they are either not severe enough to warrant a note, or perhaps even the TAs themselves
are not aware of them.</p>

<p>In this post, we cover some common mistakes that are made by LaTeX
practitioners (even in heavily cited papers), and how to address them. This
post assumes that the reader has some working knowledge of LaTeX.</p>

<h2 id="typesetting-as-a-form-of-art">Typesetting as a Form of Art</h2>
<p>It is important to get into the right mindset whenever you typeset a
document. You are not simply “writing” a document — you are crafting a work
of art that combines both the precision and creativity of your logical
thinking, as well as the elegance of a beautifully typeset writing. The amount
of attention and care you put into the presentation is indicative of the amount
of thought you put into the content. Therefore, having good style is not
only delightful and aesthetically pleasing to read, but it also serves to establish 
your ethos and character. One can tell that someone puts a lot of effort into their
work and takes great pride in them when they pay attention even to the smallest of
details.</p>

<p>Furthermore, adopting good practices also helps to avoid you making
typographical mistakes in your proof, such as missing parenthesis or wrong
positioning. This could often lead to cascading errors that are very annoying
to fix when you discover them later on. There are ways to replicate the strict
typechecking of statically typed languages to ensure that mistakes in your
expressions can be caught at compile-time.</p>

<h2 id="common-mistakes-and-how-to-fix-them">Common Mistakes, and How To Fix Them</h2>
<p>In the following section, we take a look at common mistakes that people make,
and how they can be avoided or fixed. We cover style mistakes first, since the
ideas behind them are more general. All the screenshotted examples come from
peer-reviewed papers that have been published to top conferences, so they are
definitely very common mistakes and you shouldn’t feel bad for making them.
The important thing is that you are aware of them now so that your style
will gradually improve over time.</p>

<h2 id="style-mistakes">Style Mistakes</h2>
<p>We take a look at style mistakes, which impairs reader understanding,
and makes it easy to commit other sorts of errors.</p>

<h3 id="paired-delimiters">Paired Delimiters</h3>
<p>Parenthesis, brackets, and pipes are examples of delimiters that are used to mark the start
and end of formula expressions. As they come in pairs, a common mistake is accidentally 
leaving out the closing delimiter, especially for nested expressions. Even if you don’t
forget to do so, there is the issue of incorrect sizing.</p>

<p>For instance, consider
the following way of expressing the Topologist’s sine curve, which is an example of a topology
that is connected but not path connected:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex">T = <span class="k">\{</span> ( x, <span class="k">\sin</span> <span class="k">\frac</span><span class="p">{</span>1<span class="p">}{</span>x<span class="p">}</span> ) : x <span class="k">\in</span> (0, 1] <span class="k">\}</span> <span class="k">\cup</span> <span class="k">\{</span> ( 0, 0 ) <span class="k">\}</span></code></pre></figure>

<p>which is rendered as follows:</p>

\[T = \{(x, \sin \frac{1}{x} ) : x \in (0, 1] \} \cup \{ ( 0, 0 ) \}\]

<p>The problem here is that the curly braces have the wrong
size, as they should be large enough to cover the \(\sin \frac{1}{x}\) expression vertically.</p>

<p>The wrong way of resolving this would be to use delimiter size modifiers, i.e
<code class="language-plaintext highlighter-rouge">\bigl, \Bigl, \biggl</code> paired with <code class="language-plaintext highlighter-rouge">\bigr, \Bigr, \biggr</code>  and the like. This
is tedious and error-prone, since it will even happily let you match delimiters
with different sizes. Indeed, I came across the following formula in a
paper recently, where the outer right square brackets was missing and the left one
had the wrong size:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/latex-mistakes/paired_delim.webp" class="z-depth-1 center" width="500px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      What happens when you don't use paired delimiters
    </figcaption>
</figure>

<p>The correct way to do this would be to use paired delimiters,
which will automatically adjust its size based on
its contents, and automatically result in a compile error if the matching
right delimiter is not included, or nested at the wrong level.
Some of them are given below:</p>

<table class="table table-bordered table-sm">
  <thead>
    <tr>
      <th>Raw LaTeX</th>
      <th>Rendered</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">\left( \frac{1}{x} \right)   </code></td>
      <td>\(\left( \frac{1}{x} \right)\)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">\left[ \frac{1}{x} \right]   </code></td>
      <td>\(\left[ \frac{1}{x} \right]\)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">\left\{ \frac{1}{x} \right\} </code></td>
      <td>\(\left\{ \frac{1}{x} \right\}\)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">\left\lvert \frac{1}{x} \right\lvert </code></td>
      <td>\(\left\lvert \frac{1}{x} \right\rvert\)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">\left\lceil \frac{1}{x} \right\rceil </code></td>
      <td>\(\left\lceil \frac{1}{x} \right\rceil\)</td>
    </tr>
  </tbody>
</table>

<p>In fact, to make things even simpler and more readable, you can declare paired delimiters 
for use based on the <code class="language-plaintext highlighter-rouge">mathtools</code> package, with the following commands due to
<a href="http://www.cs.cmu.edu/~odonnell/">Ryan O’Donnell</a>:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="c">% Make sure you include \usepackage{mathtools}</span>
<span class="k">\DeclarePairedDelimiter\parens</span><span class="p">{</span><span class="k">\lparen</span><span class="p">}{</span><span class="k">\rparen</span><span class="p">}</span>
<span class="k">\DeclarePairedDelimiter\abs</span><span class="p">{</span><span class="k">\lvert</span><span class="p">}{</span><span class="k">\rvert</span><span class="p">}</span>
<span class="k">\DeclarePairedDelimiter\norm</span><span class="p">{</span><span class="k">\lVert</span><span class="p">}{</span><span class="k">\rVert</span><span class="p">}</span>
<span class="k">\DeclarePairedDelimiter\floor</span><span class="p">{</span><span class="k">\lfloor</span><span class="p">}{</span><span class="k">\rfloor</span><span class="p">}</span>
<span class="k">\DeclarePairedDelimiter\ceil</span><span class="p">{</span><span class="k">\lceil</span><span class="p">}{</span><span class="k">\rceil</span><span class="p">}</span>
<span class="k">\DeclarePairedDelimiter\braces</span><span class="p">{</span><span class="k">\lbrace</span><span class="p">}{</span><span class="k">\rbrace</span><span class="p">}</span>
<span class="k">\DeclarePairedDelimiter\bracks</span><span class="p">{</span><span class="k">\lbrack</span><span class="p">}{</span><span class="k">\rbrack</span><span class="p">}</span>
<span class="k">\DeclarePairedDelimiter\angles</span><span class="p">{</span><span class="k">\langle</span><span class="p">}{</span><span class="k">\rangle</span><span class="p">}</span></code></pre></figure>

<p>Then you can now use the custom delimiters as follows, taking note that you need the <code class="language-plaintext highlighter-rouge">*</code>
for it to auto-resize:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex">T = <span class="k">\braces*</span><span class="p">{</span> <span class="k">\parens*</span><span class="p">{</span> x, <span class="k">\sin</span> <span class="k">\frac</span><span class="p">{</span>1<span class="p">}{</span>x<span class="p">}</span> <span class="p">}</span> : x <span class="k">\in</span> (0, 1] <span class="p">}</span> <span class="k">\cup</span> <span class="k">\braces*</span><span class="p">{</span> <span class="k">\parens*</span><span class="p">{</span> 0, 0 <span class="p">}}</span></code></pre></figure>

<p>which gives</p>

\[T = \left\{ \left( x, \sin \frac{1}{x} \right) : x \in (0, 1] \right\} \cup \left\{ \left( 0, 0 \right) \right\} \\\]

<p>The biggest downside of using custom paired delimiters is having to remember to
add the <code class="language-plaintext highlighter-rouge">*</code>, otherwise, the delimiters will not auto-resize. This is pretty unfortunate
as it still makes it error-prone. There is a <a href="https://tex.stackexchange.com/questions/1742/automatic-left-and-right-commands/1744#1744">proposed
solution</a>
floating around on StackExchange that relies on a custom command that makes auto-resizing
the default, but it’s still a far cry from a parsimonious solution.</p>

<h3 id="macros-for-saving-time-and-preventing-mistakes">Macros for Saving Time and Preventing Mistakes</h3>
<p>Macros can be defined using the <code class="language-plaintext highlighter-rouge">\newcommand</code> command.
The basic syntax is <code class="language-plaintext highlighter-rouge">\newcommand{command_name}{command_definition}</code>.
For instance, it might get tiring to always type <code class="language-plaintext highlighter-rouge">\boldsymbol{A}</code>
to refer to a matrix \(\boldsymbol{A}\), so you can use the following macro:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="c">% Macro</span>
<span class="k">\newcommand</span><span class="p">{</span><span class="k">\bA</span><span class="p">}{</span><span class="k">\boldsymbol</span><span class="p">{</span>A<span class="p">}}</span>

<span class="p">$$</span><span class="nv">\min</span><span class="p">_</span><span class="nb">x </span><span class="nv">\lvert</span><span class="nb"> </span><span class="nv">\bA</span><span class="nb"> x </span><span class="o">-</span><span class="nb"> b </span><span class="nv">\rvert</span><span class="p">_</span><span class="m">2</span><span class="p">^</span><span class="m">2</span><span class="p">$$</span></code></pre></figure>

\[\min_x \left\lvert \boldsymbol{A} x - b \right\rvert_2^2\]

<p>Macros can also take arguments to be substituted within the definition.
This is done by adding a <code class="language-plaintext highlighter-rouge">[n]</code> argument after your command name,
where <code class="language-plaintext highlighter-rouge">n</code> is the number of arguments that it should take. You can then
reference the positional arguments using <code class="language-plaintext highlighter-rouge">#1, #2,</code> and so on.
Here, we create a <code class="language-plaintext highlighter-rouge">\dotprod</code> macro that takes two arguments:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="c">% Macros</span>
<span class="k">\newcommand</span><span class="p">{</span><span class="k">\dotprod</span><span class="p">}</span>[2]<span class="p">{</span><span class="k">\langle</span> #1, #2 <span class="k">\rangle</span><span class="p">}</span>
<span class="k">\newcommand</span><span class="p">{</span><span class="k">\bu</span><span class="p">}{</span><span class="k">\boldsymbol</span><span class="p">{</span>u<span class="p">}}</span>
<span class="k">\newcommand</span><span class="p">{</span><span class="k">\bv</span><span class="p">}{</span><span class="k">\boldsymbol</span><span class="p">{</span>v<span class="p">}}</span>

<span class="p">$$</span><span class="nv">\left\lvert</span><span class="nb"> </span><span class="nv">\dotprod</span><span class="p">{</span><span class="nv">\bu</span><span class="p">}{</span><span class="nv">\bv</span><span class="p">}</span><span class="nb"> </span><span class="nv">\right\rvert</span><span class="p">^</span><span class="m">2</span><span class="nb"> </span><span class="nv">\leq</span><span class="nb"> </span><span class="nv">\dotprod</span><span class="p">{</span><span class="nv">\bu</span><span class="p">}{</span><span class="nv">\bu</span><span class="p">}</span><span class="nb"> </span><span class="nv">\cdot</span><span class="nb"> </span><span class="nv">\dotprod</span><span class="p">{</span><span class="nv">\bv</span><span class="p">}{</span><span class="nv">\bv</span><span class="p">}$$</span></code></pre></figure>

\[\left\lvert \dotprod{\bu}{\bv} \right\rvert^2 \leq \dotprod{\bu}{\bu} \cdot \dotprod{\bv}{\bv}\]

<p>Macros are incredibly helpful as they help to save time, and ensure that our
notation is consistent. However, they can also be used to help to catch
mistakes when typesetting grammatically structured things.</p>

<p>For instance, when expressing types and terms in programming language theory, 
there is often a lot of nested syntactical structure, which could make it easy
to make mistakes.  Consider the following proof:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/latex-mistakes/macros.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      A proof with a lot of syntactical structure
    </figcaption>
</figure>

<p>The details are unimportant, but it is clear that it is easy to miss a letter here
or a term there in the proof, given how cumbersome the notation is.
To avoid this, I used the following macros, due to <a href="http://www.cs.cmu.edu/~rwh/">Robert Harper</a>:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="k">\newcommand</span><span class="p">{</span><span class="k">\inval</span><span class="p">}</span>[2]<span class="p">{</span><span class="k">\in</span><span class="p">^{</span>(#1)<span class="p">}_</span><span class="k">\mathsf</span><span class="p">{</span>val<span class="p">}</span> #2<span class="p">}</span>
<span class="k">\newcommand</span><span class="p">{</span><span class="k">\foldex</span><span class="p">}</span>[2]<span class="p">{</span><span class="k">\mathsf</span><span class="p">{</span>fold<span class="p">}_{</span>#1<span class="p">}</span>(#2)<span class="p">}</span>
<span class="k">\newcommand</span><span class="p">{</span><span class="k">\recty</span><span class="p">}</span>[2]<span class="p">{</span><span class="k">\mathsf</span><span class="p">{</span>rec<span class="p">}</span>(#1.#2)<span class="p">}</span>
<span class="k">\newcommand</span><span class="p">{</span><span class="k">\Subst</span><span class="p">}</span>[3]<span class="p">{</span><span class="k">\sqbracks</span><span class="p">{{</span>#1<span class="p">}</span><span class="k">\mathord</span><span class="p">{</span>/<span class="p">}{</span>#2<span class="p">}}{</span>#3<span class="p">}}</span></code></pre></figure>

<p>And the source for the proof looks like the following:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex">We check that anti-monotonicity continues to hold for recursive types,
by showing that if <span class="p">$</span><span class="nb">m </span><span class="nv">\leq</span><span class="nb"> n</span><span class="p">$</span>, then
<span class="p">$$</span><span class="nv">\foldex</span><span class="p">{</span><span class="nb">X.A</span><span class="p">}{</span><span class="nb">V</span><span class="p">}</span><span class="nb"> </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">n</span><span class="p">}{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}</span><span class="nb"> </span><span class="nv">\text</span><span class="p">{</span><span class="nb"> implies </span><span class="p">}</span><span class="nb"> </span><span class="nv">\foldex</span><span class="p">{</span><span class="nb">X.A</span><span class="p">}{</span><span class="nb">V</span><span class="p">}</span><span class="nb"> </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">m</span><span class="p">}{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}</span><span class="nb">. </span><span class="p">$$</span>

<span class="nt">\begin{proof}</span>
We proceed by induction on <span class="p">$</span><span class="nb">n</span><span class="p">$</span>. 
When <span class="p">$</span><span class="nb">n</span><span class="o">=</span><span class="m">0</span><span class="p">$</span>, the result is trivial, so consider <span class="p">$</span><span class="nb">n </span><span class="nv">\geq</span><span class="nb"> </span><span class="m">0</span><span class="p">$</span>, with the intent to prove it for <span class="p">$</span><span class="nb">n</span><span class="o">+</span><span class="m">1</span><span class="p">$</span>.

Let <span class="p">$</span><span class="nb">m </span><span class="nv">\leq</span><span class="nb"> n </span><span class="o">+</span><span class="nb"> </span><span class="m">1</span><span class="p">$</span>, and assume
<span class="p">$</span><span class="nv">\foldex</span><span class="p">{</span><span class="nb">X.A</span><span class="p">}{</span><span class="nb">V</span><span class="p">}</span><span class="nb"> </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">n</span><span class="o">+</span><span class="m">1</span><span class="p">}{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}$</span>. If <span class="p">$</span><span class="nb">m </span><span class="o">=</span><span class="nb"> n </span><span class="o">+</span><span class="nb"> </span><span class="m">1</span><span class="p">$</span> or <span class="p">$</span><span class="nb">m</span><span class="o">=</span><span class="m">0</span><span class="p">$</span>, we are trivially done, so let <span class="p">$</span><span class="m">0</span><span class="nb"> &lt; m &lt; n</span><span class="o">+</span><span class="m">1</span><span class="p">$</span>.

We want to show that
<span class="p">$</span><span class="nv">\foldex</span><span class="p">{</span><span class="nb">X.A</span><span class="p">}{</span><span class="nb">V</span><span class="p">}</span><span class="nb"> </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">m</span><span class="p">}{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}$</span>.
By definition of step-indexed logical relations~(SILR), it suffices to show
<span class="p">$</span><span class="nb">V </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">m</span><span class="o">-</span><span class="m">1</span><span class="p">}{</span><span class="nv">\Subst</span><span class="p">{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}$</span>.

Since <span class="p">$</span><span class="nv">\foldex</span><span class="p">{</span><span class="nb">X.A</span><span class="p">}{</span><span class="nb">V</span><span class="p">}</span><span class="nb"> </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">n</span><span class="o">+</span><span class="m">1</span><span class="p">}{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}$</span>, by definition of SILR,
<span class="p">$</span><span class="nb">V </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">n</span><span class="p">}{</span><span class="nv">\Subst</span><span class="p">{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}$</span>.

By IH on <span class="p">$</span><span class="nb">V </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">n</span><span class="p">}{</span><span class="nv">\Subst</span><span class="p">{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}$</span>,
we also know <span class="p">$</span><span class="nb">V </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">m</span><span class="o">-</span><span class="m">1</span><span class="p">}{</span><span class="nv">\Subst</span><span class="p">{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}$</span>.

But then by definition of SILR,
<span class="p">$</span><span class="nv">\foldex</span><span class="p">{</span><span class="nb">X.A</span><span class="p">}{</span><span class="nb">V</span><span class="p">}</span><span class="nb"> </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">m</span><span class="p">}{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}$</span>, as desired. <span class="k">\qedhere</span>
<span class="nt">\end{proof}</span></code></pre></figure>

<p>It is definitely still not the most pleasant thing to read, but at least now you
will be less likely to miss an argument or forget to close a parenthesis.</p>

<h3 id="non-breaking-lines">Non-breaking lines</h3>
<p>Expressions which are logically a single unit should stay on the same line, instead
of being split apart mid-sentence. Cue the following bad example from another paper:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/latex-mistakes/nbsp.webp" class="z-depth-1 center" width="300px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Expressions that are broken apart
    </figcaption>
</figure>

<p>In the area marked in red, we had the expression that was defining \(\tau^i\)
get cut in half, which is very jarring visually and interrupts the reader’s
train of thought.</p>

<p>To ensure that expressions do not get split, simply wrap it around in curly braces.
For instance,</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="k">\tau</span>=<span class="k">\left</span>(s<span class="p">_</span>1, a<span class="p">_</span>1, <span class="k">\ldots</span>, a<span class="p">_{</span>t-1<span class="p">}</span>, s<span class="p">_</span>t<span class="k">\right</span>)</code></pre></figure>

<p>would be wrapped by <code class="language-plaintext highlighter-rouge">{</code> and <code class="language-plaintext highlighter-rouge">}</code> on both sides and become</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="p">{</span> <span class="k">\tau</span>=<span class="k">\left</span>(s<span class="p">_</span>1, a<span class="p">_</span>1, <span class="k">\ldots</span>, a<span class="p">_{</span>t-1<span class="p">}</span>, s<span class="p">_</span>t<span class="k">\right</span>) <span class="p">}</span></code></pre></figure>

<p>So if we render the following snippet, which would otherwise have expressions
split in half without the wrapped curly braces:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex">We denote the historical trajectory as 
<span class="p">${</span><span class="nb"> </span><span class="nv">\tau</span><span class="o">=</span><span class="nv">\left</span><span class="o">(</span><span class="nb">s</span><span class="p">_</span><span class="m">1</span><span class="nb">, a</span><span class="p">_</span><span class="m">1</span><span class="nb">, </span><span class="nv">\ldots</span><span class="nb">, a</span><span class="p">_{</span><span class="nb">t</span><span class="o">-</span><span class="m">1</span><span class="p">}</span><span class="nb">, s</span><span class="p">_</span><span class="nb">t</span><span class="nv">\right</span><span class="o">)</span><span class="nb"> </span><span class="p">}$</span>
and action-observation history <span class="p">$</span><span class="o">(</span><span class="nv">\mathrm</span><span class="p">{</span><span class="nb">AOH</span><span class="p">}</span><span class="o">)</span><span class="p">$</span> for
player <span class="p">$</span><span class="nb">i</span><span class="p">$</span> as 
<span class="p">${</span><span class="nb"> </span><span class="nv">\tau</span><span class="p">^</span><span class="nb">i</span><span class="o">=</span><span class="nv">\left</span><span class="o">(</span><span class="nv">\Omega</span><span class="p">^</span><span class="nb">i</span><span class="nv">\left</span><span class="o">(</span><span class="nb">s</span><span class="p">_</span><span class="m">1</span><span class="nv">\right</span><span class="o">)</span><span class="nb">, a</span><span class="p">_</span><span class="m">1</span><span class="nb">, </span><span class="nv">\ldots</span><span class="nb">, a</span><span class="p">_{</span><span class="nb">t</span><span class="o">-</span><span class="m">1</span><span class="p">}</span><span class="nb">, </span><span class="nv">\Omega</span><span class="p">^</span><span class="nb">i</span><span class="nv">\left</span><span class="o">(</span><span class="nb">s</span><span class="p">_</span><span class="nb">t</span><span class="nv">\right</span><span class="o">)</span><span class="nv">\right</span><span class="o">)</span><span class="nb"> </span><span class="p">}$</span>,
 which encodes the trajectory from player <span class="p">$</span><span class="nb">i</span><span class="p">$</span> 's point of view.</code></pre></figure>

<p>we get the following positive result where there is additional whitespace between
the justified text on the first line, to compensate for the expression assigning \(\tau\)
to stay on the same line:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/latex-mistakes/nbsp-positive.webp" class="z-depth-1 center" width="300px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Expressions that brace together stays together
    </figcaption>
</figure>

<h3 id="non-breaking-space-with-">Non-breaking space with <code class="language-plaintext highlighter-rouge">~</code></h3>
<p>When referencing figures and equations, you want the text and number (i.e Figure 10) to end up on the same line.
This is a negative example, where the region underlined in red shows how it was split up:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/latex-mistakes/figure-truncated.webp" class="z-depth-1 center" width="500px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      The phrase "Figure 2" was truncated in half
    </figcaption>
</figure>

<p>To remedy this, add a <code class="language-plaintext highlighter-rouge">~</code> after <code class="language-plaintext highlighter-rouge">Figure</code>, which LaTeX interprets as a non-breaking space:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex">We evaluated the policy periodically during training by testing it without exploration noise.
Figure~<span class="k">\ref</span><span class="p">{</span>fig:env-perf<span class="p">}</span> shows the performance curve for a selection of environments. </code></pre></figure>

<p>This would ensure that “Figure 2” always appears together.</p>

<h3 id="expressions-should-be-punctuated-like-sentences">Expressions Should Be Punctuated Like Sentences</h3>
<p>Your document is meant to be read, and it should follow the rules and structures
of English (or whichever language you are writing in). This means that
mathematical expressions should also be punctuated appropriately, which
allows it to flow more naturally and make it easier for the reader to follow.</p>

<p>Consider the following example that does not use punctuation:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/latex-mistakes/sentence-negative.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Expressions which are not punctuated are tiring to read
    </figcaption>
</figure>

<p>In the region highlighted in red, the expressions do not carry any punctuation at all,
and by the end of the last equation (Equation 15), I am almost out of breath trying
to process all of the information. In addition, it does not end in a full stop, which
does not give me an affordance to take a break mentally until the next paragraph.</p>

<p>Instead, commas should be added after each expression where the expression does not terminate,
and the final equation should be ended by a full stop. Here is a good example of punctuation
that helps to guide the reader along the author’s train of thought:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/latex-mistakes/sentence-multiline.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Appropriate use of commas and full stop to guide the reader
    </figcaption>
</figure>

<p>Here is another good example of how using commas for the equations 
allow the text to flow naturally, where it takes the form of
“analogously, observe that we have [foo] and [bar], where the inequality…”:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/latex-mistakes/sentence-two-exp.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Punctuation allows the content to flow naturally
    </figcaption>
</figure>

<p>This even extends to when you pack several equations on a single line, which
is common when you are trying to fit the page limit for conference submissions:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/latex-mistakes/sentence-singleline.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Appropriate use of punctuation when multiple equations are on a single line
    </figcaption>
</figure>

<h3 id="the-proof-environment">The <code class="language-plaintext highlighter-rouge">proof</code> environment</h3>
<p>The <code class="language-plaintext highlighter-rouge">proof</code> environment from the <code class="language-plaintext highlighter-rouge">amsthm</code> package is great for signposting to your readers
where a proof starts and ends. For instance, consider how it is used in the following example:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="k">\textit</span><span class="p">{</span>Problem: Show that if <span class="p">$</span><span class="o">(</span><span class="nb">x</span><span class="p">_</span><span class="nb">n</span><span class="o">)</span><span class="p">_</span><span class="nb">n</span><span class="p">$</span> converges to <span class="p">$</span><span class="nb">x</span><span class="p">$</span> in the usual sense, then
<span class="p">$</span><span class="nv">\lim</span><span class="p">_{</span><span class="nb">n </span><span class="nv">\to</span><span class="nb"> </span><span class="nv">\infty</span><span class="p">}</span><span class="nb"> x</span><span class="p">_</span><span class="nb">n </span><span class="o">=</span><span class="nb"> </span><span class="nv">\lim</span><span class="p">_{</span><span class="nv">\mathcal</span><span class="p">{</span><span class="nb">F</span><span class="p">}}</span><span class="nb"> x</span><span class="p">_</span><span class="nb">n</span><span class="p">$</span>.<span class="p">}</span>

Suppose that <span class="p">$</span><span class="o">(</span><span class="nb">x</span><span class="p">_</span><span class="nb">n</span><span class="o">)</span><span class="p">_</span><span class="nb">n</span><span class="p">$</span> converges to <span class="p">$</span><span class="nb">x</span><span class="p">$</span>. We show that this <span class="p">$</span><span class="nb">x</span><span class="p">$</span> is also the
<span class="p">$</span><span class="nv">\mathcal</span><span class="p">{</span><span class="nb">F</span><span class="p">}$</span>-limit of <span class="p">$</span><span class="o">(</span><span class="nb">x</span><span class="p">_</span><span class="nb">n</span><span class="o">)</span><span class="p">_</span><span class="nb">n</span><span class="p">$</span>.

<span class="nt">\begin{proof}</span>
    Take any <span class="p">$</span><span class="nv">\varepsilon</span><span class="p">$</span>. Then we know that for some large enough <span class="p">$</span><span class="nb">N</span><span class="p">$</span>, if <span class="p">$</span><span class="nb">n </span><span class="nv">\geq</span><span class="nb"> N</span><span class="p">$</span>, then
    <span class="p">$</span><span class="nb">x</span><span class="p">_</span><span class="nb">n </span><span class="nv">\in</span><span class="nb"> B</span><span class="p">_</span><span class="nv">\varepsilon</span><span class="o">(</span><span class="nb">x</span><span class="o">)</span><span class="p">$</span>. Since every non-principal ultrafilter on <span class="p">$</span><span class="nv">\N</span><span class="p">$</span> contains
    <span class="p">$</span><span class="nv">\mathcal</span><span class="p">{</span><span class="nb">F</span><span class="p">}_</span><span class="nv">\infty</span><span class="p">$</span>, then <span class="p">$</span><span class="nv">\mathcal</span><span class="p">{</span><span class="nb">F</span><span class="p">}$</span> also contains <span class="p">$</span><span class="nb"> </span><span class="nv">\left\{</span><span class="nb"> n : n </span><span class="nv">\geq</span><span class="nb"> N </span><span class="nv">\right\}</span><span class="nb"> </span><span class="p">$</span>,
    since the complement is finite. Therefore since filters are closed upwards, any
    sequence items <span class="p">$</span><span class="nb">x</span><span class="p">_</span><span class="nb">n</span><span class="p">$</span> with <span class="p">$</span><span class="nb">n &lt; N</span><span class="p">$</span> that happen to fall in the ball around <span class="p">$</span><span class="nb">x</span><span class="p">$</span>,
    i.e, <span class="p">$</span><span class="nb">x</span><span class="p">_</span><span class="nb">n </span><span class="nv">\in</span><span class="nb"> B</span><span class="p">_</span><span class="nv">\varepsilon</span><span class="o">(</span><span class="nb">x</span><span class="o">)</span><span class="p">$</span>
    is also contained in some filter element, so 
    <span class="p">$</span><span class="nv">\left\{</span><span class="nb">  n </span><span class="nv">\in</span><span class="nb"> </span><span class="nv">\N</span><span class="nb"> : </span><span class="nv">\lvert</span><span class="nb"> x</span><span class="p">_</span><span class="nb">n </span><span class="o">-</span><span class="nb"> x </span><span class="nv">\rvert</span><span class="nb"> &lt; </span><span class="nv">\varepsilon</span><span class="nb"> </span><span class="nv">\right\}</span><span class="nb"> </span><span class="nv">\in</span><span class="nb"> </span><span class="nv">\mathcal</span><span class="p">{</span><span class="nb">F</span><span class="p">}$</span>,
    as desired.
<span class="nt">\end{proof}</span></code></pre></figure>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/latex-mistakes/proof.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Signposting using the `proof` environment
    </figcaption>
</figure>

<p>This will helpfully highlight the start of your argument with <em>“Proof”</em>, and
terminate it with a square that symbolizes QED.</p>

<h3 id="terminate-proofs-with-explicit-qedhere">Terminate Proofs with Explicit <code class="language-plaintext highlighter-rouge">\qedhere</code></h3>

<p>Consider the same example as previously, but now you accidentally added an additional
newline before the closing <code class="language-plaintext highlighter-rouge">\end{proof}</code>, which happens pretty often:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="c">% Same as previously, contents elided for brevity</span>
<span class="nt">\begin{proof}</span>
    <span class="c">% Same as previously, contents elided for brevity</span>
    <span class="p">$</span><span class="nb">x</span><span class="p">_</span><span class="nb">n </span><span class="nv">\in</span><span class="nb"> B</span><span class="p">_</span><span class="nv">\varepsilon</span><span class="o">(</span><span class="nb">x</span><span class="o">)</span><span class="p">$</span>
    is also contained in some filter element, so 
    <span class="p">$</span><span class="nv">\left\{</span><span class="nb">  n </span><span class="nv">\in</span><span class="nb"> </span><span class="nv">\N</span><span class="nb"> : </span><span class="nv">\lvert</span><span class="nb"> x</span><span class="p">_</span><span class="nb">n </span><span class="o">-</span><span class="nb"> x </span><span class="nv">\rvert</span><span class="nb"> &lt; </span><span class="nv">\varepsilon</span><span class="nb"> </span><span class="nv">\right\}</span><span class="nb"> </span><span class="nv">\in</span><span class="nb"> </span><span class="nv">\mathcal</span><span class="p">{</span><span class="nb">F</span><span class="p">}$</span>,
    as desired.

    <span class="c">% Extra newline here!</span>
<span class="nt">\end{proof}</span></code></pre></figure>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/latex-mistakes/qedhere.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Misaligned QED symbol
    </figcaption>
</figure>

<p>This results in the above scenario, where the QED symbol now appears on the next line by itself,
which throws the entire text off-balance visually. To avoid such things happening,
always include an explicit <code class="language-plaintext highlighter-rouge">\qedhere</code> marker at the end of your proof, which would cause it
to always appear on the line that it appears after:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="c">% Same as previously, contents elided for brevity</span>
<span class="nt">\begin{proof}</span>
    <span class="c">% Same as previously, contents elided for brevity</span>
    <span class="p">$</span><span class="nb">x</span><span class="p">_</span><span class="nb">n </span><span class="nv">\in</span><span class="nb"> B</span><span class="p">_</span><span class="nv">\varepsilon</span><span class="o">(</span><span class="nb">x</span><span class="o">)</span><span class="p">$</span>
    is also contained in some filter element, so 
    <span class="p">$</span><span class="nv">\left\{</span><span class="nb">  n </span><span class="nv">\in</span><span class="nb"> </span><span class="nv">\N</span><span class="nb"> : </span><span class="nv">\lvert</span><span class="nb"> x</span><span class="p">_</span><span class="nb">n </span><span class="o">-</span><span class="nb"> x </span><span class="nv">\rvert</span><span class="nb"> &lt; </span><span class="nv">\varepsilon</span><span class="nb"> </span><span class="nv">\right\}</span><span class="nb"> </span><span class="nv">\in</span><span class="nb"> </span><span class="nv">\mathcal</span><span class="p">{</span><span class="nb">F</span><span class="p">}$</span>,
    as desired. <span class="k">\qedhere</span> <span class="c">% Always add \qedhere once you are done!</span>

    <span class="c">% Extra newline here!</span>
<span class="nt">\end{proof}</span></code></pre></figure>

<p>We would then get the same result as before originally, when we did not have the extra newline.</p>

<h3 id="spacing">Spacing</h3>
<p>Spacing matters a lot in readability, as it helps to separate logical components.
For instance, the following example fails to add spacing before the differential
of the variable \(dz\):</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/latex-mistakes/integral.webp" class="z-depth-1 center" width="500px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Lack of spacing before "dz"
    </figcaption>
</figure>

<p>This might seem innocuous, but consider the following example that makes the issue more explicit:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex">P(X) = <span class="k">\int</span> xyz dx</code></pre></figure>

\[P(X) = \int xyz dx\]

<p>Now we can really see that the quantities are running into each other, and it
becomes hard to interpret. Instead, we can add math-mode spacing, summarized in
the following table:</p>

<table class="table table-bordered table-sm">
  <thead>
    <tr>
      <th>Spacing Expression</th>
      <th>Type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">\;</code></td>
      <td>Thick space</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">\:</code></td>
      <td>Medium space</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">\,</code></td>
      <td>Thin space</td>
    </tr>
  </tbody>
</table>

<p>So our new expression now looks like:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex">P(X) = <span class="k">\int</span> xyz <span class="k">\,</span> dx</code></pre></figure>

\[P(X) = \int xyz \, dx\]

<p>which is much more readable.</p>

<h3 id="align-environment-for-multiline-equations"><code class="language-plaintext highlighter-rouge">align*</code> Environment for Multiline Equations</h3>
<p>When using the <code class="language-plaintext highlighter-rouge">align*</code> environment, make sure that your ampersands <code class="language-plaintext highlighter-rouge">&amp;</code> appear before the
symbol that you are aligning against. This ensures that you get the correct spacing.</p>

<p>For instance, the following is wrong, where the <code class="language-plaintext highlighter-rouge">&amp;</code> appears after the <code class="language-plaintext highlighter-rouge">=</code>:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="nt">\begin{align*}</span>
    <span class="k">\nabla</span><span class="p">_{</span><span class="k">\mu</span><span class="p">}</span> (<span class="k">\mathbb</span><span class="p">{</span>E<span class="p">}_{</span>x<span class="k">\sim</span> q<span class="p">_{</span><span class="k">\mu</span><span class="p">}}</span> f(x))  = <span class="p">&amp;</span> <span class="k">\nabla</span><span class="p">_{</span><span class="k">\mu</span><span class="p">}</span> <span class="k">\int</span><span class="p">_</span>x f(x) q<span class="p">_{</span><span class="k">\mu</span><span class="p">}</span>(x) dx                                     <span class="k">\\</span>
                                                    = <span class="p">&amp;</span> <span class="k">\int</span><span class="p">_</span>x f(x) (<span class="k">\nabla</span><span class="p">_{</span><span class="k">\mu</span><span class="p">}</span> <span class="k">\log</span> q<span class="p">_{</span><span class="k">\mu</span><span class="p">}</span>(x))  q<span class="p">_{</span><span class="k">\mu</span><span class="p">}</span>(x) dx                  <span class="k">\\</span>
                                                    = <span class="p">&amp;</span> <span class="k">\mathbb</span><span class="p">{</span>E<span class="p">}_{</span>x <span class="k">\sim</span> q<span class="p">_{</span><span class="k">\mu</span><span class="p">}}</span> <span class="k">\left</span>(f(x) <span class="k">\nabla</span><span class="p">_{</span><span class="k">\mu</span><span class="p">}</span> <span class="k">\log</span> q<span class="p">_{</span><span class="k">\mu</span><span class="p">}</span>(x)<span class="k">\right</span>)
<span class="nt">\end{align*}</span></code></pre></figure>

\[\begin{align*}
    \nabla_{\mu} (\mathbb{E}_{x\sim q_{\mu}} f(x))  = &amp; \nabla_{\mu} \int_x f(x) q_{\mu}(x) dx                                     \\
                                                    = &amp; \int_x f(x) (\nabla_{\mu} \log q_{\mu}(x))  q_{\mu}(x) dx                  \\
                                                    = &amp; \mathbb{E}_{x \sim q_{\mu}} \left(f(x) \nabla_{\mu} \log q_{\mu}(x)\right)
\end{align*}\]

<p>This is because there is too little spacing after the <code class="language-plaintext highlighter-rouge">=</code> sign on each line, which feels very cramped.
Putting the <code class="language-plaintext highlighter-rouge">&amp;</code> before the <code class="language-plaintext highlighter-rouge">=</code> is correct:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="nt">\begin{align*}</span>
    <span class="k">\nabla</span><span class="p">_{</span><span class="k">\mu</span><span class="p">}</span> (<span class="k">\mathbb</span><span class="p">{</span>E<span class="p">}_{</span>x<span class="k">\sim</span> q<span class="p">_{</span><span class="k">\mu</span><span class="p">}}</span> f(x)) <span class="p">&amp;</span> = <span class="k">\nabla</span><span class="p">_{</span><span class="k">\mu</span><span class="p">}</span> <span class="k">\int</span><span class="p">_</span>x f(x) q<span class="p">_{</span><span class="k">\mu</span><span class="p">}</span>(x) dx                                     <span class="k">\\</span>
                                                   <span class="p">&amp;</span> =  <span class="k">\int</span><span class="p">_</span>x f(x) (<span class="k">\nabla</span><span class="p">_{</span><span class="k">\mu</span><span class="p">}</span> <span class="k">\log</span> q<span class="p">_{</span><span class="k">\mu</span><span class="p">}</span>(x))  q<span class="p">_{</span><span class="k">\mu</span><span class="p">}</span>(x) dx                 <span class="k">\\</span>
                                                   <span class="p">&amp;</span> = <span class="k">\mathbb</span><span class="p">{</span>E<span class="p">}_{</span>x <span class="k">\sim</span> q<span class="p">_{</span><span class="k">\mu</span><span class="p">}}</span> <span class="k">\left</span>(f(x) <span class="k">\nabla</span><span class="p">_{</span><span class="k">\mu</span><span class="p">}</span> <span class="k">\log</span> q<span class="p">_{</span><span class="k">\mu</span><span class="p">}</span>(x)<span class="k">\right</span>)
<span class="nt">\end{align*}</span></code></pre></figure>

\[\begin{align*}
    \nabla_{\mu} (\mathbb{E}_{x\sim q_{\mu}} f(x)) &amp; = \nabla_{\mu} \int_x f(x) q_{\mu}(x) dx                                     \\
                                                   &amp; =  \int_x f(x) (\nabla_{\mu} \log q_{\mu}(x))  q_{\mu}(x) dx                 \\
                                                   &amp; = \mathbb{E}_{x \sim q_{\mu}} \left(f(x) \nabla_{\mu} \log q_{\mu}(x)\right)
\end{align*}\]

<p>The spacing is much more comfortable now.</p>

<h2 id="command-mistakes">Command Mistakes</h2>
<p>We now look at some mistakes that arise from using the wrong commands.</p>

<h3 id="math-operators">Math Operators</h3>
<p>Instead of <code class="language-plaintext highlighter-rouge">sin (x)</code> \((sin(x))\) or <code class="language-plaintext highlighter-rouge">log (x)</code> \((log (x))\), use <code class="language-plaintext highlighter-rouge">\sin (x)</code> \((\sin (x))\)
and <code class="language-plaintext highlighter-rouge">\log (x)</code> \((\log (x))\). The idea extends to many other common math functions.
These are math operators that will de-italicize the commands
and also take care of the appropriate math-mode spacing between characters:</p>

<table class="table table-sm">
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">O(n log n)</code></td>
      <td>\(O(n log n)\)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">O(n \log n)</code></td>
      <td>\(O(n \log n)\)</td>
    </tr>
  </tbody>
</table>

<p>Many times there is a math operator that you need to use repeatedly, but which does
not come out of the box. You can define custom math operators with
the <code class="language-plaintext highlighter-rouge">\DeclareMathOperator</code> command. For instance, here are some commonly used in probability:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="k">\DeclareMathOperator*</span><span class="p">{</span><span class="k">\Pr</span><span class="p">}{</span><span class="k">\mathbf</span><span class="p">{</span>Pr<span class="p">}}</span>
<span class="k">\DeclareMathOperator*</span><span class="p">{</span><span class="k">\E</span><span class="p">}{</span><span class="k">\mathbf</span><span class="p">{</span>E<span class="p">}}</span>
<span class="k">\DeclareMathOperator*</span><span class="p">{</span><span class="k">\Ex</span><span class="p">}{</span><span class="k">\mathbf</span><span class="p">{</span>E<span class="p">}}</span>
<span class="k">\DeclareMathOperator*</span><span class="p">{</span><span class="k">\Var</span><span class="p">}{</span><span class="k">\mathbf</span><span class="p">{</span>Var<span class="p">}}</span>
<span class="k">\DeclareMathOperator*</span><span class="p">{</span><span class="k">\Cov</span><span class="p">}{</span><span class="k">\mathbf</span><span class="p">{</span>Cov<span class="p">}}</span>
<span class="k">\DeclareMathOperator*</span><span class="p">{</span><span class="k">\stddev</span><span class="p">}{</span><span class="k">\mathbf</span><span class="p">{</span>stddev<span class="p">}}</span></code></pre></figure>

<p>Then you can use it as follows:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="k">\Pr</span> <span class="k">\left</span><span class="na">[ X \geq a \right]</span> <span class="k">\leq</span> <span class="k">\frac</span><span class="p">{</span><span class="k">\Ex</span><span class="na">[X]</span><span class="p">}{</span>a<span class="p">}</span></code></pre></figure>

\[\Pr \left[ X \geq a \right] \leq \frac{\Ex[X]}{a}\]

<h3 id="double-quotes">Double quotes</h3>
<p>This is more of a rookie mistake since it’s visually very obvious something is
wrong. Double quotes don’t work the way you would expect:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="k">\text</span><span class="p">{</span>"Hello World!"<span class="p">}</span></code></pre></figure>

\[\text{"Hello World!"}\]

<p>Instead, surround them in double backticks and single quotes, which is 
supposed to be reminiscent of the directional strokes of an actual double quote.
This allows it to know which side to orient the ticks:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="k">\text</span><span class="p">{</span>``Hello World!''<span class="p">}</span></code></pre></figure>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/latex-mistakes/quotes.webp" class="z-depth-1 center" width="100px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Output of correct usage of quotes
    </figcaption>
</figure>

<p>Unfortunately I had to demonstrate this with a screenshot since MathJax only
performs math-mode typesetting, but this is an instance of text-mode typesetting.</p>

<h3 id="epsilons">Epsilons</h3>
<p>This is a common mistake due to laziness. Many times, people use <code class="language-plaintext highlighter-rouge">\epsilon</code> (\(\epsilon\))
when they really meant to write <code class="language-plaintext highlighter-rouge">\varepsilon</code> (\(\varepsilon\)). For instance, in analysis
this is usually the case, and therefore writing <code class="language-plaintext highlighter-rouge">\epsilon</code> results in a very uncomfortable
read:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/latex-mistakes/epsilon-wrong.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Using "\epsilon" looks weird
    </figcaption>
</figure>

<p>Using <code class="language-plaintext highlighter-rouge">\varepsilon</code> makes the reader feel much more at peace:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/latex-mistakes/epsilon-right.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      "\varepsilon" is usually what should be used
    </figcaption>
</figure>

<p>Similarly, people tend to get lazy and mix up <code class="language-plaintext highlighter-rouge">\phi, \Phi, \varphi</code> (\(\phi, \Phi, \varphi\)),
since they are “about the same”.  Details matter!</p>

<h3 id="sets-mathbbm-instead-of-mathbb">Sets: <code class="language-plaintext highlighter-rouge">mathbbm</code> Instead Of <code class="language-plaintext highlighter-rouge">mathbb</code></h3>
<p>For sets like \(\mathbb{N}\), you should use <code class="language-plaintext highlighter-rouge">\mathbbm{N}</code>
(from <code class="language-plaintext highlighter-rouge">bbm</code> package) instead of <code class="language-plaintext highlighter-rouge">mathbb{N}</code> (from <code class="language-plaintext highlighter-rouge">amssymb</code>). See the
difference in how the rendering of the set of natural numbers
\(\mathbb{N}\) differs, using the same example as the previous section:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/latex-mistakes/mathbbm.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Use `mathbbm` instead of `mathbb`
    </figcaption>
</figure>

<p><code class="language-plaintext highlighter-rouge">mathbbm</code> causes the symbols to be bolded, which is what you want.</p>

<h3 id="dots">Dots</h3>
<p><code class="language-plaintext highlighter-rouge">...</code>  and <code class="language-plaintext highlighter-rouge">\dots</code> are different. See the difference:</p>

<figure class="highlight"><pre><code class="language-latex" data-lang="latex">X = <span class="k">\left</span>( X<span class="p">_</span>1, ..., X<span class="p">_</span>n <span class="k">\right</span>)
X = <span class="k">\left</span>( X<span class="p">_</span>1, <span class="k">\dots</span>, X<span class="p">_</span>n <span class="k">\right</span>)</code></pre></figure>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/latex-mistakes/dots.webp" class="z-depth-1 center" width="300px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Output of "..." versus "\dots"
    </figcaption>
</figure>

<p>When using “…”, the spacing between each dot, and between the final dot
and the comma character is wrong. Always use “\dots”.</p>

<h3 id="summation-and-product">Summation and Product</h3>
<p>When writing summation or products of terms, use <code class="language-plaintext highlighter-rouge">\sum</code> and <code class="language-plaintext highlighter-rouge">\prod</code> instead of <code class="language-plaintext highlighter-rouge">\Sigma</code> and <code class="language-plaintext highlighter-rouge">\Pi</code>. This helps to handle the
relative positioning of the limits properly, and is much more idiomatic to read
from the raw script:</p>

<table class="table table-bordered table-sm">
  <thead>
    <tr>
      <th>Raw LaTeX</th>
      <th>Rendered</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">\Sigma_{i=1}^n X_i</code></td>
      <td>\(\Sigma_{i=1}^n X_i\)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">\sum_{i=1}^n X_i</code></td>
      <td>\(\sum_{i=1}^n X_i\)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">\Pi_{i=1}^n X_i</code></td>
      <td>\(\Pi_{i=1}^n X_i\)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">\prod_{i=1}^n X_i</code></td>
      <td>\(\prod_{i=1}^n X_i\)</td>
    </tr>
  </tbody>
</table>

<h3 id="multiplication">Multiplication</h3>
<p>To denote multiplication, use <code class="language-plaintext highlighter-rouge">\cdot</code> or <code class="language-plaintext highlighter-rouge">times</code> instead of <code class="language-plaintext highlighter-rouge">*</code>. See the difference below
in the equation:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/latex-mistakes/multiplication.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Use "\cdot" looks much better than "*"
    </figcaption>
</figure>

<h3 id="mid">Mid</h3>
<p>For set builder notation or conditional probability, use <code class="language-plaintext highlighter-rouge">\mid</code> instead of the pipe <code class="language-plaintext highlighter-rouge">|</code>.
This helps to handle the spacing between the terms properly:</p>

<table class="table table-bordered table-sm">
  <thead>
    <tr>
      <th>Raw LaTeX</th>
      <th>Rendered</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">p(\mathbf{z}, \mathbf{x}) = p(\mathbf{z}) p(\mathbf{z} | \mathbf{z})</code></td>
      <td>\(p(\mathbf{z}, \mathbf{x}) = p(\mathbf{z}) p(\mathbf{z} | \mathbf{z})\)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">p(\mathbf{z}, \mathbf{x}) = p(\mathbf{z}) p(\mathbf{z} \mid \mathbf{z})</code></td>
      <td>\(p(\mathbf{z}, \mathbf{x}) = p(\mathbf{z}) p(\mathbf{z} \mid \mathbf{z})\)</td>
    </tr>
  </tbody>
</table>

<h3 id="angle-brackets">Angle Brackets</h3>
<p>When writing vectors, use the <code class="language-plaintext highlighter-rouge">\langle</code> and <code class="language-plaintext highlighter-rouge">\rangle</code> instead of the keyboard angle brackets:</p>

<table class="table table-bordered table-sm">
  <thead>
    <tr>
      <th>Raw LaTeX</th>
      <th>Rendered</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">&lt;u, v&gt;</code></td>
      <td>\(&lt;u, v&gt;\)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">\langle u, v \rangle</code></td>
      <td>\(\langle u, v \rangle\)</td>
    </tr>
  </tbody>
</table>

<h3 id="labels">Labels</h3>
<p>Use <code class="language-plaintext highlighter-rouge">\label</code> to label your figures, equations, tables, and so on, and reference them using <code class="language-plaintext highlighter-rouge">\ref</code>, instead of hardcoding the number. 
For instance, <code class="language-plaintext highlighter-rouge">\label{fig:myfig}</code> and <code class="language-plaintext highlighter-rouge">\ref{fig:myfig}</code>.
Including the type of the object in the tag helps to keep track
of what it is and ensures that you are referencing it correctly, i.e
making sure you write <code class="language-plaintext highlighter-rouge">Figure \ref{fig:myfig}</code> instead of accidentally saying
something like <code class="language-plaintext highlighter-rouge">Table \ref{fig:myfig}</code>.</p>

<h2 id="conclusion">Conclusion</h2>
<p>That was a lot, and I hope it has been a helpful read! 
I will continue updating this post in the future as and when I feel like
there are other important things which should be noted which I missed.</p>

<p>I would like to thank my friend <a href="https://github.com/zack-lee">Zack Lee</a> for reviewing this
article and for providing valuable suggestions.
I would also like to express my thanks to <a href="http://www.cs.cmu.edu/~odonnell/">Ryan
O’Donnell</a>, and my 15-751 A Theorist’s Toolkit
TAs <a href="https://jthsieh.github.io/">Tim Hsieh</a> and <a href="https://www.cs.cmu.edu/~eyolcu/">Emre
Yolcu</a> for helping me realize a lot of the
style-related LaTeX issues mentioned in this post, many of which I made
personally in the past.</p>]]></content><author><name>fanpu</name></author><category term="code" /><category term="general" /><summary type="html"><![CDATA[When was the first time you had to use LaTeX? If you are like most people, it was probably suddenly forced upon you during your first math or CS class where you had to start writing proofs, with minimal guidance on how to get started. Unfortunately, this meant that while many people have good operational knowledge of LaTeX, there are still many small mistakes and best practices which are not followed, which are not corrected by TAs as they are either not severe enough to warrant a note, or perhaps even the TAs themselves are not aware of them. In this post, we cover some common mistakes that are made by LaTeX practitioners (even in heavily cited papers), and how to address them.]]></summary></entry><entry><title type="html">A Concise Proof of the Central Limit Theorem, and Its Actually Useful Version, the Berry-Esseen Theorem</title><link href="https://fanpu.io/blog/2022/central-limit-theorem-and-berry-esseen/" rel="alternate" type="text/html" title="A Concise Proof of the Central Limit Theorem, and Its Actually Useful Version, the Berry-Esseen Theorem" /><published>2022-12-28T00:00:00+00:00</published><updated>2022-12-28T00:00:00+00:00</updated><id>https://fanpu.io/blog/2022/central-limit-theorem-and-berry-esseen</id><content type="html" xml:base="https://fanpu.io/blog/2022/central-limit-theorem-and-berry-esseen/"><![CDATA[<p>The Central Limit Theorem is widely used in statistics and machine learning,
as it allows us to assume that given enough samples, the mean of the samples
will follow a normal distribution. This holds even if the samples come
from a distribution that is not normally distributed.
In this post, we prove the Central Limit Theorem, and then take a look
at the Berry-Esseen Theorem, which actually provides a quantitative bound
on the convergence of the distribution and can therefore be actually used in
deriving theoretical bounds.</p>

<h3 id="the-central-limit-theorem">The Central Limit Theorem</h3>

<p>The Central Limit states that the mean of an appropriately transformed random variable
converges in distribution to a standard normal. We first need to introduce the 
definition of convergence of probability distributions:</p>

<div class="definition">
    <div class="theorem-title">Definition
        
        
            (Convergence in Distribution)
        
    </div>
    <div class="theorem-contents">
        
  Let \( F_{X_n} \) and \( F_{X} \) denotes the cumulative density functions (CDF) of 
  \( X_n \) and \( X \) respectively.

  A sequence \( X_n \) converges to \( X \) in distribution if
  $$ \lim_{n \to \infty } F_{X_n}(t) = F_X (t)$$
  
  for all points \( t \) where \( F_X \) is continuous.
  
    </div>
</div>

<p>Note that the requirement that it only holds for points of continuity is not superfluous, as there
can be distributions that converge but disagree in value at points of discontinuities
(i.e take \(X_n = N(0, 1/n)\) and \(X\) to be the point mass at 0, they converge but their CDF take different values at \(t=0\)).</p>

<p>The Central Limit Theorem can then be stated in the following form (there are many other equivalent statements):</p>

<div class="theorem">
    <div class="theorem-title">Theorem
        
        
            (Central Limit Theorem)
        
    </div>
    <div class="theorem-contents">
        
  Let \( X_1, X_2, \dots, X_n \) be a sequence of independent random variables with mean \( \mu \) and variance \( \sigma^2 \).
  Assume that the moment generating function \( \mathbb{E} \left[ \exp(t X_i) \right] \) is finite for \( t \) in a neighborhood around zero.
  Let \( \overline{X}_n = \frac{1}{n} \sum\limits_{i=1}^n X_i \). Let
  
  $$ Z_n = \frac{\sqrt{n} \left( \overline{X}_n - \mu \right)}{\sigma}. $$
  
  Then \( Z_n \) converges in distribution to \( Z \sim N(0, 1) \).
  
    </div>
</div>

<h3 id="proof-of-the-central-limit-theorem">Proof of the Central Limit Theorem</h3>

<p>There are several ways of proving the Central Limit Theorem. 
The proof that we will explore today relies on the methods of moments.
An alternative measure-theoretic version of the proof relies on Lévy’s
Continuity Theorem, and makes use of convolutions and Fourier transforms.</p>

<p>Our goal is to show that \(Z_n\) converges in distribution to \(Z \sim N(0,
1)\). To do so, we will show that all the moments of \(Z_n\) converges to
the respective moments of \(Z\).</p>

<h4 id="moment-generating-functions">Moment Generating Functions</h4>
<p>The moments of a random variable can be obtained from its moment-generating function (MGF),
defined as follows:</p>

<div class="definition">
    <div class="theorem-title">Definition
        
        
            (Moment Generating Function)
        
    </div>
    <div class="theorem-contents">
        
  The moment generating function of a random variable \( X \) is given by
  
  $$ M_X(t) = \mathbb{E} \left[ e^{tX} \right].$$
  
    </div>
</div>

<p>It is called a moment generating function since the \(k\)th moment of \(X\),
i.e \(\mathbb{E} \left[X^k \right]\), can be obtained by taking the
\(k\)th derivative of its moment-generating function (MGF) at 0:</p>

\[\mathbb{E} \left[X^k \right]  = M^{(k)}(0).\]

<p>This is not too hard to see by induction on the fact that
\(M_X^k(t) = \mathbb{E} \left[ X^k e^{tX} \right]\). The base case is trivial. 
For the inductive case,</p>

\[\begin{align*}
    M_X^{(k)}(t) &amp; = \frac{d^k}{dt^k} \mathbb{E} \left[ e^{tX} \right] \\ 
               &amp; = \frac{d}{dt} \mathbb{E} \left[ X^{k-1} e^{tX} \right] &amp; \text{(by IH)}\\
               &amp; = \frac{d}{dt} \int f(x) x^{k-1} e^{tx} \; dx \\ 
               &amp; = \int \frac{d}{dt} f(x) x^{k-1} e^{tx} \; dx \\
               &amp; = \int f(x) x^{k} e^{tx} \; dx \\
               &amp; = \mathbb{E} \left[ X^{k} e^{tX} \right].
\end{align*}\]

<p>Substituting \(t=0\) gives us the desired result.</p>

<h4 id="normal-distribution-is-determined-by-its-moments">Normal Distribution is Determined by its Moments</h4>
<p>Distributions are determined uniquely by its moments under certain conditions. This is made precise
in the following theorem:</p>

<div class="theorem">
    <div class="theorem-title">Theorem
        
        
            (Sufficient Condition for Distribution to be Determined by Moments)
        
    </div>
    <div class="theorem-contents">
        
  Let \( s_0 &gt; 0 \), and let \( X \) be a random variable with moment generating
  function \( M_X(s) \) which is finite for \( |s| &lt; s_0 \). Then \( f_X \)
  is determined by its moments (and also by \( M_X(s)\)).
  
    </div>
</div>

<p>In words, it means that for some open interval around 0 we have that all moments are finite,
then the moments determine the distribution. This is true for the normal distribution,
where it can be shown that the following recurrence holds for the \(k\)th moment:</p>

\[M^k(t) = \mu M^{k-1}(t) + (k-1) \sigma^2 M^{k-2}(t).\]

<p>This is also not hard to show by induction, and the proof is omitted for brevity. Since the
first two moments of the standard normal distribution are 1 and 0 respectively which are both finite,
and our mean and standard deviation are both finite, then all our moments generated by the
recurrence must also be finite. So our standard normal is determined by its moments.</p>

<h4 id="method-of-moments">Method of Moments</h4>
<p>Now cue the theorem that ties things together:</p>

<div class="theorem">
    <div class="theorem-title">Theorem
        
        
            (Method of Moments)
        
    </div>
    <div class="theorem-contents">
        
  Suppose that \( X \) is determined by its moments. Let \( X_n \) be a sequence of
  distributions, such that \( \int f_{X_n}(x) x^k \; dx \) is finite for all \( n, k \in \N \),
  and such that \( \lim_{n \to \infty} \int f_{X_n}(x) x^k \; dx = \int f_{X}(x) x^k \; dx \)
  for each \( k \in \N \). Then \( X_n \) converges in distribution to \( X \).
  
    </div>
</div>

<p>In words, it states that if the \(k\)th moment of \(X_n\) is finite and converges to the \(k\)th moment
of \(X\) in the limit of \(n\), then \(X_n\) converges to \(X\).</p>

<p>This is great, since now we just have to show that all the moments of 
\(Z_n = \frac{\sqrt{n} \left( \overline{X}_n - \mu \right)}{\sigma}\) converges to
the moments of the standard normal \(Z\).</p>

<h3 id="moment-generating-function-of-z">Moment Generating Function of \(Z\)</h3>
<p>Let’s first find the moment generating function of \(Z\):</p>

\[\begin{align*}
    M_{Z} &amp; = \mathbb{E} \left[ e^{tZ} \right]                                                                                                \\
          &amp; = \int f_Z(x) e^{tx} \; dx                                                                                                \\
          &amp; = \int \frac{1}{\sqrt{2 \pi}} e^{-\frac{1}{2}x^2} e^{tx} \; dx                 &amp; \text{(subst. pdf of standard Gaussian)} \\
          &amp; = \int \frac{1}{\sqrt{2 \pi}} e^{-\frac{1}{2}x^2 + tx} \; dx                                                              \\
          &amp; = \int \frac{1}{\sqrt{2 \pi}} e^{-\frac{1}{2}(x - t)^2 + \frac{1}{2}t^2} \; dx &amp; \text{(completing the square)}           \\
          &amp; = e^{\frac{1}{2}t^2} \int \frac{1}{\sqrt{2 \pi}} e^{-\frac{1}{2}(x - t)^2 } \; dx &amp; \text{($e^{\frac{1}{2}t^2}$ does not depend on $x$)}           \\
          &amp; = e^{\frac{1}{2}t^2} \cdot  1 \\
          &amp; = e^{\frac{1}{2}t^2},
\end{align*}\]

<p>where the second last step comes from the fact that
\(\frac{1}{\sqrt{2 \pi}} e^{-\frac{1}{2}(x - t)^2 }\) is a probability distribution of a Gaussian with mean \(t\) and variance 1, 
and therefore the integral integrates to 1.</p>

<h3 id="moment-generating-function-of-z_n">Moment Generating Function of \(Z_n\)</h3>

<p>Now we find the moment generating function of \(Z_n\). 
To simplify notation, define
\(A_i = \frac{X_i - \mu}{\sigma}\),
and see that we can write \(Z_n = \frac{1}{\sqrt{n}} \sum\limits_{i=1}^n A_i\), since</p>

\[\begin{align*}
    \frac{1}{\sqrt{n}} \sum\limits_{i=1}^n A_i
    &amp;= \frac{1}{\sqrt{n}} \sum\limits_{i=1}^n \frac{X_i - \mu}{\sigma} \\
    &amp;= \sqrt{n} \sum\limits_{i=1}^n \frac{X_i - \mu}{ n \sigma} \\
    &amp;= \sqrt{n} \frac{\overline{X}_n - \mu}{ \sigma} \\
    &amp;= Z_n.
\end{align*}\]

<p>See that \(\mathbb{E}[A_i] = 0\), and \(\mathbf{Var}(A_i) = 1\).</p>

<p>Then starting from the definition of the moment generating function of \(Z_n\),</p>

\[\begin{align*}
    M_{Z_n}(t) &amp; = \mathbb{E} \left[ e^{t Z_n} \right]                                                                                                   \\
               &amp; = \mathbb{E} \left[ \exp\left(t \frac{1}{\sqrt{n}} \sum\limits_{i=1}^n A_i \right) \right] &amp; \text{(by equivalent definition of $Z_n$)} \\
               &amp; = \prod_{i=1}^n \mathbb{E} \left[ \exp\left( \frac{t}{\sqrt{n}} A_i \right) \right]        &amp; \text{(by independence of $A_i$'s)}        \\
               &amp; = \prod_{i=1}^n M_{A_i}(t/\sqrt{n})                                                &amp; \text{(definition of $M_{A_i}$)}           \\
               &amp; = M_{A_i}(t/\sqrt{n} )^n.
\end{align*}\]

<p>Let’s analyze each individual term \(M_{A_i}(t / \sqrt{n})\) by performing a Taylor expansion around 0.
Recall that the Taylor expansion of a function \(f(x)\) about a point \(a\) is
given by 
\(f(x)= \sum\limits_{n=0}^\infty \frac{f^{(n)(a)}}{n!}(x-a)^n.\). We will expand up to the
second order term, which requires us to find the first three moments of the MGF.</p>

<p>These are:</p>

\[\begin{align*}
    M_{A_i}(0)                 &amp; = \mathbb{E} \left[ e^{t A_i} \right] \Big|_{t=0}                                                                                                                 \\
                               &amp; = \mathbb{E} \left[ 1 \right]                                                                                                                                     \\
                               &amp; = 1,                                                                                                                                                      \\
    M_{A_i}^\prime(0)          &amp; = \mathbb{E} \left[ A_i \right]                                                       &amp; \text{(by the $k$th moment property proved previously)}                   \\
                               &amp; = 0,                                                                                                                                                      \\
    M_{A_i}^{\prime \prime}(0) &amp; = \mathbb{E} \left[ A_i^2 \right]                                                     &amp; \text{(by the $k$th moment property proved previously)}                   \\
                               &amp; = \mathbb{E} \left[ A_i^2 \right] - \mathbb{E} \left[ A_i \right]^2 + \mathbb{E} \left[ A_i \right]^2                                                                             \\
                               &amp; = \mathbf{Var}(A_i) + \mathbb{E} \left[ A_i \right]^2                                         &amp; \text{($\mathbf{Var}(A_i) = \mathbb{E} \left[ A_i^2 \right] - \mathbb{E} \left[ A_i \right]^2 $)} \\
                               &amp; = 1 + 0 \\
                               &amp; = 1.
\end{align*}\]

<p>Taking all terms up to the second order Taylor expansion allows us to approximate \(M_{A_i}\) as</p>

\[\begin{align*}
    M_{A_i}(t/\sqrt{n}) &amp; \approx M_{A_i}(0) + M_{A_i}^\prime(0) + M_{A_i}^{\prime \prime}(0) \frac{t^2}{2n} \\
                        &amp; = 1 + 0 + \frac{t^2}{2n}                                                           \\
                        &amp; = 1 + \frac{t^2}{2n}.
\end{align*}\]

<p>Then now we can write the limit of the MGF of \(Z_n\) as the following:</p>

\[\begin{align*}
    M_{Z_n}(t) &amp; = M_{A_i}(t/\sqrt{n})^n       \\
               &amp; \approx \left( 1 + \frac{t^2}{2n}  \right)^n \\
               &amp; \to e^{t^2/2}, &amp; \text{(by identity $\lim_{n \to \infty} (1 + x/n)^n \to e^x$)}
\end{align*}\]

<p>which shows that it converges to the MGF of \(Z\), as desired. Hooray!</p>

<h3 id="an-uncomfortable-feeling">An Uncomfortable Feeling</h3>
<p>However, there is one thing in this proof that might have bothered you.
Our result came from making use of the Taylor approximation and taking limits, 
but there is no bound on how large \(n\) must be for the distributions to converge
up to a maximum amount of error. This makes it unsuitable for much theoretical analysis,
since usually we would like to know that \(n\) does not have to be too large
for us to obtain a sufficiently good approximation to the standard normal.</p>

<h3 id="the-useful-form-of-the-central-limit-theorem-the-berry-esseen-theorem">The Useful Form of the Central Limit Theorem: The Berry-Esseen Theorem</h3>

<p>The Berry-Esseen theorem solves this limitation by also providing explicit error bounds. 
This was proved independently by Andrew Berry and Carl-Gustav Esseen in the 40s,
and the statement goes as follows:</p>

<div class="theorem">
    <div class="theorem-title">Theorem
        
        
            (Berry-Esseen)
        
    </div>
    <div class="theorem-contents">
        
    Let \( X_1, \dots, X_n \) be independent random variables.

    Assume \( \mathbb{E} [X_i] = 0 \; \forall i \).

    Write \( \sigma_i^2 = \mathbf{Var} [ X_i] = \mathbb{E}[X_i^2] - \mathbb{E}[X_i]^2 = \mathbb{E}[X_i^2] \).

    Assume \( \sum\limits_{i=1}^n \sigma_i^2 = 1 \). 

    Let \( S = \sum\limits_{i=1}^n X_i \). Then \( \forall u \in \mathbb{R}\),
    
    $$
        \lvert \Pr \left[ S \leq u \right] - \Pr \left[ Z \leq u \right] \rvert
        \leq \mbox{const} \cdot \beta,
    $$

    where the exact constant depends on the proof, with the best known constant
    being \(.5600\) proven by Shevtsova in 2010, and 
    \(\beta = \sum\limits_{i=1}^n \mathbb{E} \left[ \lvert X_i \rvert^3 \right]\).

  
    </div>
</div>

<p>In words, the theorem says that the difference between the CDF of the sum of
the mean-0 random variables and the CDF of the standard normal is bounded by a
value proportionate to the third moment. This then becomes useful as a tool in
proving high probability statements if we can show that the third moment is
inversely polynomially small, i.e \(\beta = 1/\text{poly}(n)\).</p>

<p>Another thing to note is that the theorem only provides an absolute bound for all values of \(u\).
Therefore, when \(u\) is very negative and \(\Pr [Z \leq u ] = \Phi(u)\) is very small, the
relative error is actually very large, and therefore is not as helpful.</p>

<p>I hope this article has been helpful!</p>

<p><em>I would like to express my thanks to my friend <a href="https://adbforlife.github.io/">Albert Gao</a>
for reviewing this article and for providing valuable suggestions</em>.</p>

<h3 id="references">References</h3>
<ul>
  <li>Rosenthal, J. S. (2016). A first look at rigorous probability theory. World Scientific.</li>
  <li>Larry Wasserman, CMU 36-705 Intermediate Statistics Lecture Notes. URL: <a href="https://www.stat.cmu.edu/~larry/=stat705/">https://www.stat.cmu.edu/~larry/=stat705/</a></li>
  <li>Ryan O’Donnell, CMU 15-751 A Theorist’s Toolkit. URL: <a href="https://www.youtube.com/watch?v=Ig5TuZauhW4">https://www.youtube.com/watch?v=Ig5TuZauhW4</a></li>
</ul>]]></content><author><name>fanpu</name></author><category term="math" /><category term="machine-learning" /><summary type="html"><![CDATA[The Central Limit Theorem is widely used in statistics and machine learning, as it allows us to assume that given enough samples, the mean of the samples will follow a normal distribution. This holds even if the samples come from a distribution that is not normally distributed. In this post, we prove the Central Limit Theorem, and then take a look at the Berry-Esseen Theorem, which actually provides a quantitative bound on the convergence of the distribution and can therefore be actually used in deriving theoretical bounds.]]></summary></entry><entry><title type="html">Reinforcement Learning Policy Optimization: Deriving the Policy Gradient Update</title><link href="https://fanpu.io/blog/2022/deriving-the-policy-gradient-update/" rel="alternate" type="text/html" title="Reinforcement Learning Policy Optimization: Deriving the Policy Gradient Update" /><published>2022-12-26T00:00:00+00:00</published><updated>2022-12-26T00:00:00+00:00</updated><id>https://fanpu.io/blog/2022/deriving-the-policy-gradient-update</id><content type="html" xml:base="https://fanpu.io/blog/2022/deriving-the-policy-gradient-update/"><![CDATA[<p>Reinforcement learning algorithms that learn a policy (as opposed to implicit policy
methods like \(\epsilon\)-greedy) optimize their policies by
updating their policies in the direction of the gradient. However, 
the precise environment dynamics are not usually known to us, 
and the state space is usually also too large to enumerate, which means that
we still cannot compute the gradient analytically. In this post, we derive
the policy gradient update from scratch, and show how it can be approximated
by sampling sufficiently many trajectories.</p>

<h2 id="optimization-objective">Optimization Objective</h2>
<p>Our goal is to train an agent that is able to maximize its rewards in a given task.
For instance, its goal could be to balance a cartpole for as long as possible, where
for each time step the pole does not fall down, the agent receives 1
reward, and when the pole falls down the episode is terminated and
the agent no longer receives any rewards:</p>

<figure>
  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/cartpole.gif" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture><figcaption class="caption">
      Balancing a cartpole, OpenAI Gym
    </figcaption>
</figure>

<p>Formally, we want to maximize the expected rewards for our policy over the trajectories
that it visits. A trajectory \(\tau\) is defined as state-action pairs
\(\tau = (s_0, a_0, s_1, a_1, \dots, s_H, a_H, s_{H+1})\), where \(H\) is horizon of the trajectory,
i.e the duration until the episode is terminated, and \(s_t, a_t\) are the states and actions
performed at each time step \(t\).</p>

<p>This can be formalized as the following objective:</p>

\[\begin{align}
     &amp; \max_\theta \mathbb{E}_{\tau \sim P_\theta(\tau)} [R(\tau)] \\
   = &amp; \max_\theta \sum\limits_\tau P_\theta(\tau) R(\tau) \\
   = &amp; \max_\theta U(\theta),
\end{align}\]

<p>where \(\tau\) refers to a trajectory of state-action pairs, \(P_\theta(\tau)\)
denotes the probability of experiencing trajectory \(\tau\) under policy \(\theta\),
and \(R(\tau)\) is the reward under trajectory \(\tau\),
and \(U(\theta)\) is shorthand for the expression for brevity.</p>

<p>The probability of \(P_\theta(\tau)\) is given by the following:</p>

\[\begin{align}
    P_\theta(\tau) = \prod_{t=0}^H P(s_{t+1} \mid s_t, a_t) \cdot \pi_\theta (a_t \mid s_t),
\end{align}\]

<p>where in words, it is the product over each time step \(t\),
of the probability of taking the action at time \(t\) in the trajectory \(a_t\)
when we were in state \(s_t\) under our policy \(\pi_\theta\), given by \(\pi_\theta(a_t \mid s_t)\),
multiplied by the probability that the environment transitions us from \(s_t\) to
\(s_{t+1}\) given that we performed action \(a_t\). Note that we do not
necessarily know this environment transition probability \(P(s_{t+1} \mid s_t, a_t)\).</p>

<h2 id="deriving-the-gradient-update">Deriving the Gradient Update</h2>

<p>To perform a gradient-based update on \(\theta\) to increase the reward, we 
need to compute the derivative with respect to our policy \(\theta\), i.e
\(\nabla_\theta \mathbb{E}_{\tau \sim P(\tau; \theta)} [R(\tau)]\). 
Let’s walk through the derivation step by step:</p>

\[\begin{align*}
    \nabla_\theta \mathbb{E}_{\tau \sim P_\theta(\tau)} [R(\tau)]
     &amp; = \nabla_\theta \sum\limits_\tau P_\theta(\tau) R(\tau) \\
     &amp; = \sum\limits_\tau \nabla_\theta  P_\theta(\tau) R(\tau) &amp; \text{(uh oh...)}\\
\end{align*}\]

<p>It appears that we are already stuck here, since 
\(\nabla_\theta P_\theta(\tau)\) will result in many
repeated applications of the chain rule since \(P_\theta(\tau)\)
is a huge product containing our policy transition probabilities,
and will quickly get out of hand to be computed feasibly.</p>

<p>Instead, the trick is to multiply by 1 on the left:</p>

\[\begin{align*}
    \sum\limits_\tau \nabla_\theta  P_\theta(\tau) R(\tau)
    &amp;= \sum\limits_\tau \frac{ P_\theta(\tau) }{ P_\theta(\tau) } \nabla_\theta  P_\theta(\tau) R(\tau) &amp; \text{(multiplying by 1)} \\
    &amp;= \sum\limits_\tau P_\theta(\tau) \frac{ \nabla_\theta  P_\theta(\tau)  }{ P_\theta(\tau) } R(\tau) &amp; \text{(rearranging)} \\
    &amp;= \sum\limits_\tau P_\theta(\tau) \nabla_\theta  \log  P_\theta(\tau) R(\tau) &amp; \text{($\frac{d}{dx} \log f(x) = \frac{f'(x)}{f(x)} $)} \\
    &amp;= \mathbb{E}_{\tau \sim P_\theta(\tau)} \left[ \nabla_\theta  \log  P_\theta(\tau) R(\tau)  \right] \\
    &amp;\approx \frac{1}{N} \sum\limits_{i=1}^N \nabla_\theta  \log  P_\theta(\tau_i) R(\tau_i), \\
\end{align*}\]

<p>where we can use \(\frac{1}{N} \sum\limits_{i=1}^N \nabla_\theta  \log  P_\theta(\tau_i) R(\tau_i)\) as our estimator, which converges
to the true expectation as our number of trajectory samples \(N\) increases.</p>

<p>We can compute \(\nabla_\theta  \log  P_\theta(\tau_i)\) for each sampled trajectory \(\tau_i\),
and then take their average. This can be done as follows:</p>

\[\begin{align*}
    \nabla_\theta  \log  P_\theta(\tau_i)
     &amp; = \nabla_\theta  \log  P_\theta(s_0, a_0, \dots, s_H, a_H, s_{H+1}) \\
     &amp; = \nabla_\theta  \log  \left[
        \prod_{t=0}^H P(s_{t+1} \mid s_t, a_t) \cdot \pi_\theta (a_t \mid s_t),
    \right]                          \\
     &amp; = \nabla_\theta  \left[
        \sum\limits_{t=0}^H \log P(s_{t+1} \mid s_t, a_t) + \log \pi_\theta (a_t \mid s_t)
        \right] \\
     &amp; = \nabla_\theta \sum\limits_{t=0}^H \log \pi_\theta (a_t \mid s_t) \\
     &amp; \qquad \qquad \text{(first term does not depend on $\theta$, becomes zero)} \\
     &amp; = \sum\limits_{t=0}^H \nabla_\theta \log \pi_\theta (a_t \mid s_t),\\
\end{align*}\]

<p>where the last expression is easily computable for models such as neural
networks since it is end-to-end differentiable.</p>

<p>With the approximate gradient
\(\nabla_\theta U(\theta)\)
in hand, we can now perform our policy gradient update as</p>

\[\begin{align*}
    \theta_{\mbox{new}} = \theta_{\mbox{old}} + \alpha \nabla_\theta U(\theta),
\end{align*}\]

<p>for some choice of step size \(\alpha\).</p>

<h2 id="takeaways">Takeaways</h2>
<p>In this post, we saw from first principles how taking the gradients
of many sampled trajectories does indeed converge to the true policy gradient.</p>

<p>This method of multiplying by 1 to pull out a probability term so that
a summation can be converted into an expectation is widely used
in machine learning, such as for computing variational autoencoder (VAE) loss.
It is known as the log derivative trick.</p>

<p>The estimator \(\frac{1}{N} \sum\limits_{i=1}^N \nabla_\theta  \log
P_\theta(\tau_i) R(\tau_i)\) is also sometimes known as the REINFORCE
estimator, after the popular REINFORCE algorithm.</p>

<p>One limitation of this approach is that it requires \(\pi_\theta\) to be
differentiable. However, given how most RL models rely on neural networks,
this is not a significant restriction.</p>

<p>Choosing the right step size \(\alpha\) is actually not straightforward.
It is different from the offline supervised-learning context, where
you can use methods like AdaGrad or RMSProp which adaptively
chooses a learning rate for you, and even if the learning rate
was not optimal it just takes more iterations to converge.
On the other hand, in reinforcement learning,
a learning rate that is too small results in inefficient use
of trajectory samples as they cannot be trivially re-used
since it depends on your current policy, and a learning
rate that is too large can result in the policy becoming bad,
which is difficult to recover from since future trajectories
would also become bad.</p>

<p>We will discuss three important methods to
choose an appropriate step size in a future post: Natural Policy Gradients,
Proximal Policy Optimization (PPO), and Trust Region Policy Optimization
(TRPO). Hope to see you around!</p>

<p><em>I would like to express my thanks to my friend <a href="https://jytan.net/about/">Jun Yu Tan</a>
for reviewing this article and for providing valuable suggestions</em>.</p>

<h2 id="references">References</h2>
<ul>
  <li><a href="https://cmudeeprl.github.io/703website_f22/lectures/">Carnegie Mellon University 10-703 Deep Reinforcement Learning and Control Course Slides</a></li>
</ul>]]></content><author><name>fanpu</name></author><category term="machine-learning" /><summary type="html"><![CDATA[Reinforcement learning algorithms that learn a policy (as opposed to implicit policy methods like \(\epsilon\)-greedy) optimize their policies by updating their policies in the direction of the gradient. However, the precise environment dynamics are not usually known to us, and the state space is usually also too large to enumerate, which means that we still cannot compute the gradient analytically. In this post, we derive the policy gradient update from scratch, and show how it can be approximated by sampling sufficiently many trajectories.]]></summary></entry></feed>