<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://fanpu.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://fanpu.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-01-27T05:03:57+00:00</updated><id>https://fanpu.io/feed.xml</id><title type="html">blank</title><subtitle>Fan Pu&apos;s homepage </subtitle><entry><title type="html">An Intuitive Introduction to Gaussian Processes</title><link href="https://fanpu.io/blog/2025/gaussian-processes/" rel="alternate" type="text/html" title="An Intuitive Introduction to Gaussian Processes"/><published>2025-01-21T00:00:00+00:00</published><updated>2025-01-21T00:00:00+00:00</updated><id>https://fanpu.io/blog/2025/gaussian-processes</id><content type="html" xml:base="https://fanpu.io/blog/2025/gaussian-processes/"><![CDATA[<p>Deep learning is currently dominated by parametric models, which are models with a fixed number of parameters regardless of the size of the training dataset. Examples include linear regression models and neural networks.</p> <p>However, it’s good to occasionally take a step back and remember that that is not all there is. Non-parametric models like k-NN, decision trees, or kernel density estimation don’t rely on a fixed set of weights, but instead grow in complexity based on the size of the data.</p> <p>In this post we’ll talk about Gaussian processes, a conceptually important, but in my opinion under-appreciated non-parametric approach with deep connections with modern-day neural networks. An intersting motivating fact which we will eventually show is that neural networks initialized with Gaussian weights are equivalent to Gaussian processes in the infinite-width limit.</p> <h3 id="why-is-it-called-a-gaussian-process">Why is it called a Gaussian process?</h3> <p>The behavior of a (possibly multi-dimensional) random variable can be characterized by its probability distribution, i.e the bell curve for a Gaussian random variable.</p> <p>What if we now consider the probability distribution over random functions? The generalization from variables to functions is called a stochastic process. If we restrict our attention to only processes which follow a Gaussian distribution, then the computations required for learning and inference becomes relatively easy.</p> <h3 id="motivation">Motivation</h3> <p>In this post, we concern ourselves with using Gaussian processes for supervised learning, which can take on the form of either regression or classification.</p> <p>Suppose we have a set of input points with their associated values, and we would like to find a function that interpolates through all these values.</p> <p>However, there are uncountably many such functions, and so how do you decide which is the best one to use?</p> <p>There are two approaches to this:</p> <ol> <li>You can restrict the class of functions that you consider (i.e all decision trees with depth at most 3). However, this runs the risk of choosing a hypothesis class that is too restrictive and hence you get a poor model, or otherwise one that is too large and you get overfitting.</li> <li>You can place a prior over all possible functions, where you put more probability mass on functions that have nice properties like smoothness. However, a-priori it is unclear how to compute this since there is an uncountable number of functions.</li> </ol> <p>This is where Gaussian processes come in. We can imagine a function to be an (uncountably) infinite dimensional vector, where each coordinate encodes the values that the function takes on. The goal is to restrict the set of functions to only those which are consistent with a training dataset, i.e taking on a particular value. Then the wonderful thing with Gaussian Processes is that by only considering this finite set of dataset point, you get the same model as if you considered the value at every uncountably-many point, making this computationally tractable.</p> <p>Below is an illustration of what this looks like:</p> <figure id="fig-1"> <picture> <img src="/assets/img/posts/gaussian-process/gp-prior.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 1.</i> Prior over functions before training </figcaption> </figure> <figure id="fig-2"> <picture> <img src="/assets/img/posts/gaussian-process/gp-posterior.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 2.</i> Posterior over functions after observing 2 training points </figcaption> </figure> <p>We make some preliminary observations without worrying too much about what is precisely happening yet:</p> <ol> <li>Observe via the confidence interval that our prior is centered with mean 0, and 1 standard deviation (and hence $\pm$1.96 for a 95% confidence interval).</li> <li>Notice how the confidence bands shrinks at the observed points, and increases as we get further from these points. This is due to our specific choice of kernel (explained later) used for the Gaussian process, which makes the assumption that points which are closer together tend to be more correlated in their values.</li> </ol> <p>Let’s see it try to fit a random smooth function as we increase the number of randomly sampled training datapoints:</p> <figure id="fig-3"> <picture> <img src="/assets/img/posts/gaussian-process/gp_random_sampling.gif" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 3.</i> Fitting a random smooth function by sampling training points randomly. </figcaption> </figure> <p>It is possible that sampling the underlying function is expensive, and we want to minimize the number of samples we make before getting a good fit.</p> <p>We can be smart about this by prioritizing sampling regions where there is most uncertainty:</p> <figure id="fig-4"> <picture> <img src="/assets/img/posts/gaussian-process/gp_most_uncertain_sampling.gif" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 4.</i> Fitting a random smooth function by choosing training points that currently have the most uncertainty under the model. </figcaption> </figure> <p>You can also use Gaussian processes for time-series prediction, where you can now quantify uncertain in future values. Here’s an example of predicting the price of NVDA’s over the last 120 days from when the post was written:</p> <figure id="fig-5"> <picture> <img src="/assets/img/posts/gaussian-process/gp_nvda.gif" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 5.</i> Homework: try to make some money off of this. </figcaption> </figure> <p>Well.. it certainly doesn’t really do too great here as Gaussian process kernels usually assume stationarity, which means that the statistical characteristics of the data (i.e mean, variance, autocorrelation) doesn’t change over time, which is definitely not what is happening in the stock market. Still worth a shot though!</p> <p>Hope these examples help to motivate why Gaussian processes are cool.</p> <p>Let’s now do a quick review of Bayesian modelling before diving right in.</p> <h3 id="bayesian-modeling">Bayesian Modeling</h3> <p>In Bayesian modeling, we start off with a prior that represents our beliefs about our data. For instance, before flipping a coin to determine its bias $\theta$ we can have a uniform prior $p(\theta)$ on the bias it could take. This can be represented by the beta distribution $\textrm{Beta}(\alpha=1, \beta=1)$, which is used as it happens that its posterior update is also a beta distribution with different parameters, which makes the update computationally simple.</p> <p>We perform many coin flips, and can use the results $\mathcal{D}$ to update our beliefs about $\theta$. Our new beliefs about the distribution of $\theta$ is referred to as the posterior distribution.</p> <p>The update for the posterior is given by Baye’s rule:</p> \[\textrm{posterior} = \frac{\textrm{likelihood} \times \text{prior}}{\text{marginal likelihood}},\] <p>which in this case is given by</p> \[p(\theta \mid \mathcal{D}) = \frac{ p(\mathcal{D} \mid \theta) p (\theta)}{p(\mathcal{D})} = \frac{ p(\mathcal{D} \mid \theta) p (\theta)}{\int p(\mathcal{D} \mid \theta) p(\theta) \, d \theta},\] <p>where the denominator in the second form marginalizes over all possible priors, as we usually do not know $p(\mathcal{D})$ directly.</p> <p>The posterior distribution for $\theta$ for coin flipping can be shown to also follow the beta distribution, visualized below:</p> <figure id="fig-6"> <picture> <img src="/assets/img/posts/gaussian-process/coin-flip.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 6.</i> Uniform prior and updated posterior with mean 0.7 after flipping 7 heads and 3 tails </figcaption> </figure> <p>Finally, after we have “trained” our model with our data, we can also get the probability of observing test datapoints $\mathcal{D}_*$ given our posterior. This is known as the predictive distribution, given by:</p> \[p(\mathcal{D}_* \mid \mathcal{D}) = \int p(\mathcal{D}_* \mid \theta) p(\theta \mid \mathcal{D}) \, d \theta\] <p>For instance, in the coin flipping case, the probability that we observe another heads would be the mean of the beta posterior distribution, i.e 0.7.</p> <h3 id="gaussian-processes">Gaussian Processes</h3> <h4 id="definition">Definition</h4> <p>For simplicity, let’s consider the space of real processes $f(x) : \mathbb{R} \to \mathbb{R}$ (it is straightforward to generalize this to multiple dimensions).</p> <div class="definition"> <div class="theorem-title">Definition (Gaussian Process) </div> <div class="theorem-contents"> A Gaussian process is a collection of random variables, any finite number of which have a joint Gaussian distribution. </div> </div> <p>A Gaussian process can be completely specified by its mean function $m(x)$ and covariance function $k(x, x’)$ of a real process $f(x)$, given by:</p> \[\begin{align} m(x) &amp; = \E [f(x)], \\ k(x, x') &amp; = \E_{x, x'} [(f(x) - m(x))(f(x') - m(x'))]. \end{align}\] <p>This can be written as</p> \[f(x) \sim \mathcal{GP}(m(x), k(x, x')).\] <p>For notational simplicity we will assume the mean to be zero.</p> <p>The covariance function hence places a restriction on the functions $f$ that is possible under the data.</p> <h4 id="the-covariance-function">The Covariance Function</h4> <p>A common choice for the covariance function is the squared exponential (SE) function, also called the Radial Basis Function (RBF):</p> \[\textrm{cov}(f(x), f(x')) = k(x, x') = \exp \left( -\frac{(x-x')^2}{2 \sigma^2} \right)\] <p>We see the correlation between the values that $x$ and $x’$ takes on $f$ follows a Gaussian distribution of their difference: it is close to 1 when they are close, and decays to 0 as they are farther apart.</p> <p>Here’s a visualization of the covariance matrix with $\sigma=1$ over equally spaced points:</p> <figure id="fig-1"> <picture> <img src="/assets/img/posts/gaussian-process/covariance_viz.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 1.</i> Covariance matrix of the squared exponential kernel </figcaption> </figure> <h4 id="predicting-with-gaussian-processes">Predicting with Gaussian Processes</h4> <p>For simplicity, consider the case where we make $n$ observations of data $(x_1, f_1), \cdots, (x_n, f_n)$. Use $\mathbf{X}$ and $\mathbf{f}$ to denote the vector of training inputs and outputs respectively.</p> <p>We have a set of test inputs $\mathbf{X}_*$, and we are interested to know what are likely values that it could take on given the training data.</p> <p>This means we can model the joint distribution of the training data with the test inputs as follows, where the set of possible functions must respect the structure of the covariance function:</p> \[\begin{bmatrix} \mathbf{f} \\ \mathbf{f}_* \end{bmatrix} \sim \mathcal{N} \left( \begin{bmatrix} \mathbf{0} \\ \mathbf{0} \\ \end{bmatrix}, \begin{bmatrix} \mathbf{K}(\mathbf{X}, \mathbf{X}) &amp; \mathbf{K}(\mathbf{X}, \mathbf{X}_*) \\ \mathbf{K}(\mathbf{X}_*, \mathbf{X}) &amp; \mathbf{K}(\mathbf{X}_*, \mathbf{X}_*) \end{bmatrix} \right),\] <p>One may begin to worry that this is impossible to compute, but very fortunately it turns out that the posterior is also Gaussian:</p> \[\begin{align} \mathbf{f}_* &amp; \mid \mathbf{X}_*, \mathbf{X}, \mathbf{f} \sim \mathcal{N}(\mathbf{\mu}_*, \mathbf{\Sigma}_*), \\ \text{where:}\\ \mathbf{\mu}_* &amp;= \mathbf{K}(\mathbf{X}_*, \mathbf{X}) \mathbf{K}(\mathbf{X}, \mathbf{X})^{-1} \mathbf{f}, \\ \mathbf{\Sigma}_* &amp;= \mathbf{K}(\mathbf{X}_*, \mathbf{X}_*) - \mathbf{K}(\mathbf{X}_*, \mathbf{X}) \mathbf{K}(\mathbf{X}, \mathbf{X})^{-1} \mathbf{K}(\mathbf{X}, \mathbf{X}_*). \end{align}\] <p>Then to determine what values $\mathbf{X}_*$ could take on, one approach would be to sample from this Gaussian distribution.</p> <p>\(\newcommand{\fstar}{\mathbf{f}_*} \newcommand{\mustar}{\mathbf{\mu}_*}\) Another approach using the maximum a posteriori (MAP) estimate would require simply taking the posterior mean, i.e $\fstar = \mustar$.</p> <h4 id="code-walkthrough">Code Walkthrough</h4> <p>Let’s see everything in code to make things concrete:</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/gaussian-processes/gp.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div> <h4 id="relation-to-neural-networks">Relation to Neural Networks</h4> <p>In the next blog post, we will show how a neural network initialized with Gaussian weights converges to a Gaussian process in the infinite width limit.</p>]]></content><author><name>fanpu</name></author><category term="machine-learning"/><category term="math"/><category term="statistics"/><summary type="html"><![CDATA[Deep learning is currently dominated by parametric models, which are models with a fixed number of parameters regardless of the size of the training dataset. Examples include linear regression models and neural networks. However, it's good to occasionally take a step back and remember that that is not all there is. Non-parametric models like k-NN, decision trees, or kernel density estimation don't rely on a fixed set of weights, but instead grow in complexity based on the size of the data. In this post we'll talk about Gaussian processes, a conceptually important, but in my opinion under-appreciated non-parametric approach with deep connections with modern-day neural networks. An intersting motivating fact which we will eventually show is that neural networks initialized with Gaussian weights are equivalent to Gaussian processes in the infinite-width limit.]]></summary></entry><entry><title type="html">Bounding Mixing Times of Markov Chains via the Spectral Gap</title><link href="https://fanpu.io/blog/2025/bounding-markov-chain-mixing-times-by-spectral-gap/" rel="alternate" type="text/html" title="Bounding Mixing Times of Markov Chains via the Spectral Gap"/><published>2025-01-12T00:00:00+00:00</published><updated>2025-01-12T00:00:00+00:00</updated><id>https://fanpu.io/blog/2025/bounding-markov-chain-mixing-times-by-spectral-gap</id><content type="html" xml:base="https://fanpu.io/blog/2025/bounding-markov-chain-mixing-times-by-spectral-gap/"><![CDATA[<p>A Markov chain that is aperiodic and irreducible will eventually converge to a stationary distribution. This is widely used in many applications in machine learning, such as in Markov Chain Monte Carlo (MCMC) methods, where random walks on Markov chains are used to obtain a good estimate of the log likelihood of the partition function of a model, which is hard to compute directly as it is #P-hard (this is even harder than NP-hard). However, one major issue is that it is unclear how many steps we should take before we are guaranteed that the Markov chain has converged to the true stationary distribution. In this post, we will see how the spectral gap of the transition matrix of the Markov Chain relates to its mixing time.</p> <h1 id="mixing-times">Mixing Times</h1> <p>Our goal is to try to develop methods to understand how long it takes to approximate the stationary distribution $\pi$ of a Markov Chain. Our goal is to eventually show that the mixing time is in $O\left(\frac{\log (n)}{1 - \beta}\right)$, where $\beta$ is the second largest eigenvalue of the transition matrix of the Markov Chain.</p> <h2 id="aside-coupling">Aside: Coupling</h2> <p>Coupling is one general technique that allows us to bound how long it takes for a Markov Chain to converge to its stationary distribution based. It is based on having two copies of the original Markov Chain running simultaneously, with one being at stationarity, and showing how they can be made to coincide (i.e have bounded variation distance) after some time (known as the <em>coupling time</em>).</p> <p>We will not discuss coupling in this post, but will instead develop how spectral gaps can be used, as this is more useful for other concepts.</p> <h1 id="the-spectral-gap-method">The <em>Spectral Gap</em> Method</h1> <p>The main idea of the <em>Spectral Gap</em> method is that the mixing time is bounded by the inverse of the spectral gap, which is the difference between the largest and second largest eigenvalues of the transition matrix.</p> <p>Before we can talk about one distribution approximating another, we need to first introduce what <em>closeness</em> between two distributions means The formulation that we will use is via the Total Variation Distance.</p> <div class="definition"> <div class="theorem-title">Definition (Total Variation Distance) </div> <div class="theorem-contents"> Let $\mathcal{D}_1, \mathcal{D}_2$ be distributions on $\Omega$. Then \begin{align} \| \mathcal{D}_1 - \mathcal{D}_2 \|_{TV} = &amp; \frac{1}{2} \sum\limits_{\omega \in \Omega} \Big| \mathcal{D}_1(\omega) - \mathcal{D}_2(\omega) \Big| \\ = &amp; \max_{A \subseteq \Omega} \sum\limits_{\omega \in A} \mathcal{D}_1(\omega) - \sum\limits_{\omega \in A} \mathcal{D}_2(\omega). \end{align} </div> </div> <p>The equality between the two lines can be observed from the fact that</p> \[\begin{align} \max_{A \subseteq \Omega} \sum\limits_{\omega \in A} \mathcal{D}_1(\omega) - \sum\limits_{\omega \in A} \mathcal{D}_2(\omega)= \max_{B \subseteq \Omega} \sum\limits_{\omega \in B} \mathcal{D}_2(\omega) - \sum\limits_{\omega \in B} \mathcal{D}_1(\omega), \end{align}\] <p>since both $\mathcal{D}_1, \mathcal{D}_2$ are probability distributions and integrate to 1. See <a href="#fig-1">Figure 1</a> for an illustration.</p> <figure id="fig-1"> <picture> <img src="/assets/img/posts/markov-chain-mixing-times/tv.webp" class="z-depth-1 center" width="500px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 1.</i> Total Variation distance between some sample $\mathcal{D}_1, \mathcal{D}_2$ illustrated by the sum of the shaded green regions. </figcaption> </figure> <h1 id="intuition-for-mixing-times">Intuition for Mixing Times</h1> <p>We consider how long it takes to converge on some special graphs to build up intuition.</p> <h2 id="random-walks-on-path-graphs">Random Walks on Path Graphs</h2> <p>The path graph is a line graph on $n$ vertices. We claim that the mixing time of the path graph is at least $n$: this is because it takes at least $n$ steps to even reach the rightmost vertex from the leftmost vertex.</p> <figure id="fig-2"> <picture> <img src="/assets/img/posts/markov-chain-mixing-times/random-walk-path-graph.webp" class="z-depth-1 center" width="500px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 2.</i> The path graph, $n=4$. </figcaption> </figure> <h2 id="random-walks-on-the-complete-graph">Random Walks on the Complete Graph</h2> <p>The complete graph $K_n$ on $n$ vertices is one where each vertex has an edge to every other vertex.</p> <p>This only takes 1 step to mix, since after a single step we can reach any vertex.</p> <figure id="fig-3"> <picture> <img src="/assets/img/posts/markov-chain-mixing-times/random-walk-complete-graph.webp" class="z-depth-1 center" width="300px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 3.</i> The complete graph, $K_6$. </figcaption> </figure> <p>This short analysis tells us that if our graph looks like a line graph then we should expect poor mixing times; whereas if it looks more like a complete graph then we can expect the opposite.</p> \[\newcommand{\tmix}{\tau_{\mathsf{mix}}} \newcommand{\sgap}[1]{\mathsf{spectral\_gap}(#1)}\] <h1 id="mixing-times-1">Mixing Times</h1> <p>We now formally introduce the concept of mixing times.</p> <div class="definition"> <div class="theorem-title">Definition (Mixing Time) </div> <div class="theorem-contents"> Let $\left\{ X_t \right\}$ be a finite, irreducible, aperiodic Markov Chain, $\pi$ be the stationary distribution, and $T$ to be the transition matrix. Then define \begin{align} \Delta(t) = \max_{\omega \in \Omega} \| \pi - T_\omega^t \|_{TV}, \end{align} where $T_\omega^t$ is the distribution of $X_t$ given $X_o = \omega$. In words, $\Delta(t)$ is the maximum time to converge to stationary distribution over all the starting points, where convergence is defined on total variation distance. Then the mixing time $\tmix$ is defined to be the smallest $t$ such that $\Delta(t) \leq \frac{1}{4}$. </div> </div> <p>We claim that the choice of $\frac{1}{4}$ in defining $\tmix$ does not matter.</p> <div class="proposition"> <div class="theorem-title">Proposition (Constants Don't Matter) </div> <div class="theorem-contents"> The choice of constant $\frac{1}{4}$ does not matter. This is because for all $c \geq 1$, $\Delta(c \cdot \tmix) \leq \frac{1}{4^c}$. In other words, we can increase the mixing time by a linear amount to get an exponential decrease in total variation distance. </div> </div> <p>To bound mixing times, we consider random walks on undirected, regular graphs $G$. The same analysis can be extended to directed, weighted, irregular graphs, but it causes the notation to become more cumbersome and distracts from the key ideas.</p> <p>Consider random walks on an undirected, regular graph $G(V, E)$, $|V| = n$. Define the transition matrix $T$ of the graph to be</p> \[\begin{align} T_{ij} = \begin{cases} \frac{1}{\deg(j)} &amp; \text{if $j \sim i$} \\ 0 &amp; \text{otherwise} \end{cases} \end{align}\] <p>where $j \sim i$ means that $j$ shares an edge with $i$.</p> <p>The stationary distribution for $T$ is given by</p> \[\begin{align} \pi = \left( \frac{\deg (1)}{2|E|} , \dots, \frac{\deg (n)}{2|E|} \right). \end{align}\] <p>This can be seen from the following:</p> \[\begin{align} (T \pi)_i &amp; = \sum\limits_{j \in [n]} \frac{\deg (j)}{2 |E| } \mathbb{1} \begin{rcases} \begin{dcases} \frac{1}{\deg(j)} &amp; \text{ if $j \sim i$}, \\ 0 &amp; \text{ otherwise. } \\ \end{dcases} \end{rcases} \\ &amp; = \sum\limits_{j \sim i} \frac{\deg(j)}{2 |E| } \frac{1}{\deg (j)} \\ &amp; = \frac{ \deg (i) }{2|E|}. \end{align}\] <p>If $G$ is $d$-regular, then</p> \[\begin{align} T = \frac{1}{d} \cdot A, \end{align}\] <p>where $A$ is the adjacency matrix of the graph.</p> <h2 id="spectral-graph-theory">Spectral Graph Theory</h2> <p>Spectral graph theory is the study of how the eigenvalues and eigenvectors of the matrix of a graph reveals certain properties about the graph, for instance, how well-connected it is.</p> <div class="lemma" id="lemma-1"> <div class="theorem-title">Lemma (Lemma 1: Properties of the Adjacency Matrix of a $d$-regular Graph) </div> <div class="theorem-contents"> Let $T = \frac{1}{d} A$. Let ${\lambda_1 \geq \lambda_2 \geq \dots \geq \lambda_n}$ to be the eigenvalues of $T$. Then the following properties hold: $\label{laplacian-prop}$ <ol> <li> $|\lambda_i| \leq 1$ for all $i$, and $\lambda_1 = 1$ </li> <li> $\lambda_2 &lt; 1$ if and only if $G$ is connected </li> <li> $\lambda_n &gt; -1$ if and only if $G$ does not have a bipartite connected component </li> </ol> </div> </div> <p>We prove each of the claims in <a href="#lemma-1">Lemma 1</a> in order.</p> <div class="proof"> <div class="theorem-title">Proof (Claim 1: $|\lambda_i| \leq 1$ for all $i$, and $\lambda_1 = 1$) </div> <div class="theorem-contents"> Choose any eigenvector $v$. <br/> Let $v_i$ be the maximum magnitude entry of $v$. Observe that $v$ is an eigenvector of $T$ only if $Tv = \lambda v$ for some $\lambda$. Then \begin{align} \lambda v_i \label{eq:max_entry} &amp; = (Tv)_i \\ &amp; = \sum\limits_{j \in N(i)} \frac{1}{d} \cdot v_j &amp; \text{(Multiplying $i$th row of $T$ by $v$)} \\ &amp; \leq | v_i | \end{align} The last step comes from the fact that since each $|v_j| \leq |v_i|$, so at most we have $d \times \frac{1}{d}|v_i| = |v_i|$, recalling that $|N(i)| = d$ since the graph is $d$-regular. <br/><br/> This shows that $|\lambda v_i| \leq |v_i|$ for all $i$, and so $|\lambda| \leq 1$. <br/><br/> It remains to show that $\lambda_1=1$. To see this, consider the vectors where all entries are 1, i.e $\mathbb{1}$. Then $T \cdot \mathbb{1} = \mathbb{1}$. So $\mathbb{1}$ is an eigenvector of $T$ with eigenvalue 1. </div> </div> <div class="proof"> <div class="theorem-title">Proof (Claim 2: $\lambda_2 &lt; 1$ if and only if $G$ is connected.) </div> <div class="theorem-contents"> $(\Longleftarrow)$ Suppose that $G$ is disconnected, we show that its second largest eigenvalue $\lambda_2$ is 1. <br/><br/> WLOG, assume that the graph has two distinct connected components; the proof easily extends to having more components. <br/> Let $S_1, S_2$ be connected components of $G$. Recall that the connected components of $G$ are the equivalence class of components where in each component, all vertices are reachable from any other vertex. <br/><br/> Define $v^1, v^2$ via \begin{align*} v^1_i = \begin{cases} 1 &amp; \text{if $i \in S_1$,} \\ 0 &amp; \text{otherwise,} \\ \end{cases} \\ v^2_i = \begin{cases} 1 &amp; \text{if $i \in S_2$,} \\ 0 &amp; \text{otherwise.} \\ \end{cases} \\ \end{align*} <br/><br/> Then \begin{align} (T \cdot v^1)_i &amp; = \sum\limits_{j \in N(i)} \frac{1}{d} v^1_j &amp; \text{(multiplying row $i$ of $T$ by $v^1$)} \\ &amp; = \sum\limits_{j \in N(i)} \frac{1}{d} \mathbb{1} \left\{ j \in S_1 \right\} \\ &amp; = \begin{cases} 1 &amp; \text{if $i \in S_1$,} \\ 0 &amp; \text{otherwise.} \\ \end{cases} \end{align} This shows that $T \cdot v^1 = v^1$. Similarly, we can perform the same sequence of steps to derive that $T \cdot v^2 = v^2$. <br/><br/> We can show the same for $v^2$ to get $T \cdot v^2 = v^2$. which shows that $\lambda_2 = 1$. <br/> Since by our disconnected assumption $v^1, v^2 \neq \mathbb{1}$, the all-ones eigenvector corresponding to eigenvalue $\lambda_1$, it means $\lambda_2 = 1$. <br/> This shows the backwards direction. <br/><br/> $(\implies)$ For the other direction, suppose that $G$ is connected, we want to show that $\lambda_2 &lt; 1$. <br/><br/> We will show that for any eigenvector $v$ with eigenvalue $1$, then it must be a scaling of $\mathbb{1}$. <br/><br/> Let $v$ be any eigenvector with eigenvalue $1$. Then let $v_i$ be its maximum entry. From Equation \ref{eq:max_entry}, we must have that \begin{align} \lambda v_i &amp; = v_i \\ &amp; = (Tv)_i \\ &amp; = \sum\limits_{j \in N(i)} \frac{1}{d} \cdot v_j \\ &amp; = v_i. \end{align} But since $v_i$ is the largest entry, it must be the case that $v_j = v_i$ for all $j \sim i$. We then repeat this argument to observe that all the neighbors of each $j$ must also take on the same value. Since the graph is connected, $v$ is just the uniform vector, as desired. <br/><br/> Note that this lemma shows that if $G$ is disconnected, then it has a spectral gap of 0. </div> </div> <div class="proof"> <div class="theorem-title">Proof (Claim 3: $\lambda_n &gt; -1$ if and only if $G$ does not have a bipartite connected component) </div> <div class="theorem-contents"> $(\implies)$ We show the forward direction by contraposition. <br/> Suppose that $G$ has a bipartite component $S$. We want to show that $\lambda_n = -1$. <br/><br/> Let $S = L \cup R$ denote the two disjoint bipartite components. <br/><br/> Define vector \begin{align} v_i = \begin{cases} 1 &amp; \text{if $i \in L$,} \\ -1 &amp; \text{if $i \in R$,} \\ 0 &amp; \text{otherwise.} \\ \end{cases} \end{align} Again we compute $T \cdot v$, and consider its $i$th entry: \begin{align} \left( T \cdot v \right)_i &amp; = \sum\limits_{j \in N(i)} \frac{1}{d} v_j \\ &amp; = -v_i, \end{align} since the signs of its neighbors $N(i)$ are always the opposite of the sign of $v_i$ by construction. <br/><br/> Since $Tv = -v$, this shows that we have an eigenvector with eigenvalue $-1$. <br/><br/> $(\Longleftarrow)$ Now suppose that $Tv = -v$, with the goal to show that the graph is bipartite. <br/> Similarly as for the backwards direction of Claim 2, we can see that this can only hold on each element $v_i$ if all the signs of the neighbors of $v_i$ have the same magnitude but opposite sign of $v_i$. Then we can similarly expand this argument to the neighbors of its neighbors, which shows that the graph is bipartite. </div> </div> <p>This shows how we can gleam useful information about a graph just from its eigenvalues.</p> <p>Recall how we previously showed that a unique stationary distribution exists if the graph is connected and not bipartite. Now we have another characterization of the same property, except in terms of the eigenvalues of its transition matrix:</p> <div class="corollary"> <div class="theorem-title">Corollary (Corollary of the Fundamental Theorem) </div> <div class="theorem-contents"> If $T$ is such that $\lambda_2 &lt; 1$, $\lambda_n &gt; -1$ then the random walk has a unique stationary distribution which is uniform. </div> </div> <p>Our goal now is to formulate a robust version of this corollary, where we can bound the mixing time of approaching the stationary distribution.</p> <h1 id="bounding-the-mixing-time-via-the-spectral-gap">Bounding the Mixing Time via the Spectral Gap</h1> <p>We define the spectral gap:</p> <div class="definition"> <div class="theorem-title">Definition (Spectral Gap) </div> <div class="theorem-contents"> Given $T$, define \begin{align} \beta = \max\left\{ \lambda_2, | \lambda_n | \right\} = \max_{2 \leq i \leq n} |\lambda_i|. \end{align} Then the spectral gap is given by \begin{align} \sgap{T} = 1 - \beta. \end{align} </div> </div> <p>We now finally introduce a lemma that shows that the mixing time is proportional to the inverse of the spectral gap multiplied by a log factor:</p> <div class="lemma" id="lemma-2"> <div class="theorem-title">Lemma (Lemma 2: Mixing Time of Markov Chains) </div> <div class="theorem-contents"> Suppose $T = \frac{1}{d} A$. Then \begin{align} \tmix(T) \leq O\left(\frac{\log (n)}{1 - \beta}\right). \end{align} </div> </div> <p>This shows that if your spectral gap is bounded by a constant, your mixing time is in $O(\log (n))$.</p> <div class="exercise"> <div class="theorem-title">Exercise </div> <div class="theorem-contents"> Verify that the path graph indeed has a small spectral gap, since we previously established that it has a large mixing time. Similarly, check that the complete graph has a large spectral gap. </div> </div> <h2 id="proof">Proof</h2> <p>We now prove <a href="#lemma-2">Lemma 2</a>.</p> <p>Let $T$ have eigenvalues $1 = \lambda_1 \geq \lambda_2 \geq \dots \geq \lambda_n$ with eigenvectors $v^1, v^2, \dots, v^n$. Assume that the eigenvectors are scaled to be unit vectors.</p> <p>Since this is a symmetric matrix, the eigenvectors are pairwise orthogonal.</p> <p>We can perform an eigenvalue decomposition of $T$ in terms of its eigenvectors via \begin{align}\label{eq:decomp} T = \sum\limits_i \lambda_i v_i v_i^\top . \end{align}</p> <p>It follows from Equation \ref{eq:decomp} that \begin{align} T^k = \sum\limits_i \lambda_i^k v_i v_i^\top . \end{align}</p> <p>Let $x \in [0,1]^n$ be a probability vector of $G$ where all entries are non-negative and sum to 1. Think of $x$ as the start state of the Markov chain.</p> <p>After $k$ steps, the state will be $T^k \cdot x$.</p> <p>We can re-write $x$ in terms of the orthogonal basis of the eigenvectors of $T$, i.e \begin{align} x = \sum\limits_{i} \langle x, v_i \rangle \cdot v_i. \end{align} Write $a_i = \langle x, v_i \rangle $ to be the coefficients of each eigenvector $v_i$.</p> <p>$\lambda_1=1$, so $\lambda_1^k = 1$. We also know that</p> \[\begin{align} v^1 = \begin{pmatrix} \frac{1}{\sqrt{n}} \\ \vdots \\ \frac{1}{\sqrt{n}} \\ \end{pmatrix}, \end{align}\] <p>since we previously showed that the all-ones vector is always an eigenvector with eigenvalue 1, where here it is re-scaled to have unit norm.</p> <p>Then \(\begin{align} T^k \cdot x &amp; = \sum\limits_{i} \langle x, v_i \rangle \cdot \lambda_i^k \cdot v_i \\ &amp; = \langle x, v^1 \rangle \cdot v^1 + \sum\limits_{i \geq 2} \langle x, v_i \rangle \cdot \lambda_i^k \cdot v_i \\ &amp; = \frac{1}{n} \langle x, \mathbb{1} \rangle \cdot \mathbb{1} + \sum\limits_{i \geq 2} \langle x, v_i \rangle \cdot \lambda_i^k \cdot v_i \\ &amp; = \begin{pmatrix} \frac{1}{n} \\ \vdots \\ \frac{1}{n} \\ \end{pmatrix} + \sum\limits_{i \geq 2} \langle x, v_i \rangle \cdot \lambda_i^k \cdot v_i, \end{align}\)</p> <p>where the last step follows from the fact that $x$ is a probability distribution and thus $x \cdot \mathbb{1} = 1$.</p> <p>Rearranging and moving to work in the L2 (Euclidean) norm, we obtain</p> \[\begin{align} \left| \left| T^k \cdot x - \begin{pmatrix} \frac{1}{n} \\ \vdots \\ \frac{1}{n} \\ \end{pmatrix} \right| \right|_2 &amp; = \left| \left| \sum\limits_{i = 2}^n \langle x, v_i \rangle \cdot \lambda_i^{k} v_i \right| \right|_2 \\ &amp; = \sqrt{ \sum\limits_{i = 2}^n \langle x, v_i \rangle^2 \cdot \lambda_i^{2k} \cdot \| v_i \|^2_2 } \\ &amp; \text{(def of L2 norm, x-terms cancel as e.v are pairwise orth)} \\ &amp; = \sqrt{ \sum\limits_{i = 2}^n \langle x, v_i \rangle^2 \cdot \lambda_i^{2k} } \\ &amp; \text{($v_i$ has unit norm)} \\ &amp; \leq \| x \|_2 \cdot \beta^k, \end{align}\] <p>where the last step comes from the fact that $\lambda_i \leq \beta$ for all $i \geq 2$ since $\beta$ is the second-largest eigenvalue, and $\sum\limits_{i = 1}^n \langle x, v_i \rangle^2 = | x |_2^2$ .</p> <p>Since $| x |_2 \leq 1$, we can simplify</p> \[\begin{align} \left| \left| T^k \cdot x - \begin{pmatrix} \frac{1}{n} \\ \vdots \\ \frac{1}{n} \\ \end{pmatrix} \right| \right|_2 &amp; \leq \beta^k \\ &amp; = (1 - (1 - \beta))^k. \end{align}\] <p>However, what we really care about is the total variation distance, which is the quantity</p> \[\begin{align} \frac{1}{2} \left| \left| T^k \cdot x - \begin{pmatrix} \frac{1}{n} \\ \vdots \\ \frac{1}{n} \\ \end{pmatrix} \right| \right|_{TV} \\ = \frac{1}{2} \left| \left| T^k \cdot x - \begin{pmatrix} \frac{1}{n} \\ \vdots \\ \frac{1}{n} \\ \end{pmatrix} \right| \right|_{1}. \end{align}\] <p>Recall that for any $n$-dimensional vector $x$, $| x |_1 = \sqrt{n} | x |_s$ by Cauchy-Schwarz:</p> \[\begin{align} \| x \|_1 &amp; = \mathbb{1} \cdot x \\ &amp; \leq \| \mathbb{1} \|_2 \| x \|_2 \tag{by Cauchy-Schwarz} \\ &amp; = \sqrt{n} \| x \|_2. \end{align}\] <p>To relate the L2 distance to L1 distance, we can apply the above inequality to get \(\begin{align} \frac{1}{2} \left| \left| T^k \cdot x - \begin{pmatrix} \frac{1}{n} \\ \vdots \\ \frac{1}{n} \\ \end{pmatrix} \right| \right|_1 &amp; \leq \frac{1}{2} \sqrt{n} \left| \left| T^k \cdot x - \begin{pmatrix} \frac{1}{n} \\ \vdots \\ \frac{1}{n} \\ \end{pmatrix} \right| \right|_2 \\ \\ &amp; \leq \frac{1}{2} \sqrt{n} \beta^k \\ &amp; \leq \frac{1}{4}, \tag{if $k &gt; O\left( \frac{\log n}{1 - \beta} \right)$} \end{align}\) as desired.</p> <p>So we set $k \geq O\left( \frac{\log n}{1 - \beta} \right)$ for the total variation distance to be less than 1/4.</p> <p>We say that a Markov Chain is fast mixing if $\tmix \leq \log^{O(1)}(n)$.</p> <h1 id="expander-graphs">Expander Graphs</h1> <p><a href="#lemma-2">Lemma 2</a> motivates the following definition of expander graphs:</p> <div class="definition"> <div class="theorem-title">Definition (Expander Graphs) </div> <div class="theorem-contents"> $G$ is a $(n, d, \epsilon)$-expander graph if $G$ is a $d$-regular graph and $T = \frac{1}{d} A$ has spectral gap at least $\epsilon$. </div> </div> <p>From what we have learnt so far, we know that an expander has to be well-connected in order to have a large spectral gap. Expander graphs can be used for derandomization, which helps to reduce the amount of random bits required for algorithms.</p>]]></content><author><name>fanpu</name></author><category term="math"/><category term="machine-learning"/><summary type="html"><![CDATA[An aperiodic and irreducible Markov chain will eventually converge to a stationary distribution. This is used in many applications in machine learning like Markov Chain Monte Carlo (MCMC) methods, where random walks on Markov chains are used to obtain a good estimate of the log likelihood of the partition function of a model, which is hard to compute directly as it is #P-hard (this is even harder than NP-hard). However, one common problem is that it is unclear how many steps we should take before we are guaranteed that the Markov chain has converged to the its stationary distribution. In this post, we understand how the spectral gap of the transition matrix of the Markov chain relates to its mixing time.]]></summary></entry><entry><title type="html">Notes on ‘The Llama 3 Herd of Models’</title><link href="https://fanpu.io/blog/2024/llama-3.1-technical-report-notes/" rel="alternate" type="text/html" title="Notes on ‘The Llama 3 Herd of Models’"/><published>2024-08-07T00:00:00+00:00</published><updated>2024-08-07T00:00:00+00:00</updated><id>https://fanpu.io/blog/2024/llama-3.1-technical-report-notes</id><content type="html" xml:base="https://fanpu.io/blog/2024/llama-3.1-technical-report-notes/"><![CDATA[<h1 id="reading-recommendations">Reading Recommendations</h1> <p>This is a long paper, but it’s full of gems. Here’s a reading recommendation guide:</p> <ul> <li>Strapped on time: sections 1 (Introduction), 2 (General Overview). It’s just a couple of pages and provides a good overview.</li> <li>Love ML systems: 3.3 (Infrastructure, Scaling, Efficiency). Talks about on hardware, architecture, training challenges, parallelism optimizations</li> <li>How to train a coding model: 4.3.1 (Code). Covers how they targeted specific coding abilities and generated synthetic datasets to bootstrap the model</li> <li>Training model to perform tool use: 4.3.5 (Tool Use)</li> <li>Post-training framework: 4.1 (Modeling). Covers their pipeline for reward modeling, supervised finetuning, and direct preference optimization</li> <li>Extending to 128K context: 3.4.2 (Long Context Pre-Training) and 4.3.4 (Long Context)</li> <li>Why a 405B model: 3.2.1 (Scaling Laws)</li> <li>Optimizations for inference: 6 (Inference) on both pipeline parallelism and FP8 quantization, this is a short section</li> <li>Results and benchmarks: 5.1, 5.2 (Pre and Post-trained Language Model), 5.3 (Human Evaluations)</li> <li>Red teaming: 5.4.6 (Red Teaming)</li> <li>Multi-modality: 7 (Vision Experiments), 8 (Speech Experiments), 9.2 (Multimodality)</li> </ul> <h1 id="introduction">Introduction</h1> <p>Introduces new set of models (8/70/405 B) that supports:</p> <ul> <li>multilinguality</li> <li>coding</li> <li>reasoning</li> <li>tool usage</li> </ul> <p>Largest model:</p> <ul> <li>405B parameters</li> <li>128k context window</li> <li>Has instruction fine-tuned version</li> <li>Pre-trained on 3.8 x \(10^{25}\) FLOPS</li> </ul> <p>Also introduced Llama Guard 3 model for input/output safety.</p> <h1 id="pre-training">Pre-training</h1> <h2 id="pre-training-data">Pre-Training Data</h2> <h3 id="data-cleaning">Data Cleaning</h3> <p>Knowledge cutoff end of 2023. To ensure high-quality tokens, performed: de-duplication, data cleaning, removed domains known to contain large amounts of PII, adult content.</p> <p>Data cleaning:</p> <ul> <li>extracts HTML content from web documents</li> <li>done carefully for pages with math &amp; code content to preserve structure</li> <li>Markdown markers also removed</li> </ul> <p>De-duplication:</p> <ul> <li>on the URL, duplication across documents, line-level de-duplication (common in boilerplate)</li> </ul> <p>Used heuristics to filter other low-quality documents: logs/error messages, other adult websites, websites with excessive numbers of outlier tokens</p> <p>Built a model-based classifier to sub-select high-quality tokens.</p> <p>Built domain-specific pipelines to extract code &amp; math-relevant web pages, including pages containing math deduction, pages containing code interleaved with natural language.</p> <p>Used similar approaches as the above for other languages.</p> <h3 id="data-mix">Data Mix</h3> <p>This ensures they have the right proportion of different data sources. They ended up with:</p> <ul> <li>50% general knowledge</li> <li>25% math &amp; reasoning</li> <li>17% code</li> <li>8% multilingual</li> </ul> <p>Knowledge classification: categorizes data to determine the data mix. Used this to downsample data over-represented on the web like arts &amp; entertainment.</p> <p>Scaling laws for data mix: trained several small models on data mix &amp; use that to predict the performance of large models on mix</p> <p>Overview</p> <ul> <li>15.6T multilingual tokens (compare 1.8T for Llama 2)</li> <li>Use 8K token context window initially, followed by continued pre-training stage which increases supported context window to 128K tokens</li> </ul> <h3 id="multi-modality">Multi-modality</h3> <h4 id="encoders">Encoders</h4> <p>Separate encoders trained for images and speech.</p> <p>Image encoder:</p> <ul> <li>Trained on image-text pairs</li> </ul> <p>Speech encoder:</p> <ul> <li>Self-supervised learning via masking</li> <li>Masked part reconstructed by discrete-token representation</li> </ul> <h4 id="adapters">Adapters</h4> <p>TBD</p> <h3 id="annealing-data">Annealing Data</h3> <p>Performed annealing on small amounts of high-quality code and mathematical data. Annealing here means increasingly upsampling these high-quality data over time.</p> <p>Found improvements for Llama 3 8B on GSM8k and MATH, but not 405B.</p> <h2 id="model-architecture">Model Architecture</h2> <p>Architecture</p> <ul> <li>Uses dense Transformer architecture instead of MoE for training stability</li> <li>Similar to Llama and Llama 2, performance gains mostly from improvements in data quality &amp; diversity, and training scale</li> <li>Grouped query attention with 8 KV heads: improves inference speed, reduce size of KV cache during decoding</li> <li>Attention mask to prevent self-attention between different documents (why not just put them in different sequences? maybe to take advantage of parallelism?). Limited impact during pre-training, helpful for continued pre-training on long sequences</li> <li>RoPE for positional embeddings (500,000 base frequency hyperparameter instead of 10k in original paper, this is helpful for longer context), SwiGLU activation</li> <li>128K token vocabulary, based off <code class="language-plaintext highlighter-rouge">tiktoken</code> tokenizer and extra 28K non-English tokens. Tokenizer improves compression rate from 3.17 to 3.94 characters per token compared to Llama 2 tokenizer.</li> <li>Llama 3 405B: 126 layers (!!), model dimension 16,382, 128 attention heads</li> </ul> <h3 id="scaling-laws">Scaling Laws</h3> <p>Scaling laws are nice for predicting loss, but not helpful for understanding impact on downstream task performance.</p> <p>To find relationship with downstream task performance they did:</p> <ol> <li>Find correlation between compute-optimal model’s loss on downstream tasks and training FLOPs</li> <li>Find correlation between loss and downstream task accuracy, using scaling law models</li> </ol> <p>The scaling laws suggest that given their compute budget of \(3.8 \times 10^{25}\) FLOPs, a 402B model with 16.55T tokens is optimal, which led to their 405B model.</p> <p>They also found their predictions to be quite accurate for the final downstream performance of their models.</p> <h3 id="infrastructure-scaling-and-efficiency">Infrastructure, Scaling, and Efficiency</h3> <p>Compute:</p> <ul> <li>16K H100 GPUs, 700W TDP (thermal design power) with 80GB HBM3 (high bandwidth memory that allows for faster data transfer between CPU and GPU)</li> <li>Trained on Meta’s Grand Teton AI server platform, scheduling using MAST (Meta’s global-scale training scheduler)</li> <li>Each server: 8 GPUs connected by NVLink, 2 CPUs</li> </ul> <p>Storage:</p> <ul> <li>Tectonic, Meta’s distributed file system</li> <li>240 PB storage over 7500 servers, 2TB/s sustainable throughput, 7TB/s peak throughput</li> </ul> <p>Network:</p> <ul> <li>Llama 3 405B used RDMA over Converged Ethernet (RoCE) fabric</li> <li>Smaller models uses Nvidia Quantum2 Infiniband</li> <li>Both 400 Gbps interconnect</li> </ul> <h3 id="parallelism-for-model-scaling">Parallelism for Model Scaling</h3> <p>Scaled parallelism as much as possible, so all of GPU’s model parameters, optimizer states, gradients, and activations fit in HBM.</p> <p>4D parallelism:</p> <ul> <li>tensor parallelism</li> <li>pipeline parallelism</li> <li>context parallelism</li> <li>data parallelism</li> </ul> <p>Parallelism achieved BF16 Model FLOPs Utilization (MFU) of 38-43%</p> <h3 id="reliability-and-operational-challenges">Reliability and Operational Challenges</h3> <ul> <li> <blockquote> <p>90% effective training time, even while supporting automated cluster maintenance (i.e Linux kernel upgrades)</p> </blockquote> </li> <li>At least one training interruption daily</li> </ul> <p>466 job interruptions</p> <ul> <li>47 planned interruptions (i.e maintenance)</li> <li>419 unexpected: mostly GPU/host component failures, suspected data corruption, unplanned maintenance</li> <li>Significant manual intervention only required 3 times, rest handled by automation</li> </ul> <p>Debugging</p> <ul> <li>PyTorch’s built-in NCCL flight recorder helped diagnose issues quickly at scale</li> <li>Mixed use of NVLink and RoCE complicated things</li> </ul> <p>Others</p> <ul> <li>Higher mid-day temperatures impacted GPU dynamic voltage and frequency scaling, causing diurnal 1-2% throughput variation throughout the day</li> <li>~10ks of GPUs with correlated increase/decrease in power consumption (i.e waiting for checkpointing) causes fluctuation of power consumption on the order of ~10s megawatts, stretching limits of power grid</li> </ul> <h2 id="training-recipe">Training Recipe</h2> <p>Initial pre-training:</p> <ul> <li>AdamW optimizer</li> <li>Linear warm up, cosine LR schedule</li> <li>Start with lower batch size for training stability, increase subsequently for efficiency</li> <li>Few loss spikes, no interventions needed to correct for training divergence</li> <li>Upsampled non-English and math data, downsampled low-quality data</li> <li>Added recent web data in final stages of pre-training to advance model knowledge cut-off</li> </ul> <p>Long context pre-training:</p> <ul> <li>To support 128K context window</li> <li>Don’t do long-context training earlier because of quadratic self-attention, too expensive</li> <li>Increased context length by successive adaptation over 6 stages from 8K to 128K, 800B training tokens</li> </ul> <p>Annealing:</p> <ul> <li>On final 40M tokens, linearly annealed LR to 0, kept 128K context window</li> <li>Upsampled data source of very high quality</li> <li>Averaged model checkpoints during annealing to get final pre-trained model</li> </ul> <h1 id="post-training">Post-Training</h1> <ul> <li>Several rounds of post-training, each starts with SFT followed by DPO</li> <li>Examples collected by human annotations or generated synthetically</li> <li>Custom</li> </ul> <h2 id="modeling">Modeling</h2> <ul> <li>Uses reward model (RM) and language model (LM)</li> <li>RM trained by human-annotated preference data</li> <li> <p>Checkpoints aligned with DPO</p> </li> <li>Model supports tool use, which required designing multi-message chat protocol with special header and termination tokens</li> </ul> <h3 id="reward-modeling">Reward Modeling</h3> <ul> <li>RM trained on top of pre-trained checkpoint</li> <li>Preference pairs of either (chosen, rejected) or (chosen, rejected, edited), where edited &gt; chosen &gt; rejected</li> <li>Filtered out preference data with similar responses</li> </ul> <h3 id="supervised-finetuning">Supervised Finetuning</h3> <ul> <li>RM performs rejection sampling on human annotation prompts</li> <li>Fine-tune pre-trained LM on the model-generated samples that are accepted</li> </ul> <h3 id="direct-preference-optimization">Direct Preference Optimization</h3> <ul> <li>Why not on-policy algorithms like PPO? DPO required less compute, performed better on instruction-following benchmarks</li> <li>Used most recent batches of preference data from best-performing models during previous alignment rounds, ensures training data conforms better to distribution of policy model being optimized</li> </ul> <p>Modified DPO:</p> <ul> <li>Masked out formatting tokens (including header and termination tokens) in DPO loss, helps with stability. These tokens caused tail repetition or random termination tokens. Hypothesized due to these tokens being common in both chosen and rejected responses causes conflicting optimization objectives</li> <li>Added regularization with negative log-likelihood (NLL) loss</li> </ul> <h2 id="post-training-data">Post-training Data</h2> <h3 id="preference-data">Preference Data</h3> <ul> <li>Sample two responses from two different models for each user prompt, labelled by human annotators</li> <li>Annotators state strength of preference by 4 levels: significantly better, better, slightly better, marginally better</li> <li>Allow editing step after annotation to further improve response</li> <li>Only used responses significantly better or better for training</li> </ul> <h3 id="sft-data">SFT Data</h3> <p>Finetuning data contains:</p> <ul> <li>Prompts from human annotation collection with rejection-sampled (RS) responses</li> <li>Synthetic data targeting specific capabilities</li> <li>Small amounts of human-curated data</li> </ul> <p>Datasets:</p> <ul> <li>General English</li> <li>Code</li> <li>Multilingual</li> <li>Exam-like</li> <li>Reasoning and tools</li> <li>Long context</li> </ul> <p>Rejection sampling:</p> <ul> <li>Choose prompt from human annotation collection</li> <li>Sample 10-30 outputs from latest chat model policy</li> <li>Use RM to choose best candidate</li> <li>For later rounds of post-training, use system prompt to steer RS responses to conform with tone/style/formatting</li> <li>Uses PagedAttention to make RS efficient</li> </ul> <h3 id="data-processing-and-quality-control">Data Processing and Quality Control</h3> <p>Most of training data is model-generated, requires careful cleaning and quality control</p> <p>Data cleaning:</p> <ul> <li>Rule-based data removal or modification strategies</li> <li>Balance proportion of such samples in dataset</li> </ul> <p>Data pruning:</p> <ul> <li>Topic classification: Fine-tuned Llama 3 8B to a topic classifier</li> <li>Quality scoring: Use RM and Llama 3 checkpoint to rate content, keep examples marked as high quality by either RM or Llama. Both signals have high disagreement rates, and combining signals gives best recall on test set.</li> <li>Difficulty scoring: used Llama 3 70B to perform intention-tagging, where more intentions implies more complexity. Also used it to measure difficulty of dialogs</li> <li>Semantic deduplication: clustering using RoBERTa, sort by quality score \(\times\) difficulty score, go through sorted examples by best and take only ones with maximum cosine similarity less than threshold</li> </ul> <h2 id="capabilities">Capabilities</h2> <h3 id="code">Code</h3> <p>Capabilities:</p> <ul> <li>Code generation</li> <li>Documentation</li> <li>Debugging</li> <li>Review</li> </ul> <p>Targeted languages: Python, Java, Javascript, C/C++, Typescript, Rust, PHP, HTML/CSS, SQL, bash/shell</p> <p>Improved capabilities via:</p> <ul> <li>Training a code expert</li> <li>Generate synthetic data for SFT</li> <li>Improve formatting with system prompt steering</li> <li>Create quality filters to remove bad examples</li> </ul> <p>Expert training:</p> <ul> <li>Train code expert to obtain high quality human annotations for code</li> <li>Approach similar to CodeLlama (scant on details, should probably check this paper)</li> </ul> <p>Synthetic data generation:</p> <ul> <li>Faced issues in code generation: following instructions, code syntax errors, incorrect code generation, difficulty in fixing bugs</li> <li>Use Llama 3 and code expert to generate synthetic 2.7M dialogs for SFT</li> </ul> <p>During RS, used code specific system prompts to improve:</p> <ul> <li>code readability</li> <li>documentation</li> <li>thoroughness</li> <li>specificity</li> </ul> <h4 id="synthetic-data-generation-execution-feedback">Synthetic data generation: execution feedback</h4> <ul> <li>Distillation to smaller models helped, but not for 405B on its own inputs</li> <li>Use execution feedback as source of truth, allow model to learn from own mistakes <ol> <li>Problem description generation: generate programming problem descriptions, use random code snippets as inspiration</li> <li>Solution generation: Prompt Llama 3 to solve problem, use CoT in comments, add programming guidelines in system prompt</li> <li>Correctness analysis: use static analysis (parser and linters), and unit test generation (also by the model) and execution</li> <li>Error feedback and iterative self-correction: prompt model to revise solutions that fail, includes feedback from parser/linter/tester. Can modify code and unit test to accomodate new code. 20% of solutions that were incorrect could be self-corrected this way.</li> <li>Fine-tuning and iterative improvement: process iterated over multiple rounds, higher-quality synthetic data generated in each subsequent rounds</li> </ol> </li> </ul> <h4 id="synthetic-data-generation-programming-language-translation">Synthetic data generation: programming language translation</h4> <ul> <li>Noted performance gap between popular vs less common programming languages, due to difference in dataset size</li> <li>Translate data from more common to less common languages</li> <li>Ensure quality via syntax parsing, compilation, execution</li> </ul> <h4 id="synthetic-data-generation-backtranslation">Synthetic data generation: backtranslation</h4> <ul> <li>Some coding capabilities don’t benefit as much from execution feedback, i.e documentation &amp; explanation</li> <li>Generated 1.2M synthetic dialogs for code explanation, generation, documentation, debugging</li> <li>Done as follows: <ol> <li>Generate: Prompt Llama 3 to generate data corresponding to desired capability (i.e add comments to code)</li> <li>Backtranslate: Ask model to backtranslate synthetically generated data to original code (i.e generate code based on only comments)</li> <li>Filter: ask Llama 3 to determine quality of generated code with original code as reference. This self-verification step acts as a filter for good examples, only those with high scores are used for SFT</li> </ol> </li> </ul> <h3 id="tool-use">Tool Use</h3> <p>Trained Llama 3 to use search engine (Brave), Python interpreter, Wolfram Alpha API.</p> <p>To train on tool use:</p> <ul> <li>Start with training single-turn tool use, then tool use in dialog, and then multi-step tool use and data analysis</li> <li>All synthetically generated: first synthetic user prompts which require calling out to tools, then the corresponding tool calls which are then executed, and then the final answer to user prompt</li> <li>Multi-step tool use trained in a similar way synthetically</li> <li>User prompts are based on a provided file, and ask to summarize the contents of the file, find and fix bugs, optimize a piece of code, perform data analysis or visualization</li> <li>Augmented synthetic data with different system prompts to teach model to use tools only when activated</li> <li>To avoid model using tools for simple queries, added dataset containing queries of simple math/reasoning questions with tool use activated but without using tools in response</li> </ul> <h3 id="factuality">Factuality</h3> <p>To train the model to guard against hallucinations, they used a knowledge probe to find out what the model knows, and to generate training data of refusals for the things it doesn’t:</p> <ol> <li>Extract a data snippet from the pre-training data.</li> <li>Generate a factual question about these snippets (context) by prompting Llama 3.</li> <li>Sample responses from Llama 3 to the question.</li> <li>Score the correctness of the generations using the original context as a reference and Llama 3 as a judge.</li> <li>Score the informativeness of the generations using Llama 3 as a judge.</li> <li>Generate a refusal for responses which are consistently informative and incorrect across the generations, using Llama 3.</li> </ol> <p>But because pre-training data is not always factually correct, they also did this for sensitive topics where contradictory/incorrect statements are prevalent</p> <h3 id="steerability">Steerability</h3> <p>Remainder to be continued…</p> ]]></content><author><name>fanpu</name></author><category term="machine-learning"/><summary type="html"><![CDATA[Notes on the new Llama 3.1 technical report. It's a long paper, but one that's well-written with lots of interesting technical details and design choices.]]></summary></entry><entry><title type="html">Playing Sound Voltex at Home: Setting Up Unnamed SDVX Clone with the Yuancon SDVX Controller</title><link href="https://fanpu.io/blog/2023/setting-up-yuancon-controller-sound-voltex/" rel="alternate" type="text/html" title="Playing Sound Voltex at Home: Setting Up Unnamed SDVX Clone with the Yuancon SDVX Controller"/><published>2023-09-02T00:00:00+00:00</published><updated>2023-09-02T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/setting-up-yuancon-controller-sound-voltex</id><content type="html" xml:base="https://fanpu.io/blog/2023/setting-up-yuancon-controller-sound-voltex/"><![CDATA[<p>Rhythm is just a $200 controller and some hopefully-not-too-complicated open source software setup away!</p> <p>This beginner’s guide will help to demystify the process of setting up Sound Voltex at home using a custom SDVX controller using Unnamed SDVX Clone.</p> <hr/> <p>My foray into rhythm games started way back with <a href="https://lovelive-sif-global.bushimo.jp/">Love Live! School Idol Festival</a>. While the game has sadly since shut down, other titles I’ve played include <a href="https://bang-dream-gbp-en.bushiroad.com/">BanG Dream!</a> and <a href="https://projectsekai.fandom.com/wiki/Project_SEKAI_COLORFUL_STAGE!">Project SEKAI</a>.</p> <p>When I visited Japan a few months ago in the summer, I discovered <a href="https://p.eagate.573.jp/game/sdvx/sv/p/index.html">Sound Voltex</a>, and instantly fell in love with its unique control system and beautiful flashy graphics:</p> <figure> <picture> <img src="/assets/img/posts/sdvx/sdvx_and_me.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In Japan, you pay 100 yen (~$0.68 USD) to play two to three songs. You get to play three songs if you don’t crash (i.e fail) any tracks, and two if you fail on either of the first two guaranteed plays.</p> <p>Rhythm games in general are sadly not as mainstream outside of Japan. For instance, in Singapore I was only aware of a single arcade that had Sound Voltex cabs, even though arcades are quite popular in general. Similarly, in NYC, there’s only a single small arcade called <a href="http://www.chinatownfair.biz/">Chinatown Fair</a> that has Sound Voltex. So naturally I wanted to see if I could set it up at home to continue enjoying the game.</p> <p>(Apparently, if you have a lot of disposable income and space in your living room, you can also just buy an entire <a href="https://www.hadouken-arcade.com/products/sound-voltex-vivid-wave">previous-generation Sound Voltex cabinet</a> for a few thousand dollars)</p> <h2 id="why-this-guide">Why This Guide</h2> <p>I decided to write this guide since the setup process could seem somewhat daunting for people who are interested in rhythm games but are not developers. Hopefully now more people will also be able to play and enjoy this game.</p> <p>The setup process is very straightforward on Windows, but has a few subtle points on macOS and Linux that I’ll point out.</p> <h2 id="setup-specification">Setup Specification</h2> <p>This guide will use the following setup:</p> <ul> <li>Game: <a href="https://github.com/Drewol/unnamed-sdvx-clone">unnamed-sdvx-clone</a>, commonly abbreviated USC</li> <li>Controller: <a href="https://yuancon.store/controller/sdvxblack">Yuancon SDVX controller</a>.</li> </ul> <p>While I performed the setup on macOS, the instructions are largely the same for Linux based systems as well. In fact, if you are already regardless of which controller or OS you use.</p> <h2 id="installing-unnamed-sdvx-clone">Installing Unnamed SDVX Clone</h2> <h3 id="windows">Windows</h3> <p>The setup process for Windows is very straightforward. You should just download the <a href="https://drewol.me/Downloads/Game.zip">latest Windows build</a> as linked on the <a href="https://drewol.me/Downloads/Game.zip">Github page</a>, and run <code class="language-plaintext highlighter-rouge">usc-game.exe</code> to start the game.</p> <h3 id="macos">macOS</h3> <p>This is mostly just from the <a href="https://github.com/Drewol/unnamed-sdvx-clone#macos">official instructions</a>, but with implicit points made explicit:</p> <ol> <li>If you don’t have <a href="https://docs.brew.sh/">Homebrew</a> on your machine yet, install it by <a href="https://brew.sh/">following the instructions here</a>. Homebrew is a package management software.</li> <li> <p>If you don’t have <a href="https://git-scm.com/">git</a> yet, install it with Homebrew:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>git
</code></pre></div> </div> <p>Git is a version control system (normally used for code). In our case, we use it mainly to obtain the project dependencies.</p> </li> <li> <p>Clone the <code class="language-plaintext highlighter-rouge">unnamed-sdvx-clone</code> with <code class="language-plaintext highlighter-rouge">git</code>:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git clone https://github.com/Drewol/unnamed-sdvx-clone
</code></pre></div> </div> <p>This will result in the game being downloaded to a <code class="language-plaintext highlighter-rouge">unnamed-sdvx-clone</code> folder in your current working directory.</p> </li> <li> <p>Navigate into the new folder, and download the submodules of the project:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cd </span>unnamed-sdvx-clone
<span class="nv">$ </span>git submodule update <span class="nt">--init</span> <span class="nt">--recursive</span>
</code></pre></div> </div> <p>This is necessary because the game has third-party dependencies, which are tracked as <a href="https://github.com/Drewol/unnamed-sdvx-clone/blob/develop/.gitmodules">other Github repositories</a>.</p> </li> <li> <p>Install more dependencies required to build the project with Homebrew:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>cmake freetype libvorbis sdl2 libpng jpeg libarchive libiconv
</code></pre></div> </div> <p>These are all open source libraries required for the following reasons:</p> <ul> <li><a href="https://cmake.org/"><code class="language-plaintext highlighter-rouge">cmake</code></a>: a popular build system used to compile the project</li> <li><a href="https://freetype.org/"><code class="language-plaintext highlighter-rouge">freetype</code></a>: for rendering fonts</li> <li><a href="https://xiph.org/vorbis/"><code class="language-plaintext highlighter-rouge">libvorbis</code></a>: audio compression</li> <li><a href="https://www.libsdl.org/"><code class="language-plaintext highlighter-rouge">sdl2</code></a>: get access to hardware inputs like keyboard, mouse, controller, etc</li> <li><a href="https://github.com/glennrp/libpng"><code class="language-plaintext highlighter-rouge">libpng</code></a>: for using/manipulating PNG images</li> <li><a href="https://www.ijg.org/"><code class="language-plaintext highlighter-rouge">jpeg</code></a>: for using/manipulating JPEG images</li> <li><a href="https://www.libarchive.org/"><code class="language-plaintext highlighter-rouge">libarchive</code></a>: compression library</li> <li><a href="https://www.gnu.org/software/libiconv/"><code class="language-plaintext highlighter-rouge">libiconv</code></a>: convert between different character encodings (i.e <a href="https://en.wikipedia.org/wiki/ISO/IEC_8859-1">ISO-8859-1</a> to <a href="https://en.wikipedia.org/wiki/UTF-8">UTF-8</a>)</li> </ul> </li> <li> <p>Configure the project using <code class="language-plaintext highlighter-rouge">cmake</code>. In this case, the project author already kindly wrapped a script around this command, so we only have to run the script:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>./mac-cmake.sh
</code></pre></div> </div> </li> <li> <p>Compile and build the project:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make
</code></pre></div> </div> <p>This step could take a while. If you want to speed it up, you can run it and specify the <code class="language-plaintext highlighter-rouge">-j</code> argument parallelize the compilation based on the number of cores you have (use one less than your total number of cores):</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make <span class="nt">-j</span> 9
</code></pre></div> </div> </li> <li> <p>Run the game from the <code class="language-plaintext highlighter-rouge">bin</code> folder:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cd </span>bin
<span class="nv">$ </span>./usc-game
</code></pre></div> </div> <p>It is important to run it from the <code class="language-plaintext highlighter-rouge">./bin</code> folder and not the root of the project directory, as some skins search for file dependencies in a relative manner and will hence not be able to find it.</p> </li> </ol> <h3 id="linux">Linux</h3> <p>Honestly if you’re on Linux, you should be able to figure it out by yourself 😊</p> <h2 id="first-startup">First Startup</h2> <p>On first startup, you should see this:</p> <figure> <video src="/assets/img/posts/sdvx/sdvx-initial.webm" class="z-depth-1 center" width="400px" height="auto" autoplay="" loop="" muted=""/> </figure> <p>For now, you can just use your mouse to interact with the game menu.</p> <h2 id="configuring-the-controller">Configuring The Controller</h2> <p>Let’s now setup our Yuancon controller!</p> <ol> <li> <p>Quit the game, and unplug your SDVX controller if it is plugged in</p> </li> <li> <p>Hold the <code class="language-plaintext highlighter-rouge">START</code> and <code class="language-plaintext highlighter-rouge">BT-C</code> button simultaneously. The <code class="language-plaintext highlighter-rouge">START</code> button is the diamond-shaped button at the top, while the BT-C is the third white button from the left (it should also be labelled on the controller board).</p> <p>Then while still holding down both buttons, connect it to your computer. This will put it in <a href="https://oniichan.wtf/help/index.html">Controller HID Mode</a>, where the controller inputs as a gamepad.</p> </li> <li> <p>Start up the game again, and navigate to the <code class="language-plaintext highlighter-rouge">Settings</code> page. Here, you want to do the following:</p> <ul> <li>Set <code class="language-plaintext highlighter-rouge">Button input mode</code> to <code class="language-plaintext highlighter-rouge">Controller</code></li> <li>Set <code class="language-plaintext highlighter-rouge">Laser input mode</code> to <code class="language-plaintext highlighter-rouge">Controller</code></li> <li>Adjust laser sensitivity accordingly (I like <code class="language-plaintext highlighter-rouge">1.875</code>)</li> <li>Click on each of the key bindings, and hit the corresponding keys on your controller. I used the button on the right side of the controller panel as my back button.</li> </ul> <p>You should have something that looks similar to this:</p> </li> </ol> <p><img src="/assets/img/posts/sdvx/sdvx-settings.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover"/></p> <ol> <li>Restart the game. You should now be able to use the knobs to cycle through the menus, and the buttons to activate them!</li> </ol> <h2 id="getting-songs">Getting Songs</h2> <p>Right after setup, there are no songs to play yet. USC uses the same chart format as <a href="https://www.kshootmania.com/en/">K-Shoot MANIA (KSM)</a></p> <p>There are a few places you can get songs:</p> <ul> <li><a href="https://ksm.dev/">Nautica</a> hosts community-created KSM charts. There is also a menu option to download these directly from within USC.</li> <li><a href="https://oniichan.wtf/help/songs.html">Converted SDVX Charts</a>: probably somewhat questionable legally because of copyright and whatnot but a lot of people recommend and use it</li> <li><a href="https://www.reddit.com/r/kshootmania/wiki/gettingsongs/#wiki_getting_more_songs">This KSM FAQ page on Reddit</a> provides many useful links for downloading new songs</li> </ul> <p>Once you have downloaded the songs, unzip and extract them if necessary, and copy them into <code class="language-plaintext highlighter-rouge">./bin/songs</code>.</p> <h2 id="skinning-the-game">Skinning The Game</h2> <p>The default skin works, but it is not very impressive:</p> <figure> <video src="/assets/img/posts/sdvx/sdvx-default.webm" class="z-depth-1 center" width="400px" height="auto" autoplay="" loop="" muted=""/> </figure> <p>Let’s try to re-create the original SDVX arcade experience with skins. You can get skins for the game <a href="https://oniichan.wtf/help/skins.html">here</a>. These are really high-effort and well-made, and huge thanks to the developers and artists for making them.</p> <p>Once you have downloaded the skin, extract and move them to <code class="language-plaintext highlighter-rouge">./bin/skins</code>. You should then be able to select the skin under the <code class="language-plaintext highlighter-rouge">Skins</code> tab of the game settings.</p> <p>The UI of the skin for the game may change depending on whether your monitor is in portrait or landscape mode. Orienting it vertically is recommended for the best SDVX-like experience - the spaceship(?) at the bottom only shows up when it’s vertical.</p> <p>Some examples of the different skins are shown below. I know, they’re pretty!</p> <p>(<em>Why are the previews so low-res? <a href="https://www.digitalocean.com/blog/its-all-about-the-bandwidth-why-many-network-intensive-services-select-digitalocean-as-their-cloud">Bandwidth costs add up!</a></em>)</p> <h3 id="liqidwave">LiqidWave</h3> <figure> <video src="/assets/img/posts/sdvx/vivid.webm" class="z-depth-1 center" width="400px" height="auto" autoplay="" loop="" muted=""/> </figure> <p>If you run into errors about shaders when trying to play a song, see the <a href="#common-errors">Common Errors</a> section below.</p> <h3 id="experimentalgear">ExperimentalGear</h3> <figure> <video src="/assets/img/posts/sdvx/experimental-gear.webm" class="z-depth-1 center" width="400px" height="auto" autoplay="" loop="" muted=""/> </figure> <p>As a side note, if you find the default menu text for this skin too casual/unprofessional, you can change it in <code class="language-plaintext highlighter-rouge">./bin/skins/ExperimentalGear/scripts/language/EN.lua</code>.</p> <h3 id="heavenly-express">Heavenly Express</h3> <figure> <video src="/assets/img/posts/sdvx/heavenly-express.webm" class="z-depth-1 center" width="400px" height="auto" autoplay="" loop="" muted=""/> </figure> <h2 id="crew">Crew</h2> <p>Not all skins come with a cast of crews, like the ExperimentalGear skin which only comes with a boring empty <code class="language-plaintext highlighter-rouge">nothing</code> skin in <code class="language-plaintext highlighter-rouge">./bin/skins/ExperimentalGear/textures/crew/anim</code>.</p> <p>As crews are very important for our psychological safety and well-being, fortunately we can just copy over the animations from other skins. In HeavenlyExpress, you can find it in <code class="language-plaintext highlighter-rouge">./bin/skins/HeavenlyExpress-1.3.0/textures/_shared/crew</code>. Similarly, in LiqidWave they are stored in <code class="language-plaintext highlighter-rouge">./bin/skins/LiqidWave-1.5.0/textures/_shared/crew</code>.</p> <figure> <video src="/assets/img/posts/sdvx/rasis.webm" class="z-depth-1 center" width="400px" height="auto" autoplay="" loop="" muted=""/> </figure> <h2 id="conclusion">Conclusion</h2> <p>If you’ve made it this far, congrats and thanks for reading! I hope you’ll enjoy the game as much as I do. If you have any questions or run into problems, feel free to ask in the comments section below.</p> <h2 id="extras">Extras</h2> <h3 id="aside-ksm-chart-formats">Aside: KSM Chart Formats</h3> <p>KSM charts have a <code class="language-plaintext highlighter-rouge">.ksh</code> extensions. This can be a useful check to ensure that any charts that you download are actually for this game.</p> <p>The following is a snippet of the <code class="language-plaintext highlighter-rouge">ADV.ksh</code> (i.e advanced beatmap) file for YOASOBI’s Idol (アイドル):</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">title</span><span class="o">=</span>アイドル
<span class="nv">artist</span><span class="o">=</span>YOASOBI /「推しの子」より
<span class="nv">effect</span><span class="o">=</span>AS
<span class="nv">jacket</span><span class="o">=</span>jk.jpg
<span class="nv">illustrator</span><span class="o">=</span>-
<span class="nv">difficulty</span><span class="o">=</span>challenge
<span class="nv">level</span><span class="o">=</span>10
<span class="nv">t</span><span class="o">=</span>166
<span class="nv">m</span><span class="o">=</span>music.ogg
<span class="nv">o</span><span class="o">=</span>0
<span class="nb">bg</span><span class="o">=</span>desert
<span class="nv">layer</span><span class="o">=</span>smoke
<span class="nv">po</span><span class="o">=</span>56024
<span class="nv">plength</span><span class="o">=</span>15000
<span class="nv">pfiltergain</span><span class="o">=</span>50
<span class="nv">filtertype</span><span class="o">=</span>peak
<span class="nv">chokkakuautovol</span><span class="o">=</span>0
<span class="nv">chokkakuvol</span><span class="o">=</span>50
<span class="nv">ver</span><span class="o">=</span>171
<span class="nt">--</span>
<span class="nv">beat</span><span class="o">=</span>4/4
0000|00|--
<span class="nt">--</span>
0000|00|0-
0000|00|:-
0000|00|o-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|o-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|P-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|P-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
0000|00|:-
<span class="nt">--</span>
0000|00|0-
0000|00|:-
<span class="nv">filtertype</span><span class="o">=</span>lpf1
0000|00|0o
0000|00|::
0000|00|o0
0000|00|::
</code></pre></div></div> <h2 id="possible-errors-and-how-to-resolve">Possible Errors And How To Resolve</h2> <p>Some errors I faced when trying to setup and configure the game.</p> <h3 id="module-commonshared-not-found">module <code class="language-plaintext highlighter-rouge">commonShared</code> not found</h3> <p>If you get a Lua error about not being able to load a <code class="language-plaintext highlighter-rouge">commonShared</code> package, such as when using a custom skin:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>14:45:10][Error] Lua error: ...clone/bin/skins/HeavenlyExpress-1.3.0/scripts/common.lua:2: module <span class="s1">'commonShared'</span> not found:
	no field package.preload[<span class="s1">'commonShared'</span><span class="o">]</span>
	no file <span class="s1">'/usr/local/share/lua/5.3/commonShared.lua'</span>
	no file <span class="s1">'/usr/local/share/lua/5.3/commonShared/init.lua'</span>
	no file <span class="s1">'/usr/local/lib/lua/5.3/commonShared.lua'</span>
	no file <span class="s1">'/usr/local/lib/lua/5.3/commonShared/init.lua'</span>
	no file <span class="s1">'./commonShared.lua'</span>
	no file <span class="s1">'./commonShared/init.lua'</span>
	no file <span class="s1">'/Users/fanpu/unnamed-sdvx-clone/bin/skins/HeavenlyExpress-1.3.0/scripts/commonShared.lua'</span>
	no file <span class="s1">'skins/HeavenlyExpress-1.3.0/textures/_shared/scripts/commonShared.lua'</span>
	no file <span class="s1">'/usr/local/lib/lua/5.3/commonShared.so'</span>
	no file <span class="s1">'/usr/local/lib/lua/5.3/loadall.so'</span>
	no file <span class="s1">'./commonShared.so'</span>

</code></pre></div></div> <p>You are likely running the game from the root of the project directory (i.e <code class="language-plaintext highlighter-rouge">./bin/usc-game</code>), instead of from within the <code class="language-plaintext highlighter-rouge">./bin</code> directory itself.</p> <h3 id="heavenlyexpress-skin-could-not-load-shaders">HeavenlyExpress Skin: Could not load shaders</h3> <p>If you are using the HeavenlyExpress skin, you may run into the following error after selecting a track to play:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Shader Error: 
Could not load shaders skins/HeavenlyExpress-1.3.0/shaders/holdbutton.vs 
and skins/HeavenlyExpress-1.3.0/shaders/holdbutton.fs
</code></pre></div></div> <p>You may also get logs like this:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>14:58:37][Error] Shader program compile log <span class="k">for</span> /Users/fanpu/unnamed-sdvx-clone/bin/skins/HeavenlyExpress-1.3.0/shaders/holdbutton.vs: ERROR: 0:6: <span class="s1">'varying'</span> : syntax error: syntax error

<span class="o">[</span>14:58:37][Error] Shader program compile log <span class="k">for</span> /Users/fanpu/unnamed-sdvx-clone/bin/skins/HeavenlyExpress-1.3.0/shaders/holdbutton.fs: ERROR: 0:10: <span class="s1">'varying'</span> : syntax error: syntax error

<span class="o">[</span>14:58:37][Error] Failed to load vertex shader <span class="k">for </span>material from /Users/fanpu/unnamed-sdvx-clone/bin/skins/HeavenlyExpress-1.3.0/shaders/holdbutton.vs
</code></pre></div></div> <p>The shaders were probably written a long time ago, since the <code class="language-plaintext highlighter-rouge">varying</code> keyword has been deprecated since OpenGL 3.3. It was previously used as a qualifier for variables that communicate between the vertex shader and the fragment shader, that is now replaced by the <code class="language-plaintext highlighter-rouge">in</code> and <code class="language-plaintext highlighter-rouge">out</code> qualifiers to provide a more clear distinction of data flow between shaders.</p> <p>To fix this, modify the two files and change the <code class="language-plaintext highlighter-rouge">varying</code> keyword to <code class="language-plaintext highlighter-rouge">out</code> in both files:</p> <p>In file <code class="language-plaintext highlighter-rouge">bin/skins/HeavenlyExpress-1.3.0/shaders/holdbutton.vs</code>:</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#version 330
#extension GL_ARB_separate_shader_objects : enable
</span><span class="n">layout</span><span class="p">(</span><span class="n">location</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="n">in</span> <span class="n">vec2</span> <span class="n">inPos</span><span class="p">;</span>
<span class="n">layout</span><span class="p">(</span><span class="n">location</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="n">in</span> <span class="n">vec2</span> <span class="n">inTex</span><span class="p">;</span>

<span class="n">out</span> <span class="n">vec4</span> <span class="n">position</span><span class="p">;</span> <span class="c1">// update here</span>

<span class="n">out</span> <span class="n">gl_PerVertex</span>
<span class="p">{</span>
        <span class="n">vec4</span> <span class="n">gl_Position</span><span class="p">;</span>
<span class="p">};</span>

<span class="p">...</span><span class="n">rest</span> <span class="n">of</span> <span class="n">file</span> <span class="n">omitted</span><span class="p">...</span>
</code></pre></div></div> <p>In file <code class="language-plaintext highlighter-rouge">bin/skins/HeavenlyExpress-1.3.0/shaders/holdbutton.fs</code>:</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#version 330
#extension GL_ARB_separate_shader_objects : enable
</span>
<span class="n">layout</span><span class="p">(</span><span class="n">location</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="n">in</span> <span class="n">vec2</span> <span class="n">fsTex</span><span class="p">;</span>
<span class="n">layout</span><span class="p">(</span><span class="n">location</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="n">out</span> <span class="n">vec4</span> <span class="n">target</span><span class="p">;</span>

<span class="n">uniform</span> <span class="n">sampler2D</span> <span class="n">mainTex</span><span class="p">;</span>
<span class="n">uniform</span> <span class="kt">float</span> <span class="n">objectGlow</span><span class="p">;</span>

<span class="n">out</span> <span class="n">vec4</span> <span class="n">position</span><span class="p">;</span> <span class="c1">// update here</span>

<span class="p">...</span><span class="n">rest</span> <span class="n">of</span> <span class="n">file</span> <span class="n">omitted</span><span class="p">...</span>
</code></pre></div></div> <p>Restart the game and you should be good now.</p> <h3 id="experimentalgear-custom-skin-does-not-change">ExperimentalGear Custom Skin Does Not Change</h3> <p>I faced issues where it appeared that the value that I set in the settings page for the skin to use was not being saved. I resolved this by manually editing the config file in <code class="language-plaintext highlighter-rouge">./bin/skins/ExperimentalGear/skin.cfg</code>.</p>]]></content><author><name>fanpu</name></author><category term="general"/><category term="rhythm-games"/><summary type="html"><![CDATA[Rhythm is just a $200 controller and some hopefully-not-too-complicated open source software setup away! This beginner's guide will help to demystify the process of setting up Sound Voltex at home using a custom SDVX controller using Unnamed SDVX Clone.]]></summary></entry><entry><title type="html">Creating Trackback Requests for Static Sites</title><link href="https://fanpu.io/blog/2023/creating-trackback-requests/" rel="alternate" type="text/html" title="Creating Trackback Requests for Static Sites"/><published>2023-09-01T00:00:00+00:00</published><updated>2023-09-01T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/creating-trackback-requests</id><content type="html" xml:base="https://fanpu.io/blog/2023/creating-trackback-requests/"><![CDATA[<p>In this article, I will show you how you can generate trackback requests to external websites to link back to your static site like <a href="https://jekyllrb.com/">Jekyll</a> or <a href="https://gohugo.io/">Hugo</a>. I decided to write this article after realizing how there is almost no information online about how to make DIY trackback requests when I was trying to set it up.</p> <h2 id="what-is-trackback">What is Trackback?</h2> <p>From <a href="">Wikipedia</a>:</p> <blockquote> <p>A trackback allows one website to notify another about an update. It is one of four types of linkback methods for website authors to request notification when somebody links to one of their documents. This enables authors to keep track of who is linking to their articles. Some weblog software, such as SilverStripe, WordPress, Drupal, and Movable Type, supports automatic pingbacks where all the links in a published article can be pinged when the article is published. The term is used colloquially for any kind of linkback.</p> </blockquote> <p>Essentially, it is a mechanism for other websites to know that you mentioned them, with the hope that they’ll notice you and possibly mention you as well. It helps to increase the visibility and discoverability of your website.</p> <h2 id="use-case">Use Case</h2> <p>My use case was to send trackbacks to <a href="https://info.arxiv.org/help/trackback.html">arXiv</a>, so that specific arXiv papers will know that my blog post mentioned them, and readers can also check it out as an additional resource. In particular, each of my <a href="/summaries/">paper summary</a> posts is based around a paper, and it would be nice if they could be linked from the respective arXiv paper abstract pages.</p> <p>In arXiv, there is a blog link section that will track websites that made trackback requests for a given paper:</p> <figure> <picture> <img src="/assets/img/posts/trackback_post/trackback_blog_link.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Unfortunately, if you try to search for anything about trackbacks and/or pingbacks, most of what you’ll get are articles about how to disable them on popular blogging platforms like WordPress due to <a href="https://blog.hubspot.com/website/trackback-spam">widespread misuse and spam</a>, or otherwise how to configure them.</p> <p>There was also a 7-year old <a href="https://superuser.com/questions/1098682/how-to-send-trackback-to-arxiv-papers-from-a-jekyll-blog">StackOverflow post</a> about how to create trackback requests for arXiv, essentially the same problem I was facing. Sadly, it currently has a grand total of 0 answers and 0 comments. I hope this article might be useful if the author is still facing the issue.</p> <h2 id="manually-creating-trackback-requests">Manually Creating Trackback Requests</h2> <p>The convenience of CMS blogging software like <a href="https://wordpress.org/documentation/article/trackbacks-and-pingbacks/">WordPress</a> is that it supports features like automated trackbacks and pingbacks for content that you create. Static site generators are not capable of this, since by design they are static and stateless. This means that we have to make such requests manually, which is fortunately not too difficult!</p> <p>Here’s a very simple script for doing it. In this example, the target URL is for the arXiv trackback endpoint.</p> <p>Before reading or running the code, please note that you <strong>SHOULD NOT</strong> test or experiment on this with trackback listener URLs and spam them. You should only make requests if they are legitimate and you have a genuine reason for letting them know about your blog post. Trackback spam is a serious issue and part of why they have become so unpopular and unmanageable is due to the high volumes of spam.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td class="code"><pre><span class="kn">import</span> <span class="n">requests</span>

<span class="c1"># Replace with your own data
</span><span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">title</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">My Awesome Blog Post</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">url</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">https://my-blog.com/post/</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">blog_name</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">My Awesome Blog</span><span class="sh">'</span>
<span class="p">}</span>

<span class="c1"># Replace with actual Trackback destination URL
</span><span class="n">trackback_url</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">https://foo.bar/trackback/post_id</span><span class="sh">'</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span><span class="n">trackback_url</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>

<span class="k">if</span> <span class="n">response</span><span class="p">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Trackback successful!</span><span class="sh">"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Trackback failed with status code: </span><span class="si">{</span><span class="n">response</span><span class="p">.</span><span class="n">status_code</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">response</span><span class="p">.</span><span class="n">content</span><span class="p">.</span><span class="nf">decode</span><span class="p">())</span>
</pre></td></tr></tbody></table></code></pre></figure> <p>A successful response has the <code class="language-plaintext highlighter-rouge">error</code> field set to <code class="language-plaintext highlighter-rouge">0</code>:</p> <figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="cp">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span>
<span class="nt">&lt;response&gt;</span>
  <span class="nt">&lt;error&gt;</span>0<span class="nt">&lt;/error&gt;</span>
<span class="nt">&lt;/response&gt;</span></code></pre></figure> <p>If an error occured, the <code class="language-plaintext highlighter-rouge">error</code> field is set to <code class="language-plaintext highlighter-rouge">1</code>:</p> <figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="cp">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span>
<span class="nt">&lt;response&gt;</span>
  <span class="nt">&lt;error&gt;</span>1<span class="nt">&lt;/error&gt;</span>
  <span class="nt">&lt;message&gt;</span>(some error message)<span class="nt">&lt;/message&gt;</span>
<span class="nt">&lt;/response&gt;</span></code></pre></figure> <h2 id="conclusion">Conclusion</h2> <p>And that’s all there is to creating Trackback requests! It’s actually quite simple, and is just not terribly well-documented.</p> <p>As a final parting word, a reminder again to please use it <em>responsibly</em> and <em>stay away from any behavior that could be constituted as spamming</em>.</p>]]></content><author><name>fanpu</name></author><category term="code"/><category term="general"/><summary type="html"><![CDATA[A simple guide on creating manual Trackback requests for static sites to increase visibility and discoverability]]></summary></entry><entry><title type="html">A Unified Framework for High-Dimensional Analysis of M-Estimators with Decomposable Regularizers: A Guided Walkthrough</title><link href="https://fanpu.io/blog/2023/high-dimensional-analysis-of-m-estimators/" rel="alternate" type="text/html" title="A Unified Framework for High-Dimensional Analysis of M-Estimators with Decomposable Regularizers: A Guided Walkthrough"/><published>2023-07-14T00:00:00+00:00</published><updated>2023-07-14T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/high-dimensional-analysis-of-m-estimators</id><content type="html" xml:base="https://fanpu.io/blog/2023/high-dimensional-analysis-of-m-estimators/"><![CDATA[\[\newcommand{\rcal}{\mathcal{R}} \newcommand{\lcal}{\mathcal{L}} \newcommand{\mcal}{\mathcal{M}} \newcommand{\mocal}{\overline{\mathcal{M}}} \newcommand{\mocalp}{\overline{\mathcal{M}}^\perp} \newcommand{\mcalp}{\mathcal{M}^\perp} \newcommand{\sse}{\subseteq} \newcommand{\kl}{\kappa_{\lcal}} \newcommand{\tl}{\tau_{\lcal}} \newcommand{\ts}{\theta^*} \newcommand{\hd}{\widehat{\Delta}} \newcommand{\thatn}{\hat{\theta}_n} \newcommand{\that}{\hat{\theta}} \newcommand{\thatlambda}{\widehat{\theta}_{\lambda_n}} \newcommand{\thatl}{\thatlambda} \newcommand{\rs}{\rcal^*} \newcommand{\ctriplet}{ \C(\mcal, \mocalp; \ts) } \newcommand{\fcal}{\mathcal{F}} \newcommand{\kbb}{\mathbb{K}} \newcommand{\dotprod}[2]{\langle #1, #2 \rangle} \DeclareMathOperator*{\argmin}{arg\,min}\] <h1 id="introduction">Introduction</h1> <p>In high-dimensional statistical inference, it is common for the number of parameters \(p\) to be comparable to or greater than the sample size \(n\). However, for an estimator \(\thatn\) to be consistent in such a regime, meaning that it converges to the true parameter \(\theta\), it is necessary to make additional low-dimensional assumptions on the model. Examples of such constraints that have been well-studied include linear regression with sparsity constraints, estimation of structured covariance or inverse covariance matrices, graphical model selection, sparse principal component analysis (PCA), low-rank matrix estimation, matrix decomposition problems and estimation of sparse additive nonparametric models <a href="https://arxiv.org/abs/1010.2731">(Negahban et al., 2009)</a>.</p> <p>In recent years, there has been a flurry of work on each of these individual specific cases. However, the authors of the paper in discussion poses the question of whether there is a way of unifying these analysis to understand all of such estimators in a common framework, and answers it in the affirmative. They showed that it is possible to bound the squared difference between any regularized \(M\)-estimator and its true parameter by (1) the decomposability of the regularization function, and (2) restricted strong convexity of the loss function. We will call this the “main theorem” in the remainder of the blog post, and this is referred to as “Theorem 1” in <a href="https://arxiv.org/abs/1010.2731">(Negahban et al., 2009)</a>.</p> <p>In the remainder of the paper, we will develop the tools necessary to deeply understand and prove the result. Notation used will be consistent with the original paper for expositional clarity.</p> <h1 id="background">Background</h1> <p>In this section, we develop some of the necessary background and notation to build up to the proof.</p> <h2 id="regularized-m-estimators">Regularized \(M\)-estimators</h2> <p>\(M\)-estimators (\(M\) for “maximum likelihood-type”) are solutions that minimize the sum of loss functions \(\rho\): \begin{align} \that \in \argmin_\theta \sum_{i=1}^n \rho(x_i, \theta). \end{align}</p> <p>If we add a regularization term \(\rcal\) to penalize complexity of the model, scaled by weights \(\lambda\), the method is known as a regularized \(M\)-estimator: \begin{align} \that \in \argmin_\theta \sum_{i=1}^n \rho(x_i, \theta) + \lambda \rcal(\theta). \end{align}</p> <div class="example"> <div class="theorem-title">Example (Lasso Program) </div> <div class="theorem-contents"> The Lasso program is an example of a regularized \( M \)-estimator, where a \( \ell_1 \) regularization penalty is applied: $$ \that \in \argmin_{\theta \in \mathbb{R}^d} \left\{ \frac{1}{2n} \| y - \bX \theta \|_2^2 + \lambda_n \| \theta \|_1 \right\}. $$ </div> </div> <h2 id="dual-norms">Dual Norms</h2> <div class="definition"> <div class="theorem-title">Definition (Dual Norms) </div> <div class="theorem-contents"> Let \(\rcal\) be a norm induced by an inner product \(\dotprod{\cdot}{\cdot}\). Then the dual norm of \(\rcal\) is defined as $$ \rs(v) \coloneqq \sup_{u \in \mathbb{R}^p \setminus \left\{ 0 \right\}} \frac{ \dotprod{u}{v} }{\rcal (u)} = \sup_{\rcal(u) \leq 1} \dotprod{u}{v}. $$ </div> </div> <div class="example"> <div class="theorem-title">Example (\(\ell_1\) and \(\ell_\infty\) norms are dual norms) </div> <div class="theorem-contents"> We will show that the dual of the \( \ell_1 \) norm is the \( \ell_\infty \) norm. Well, to see that \( \rs(v) \leq \| v \|_\infty \), observe that \begin{align*} \rs(v) &amp; = \sup_{\| u \|_1 \leq 1} \dotprod{u}{v} \\ &amp; = \sup_{\| u \|_1 \leq 1} \sum_{k=1}^p | u_k | | v_k | \\ &amp; \leq \sup_{\| u \|_1 \leq 1} \left( \sum_{k=1}^p | u_k | \right) \| v \|_\infty \\ &amp; = | v |_\infty \tag{since \( \| u \|_1 \leq 1 \) }. \end{align*} For the opposite direction, \begin{align*} \sup_{\| u \|_1 \leq 1} \dotprod{u}{v} &amp; = \sup_{\| u \|_1 \leq 1} \sum_{k=1}^p |u_k| |v_k| \\ &amp; \geq 1 \cdot |v_j| \tag{ set \( j = \argmax_j |v_j|, u = \be_j \) } \\ &amp; = \| v \|_\infty, \end{align*} hence we have equality. </div> </div> <h2 id="subspace-compatibility-constant">Subspace Compatibility Constant</h2> <p>The subspace compatibility constant measures how much the regularizer \(\rcal\) can change with respect to the error norm \(\| \cdot \|\) restricted to the subspace \(\mcal\). This concept will show up later in showing that the restricted strong convexity condition will hold with certain parameters.</p> <p>The subspace compatibility constant is defined as follows:</p> <div class="definition"> <div class="theorem-title">Definition (Subspace Compatibility Constant) </div> <div class="theorem-contents"> For any subspace \( \mcal \) of \( \mathbb{R}^p \), the <i>subspace compatibility constant</i> with respect to the pair \( (\rcal, \| \cdot \|) \) is given by $$ \varPsi (\mcal) \coloneqq \sup_{u \in \mcal \setminus \left\{ 0 \right\}} \frac{\rcal(u)}{\| u \|}. $$ </div> </div> <p>It can be thought of as the Lipschitz constant of the regularizer with respect to the error norm restricted to values in \(\mcal\), by considering the point where it can vary the most.</p> <h2 id="projections">Projections</h2> <p>Define the projection operator \begin{align} \Pi_{\mcal}(u) \coloneqq \argmin_{v \in \mcal} | u - v | \end{align} to be the projection of \(u\) onto the subspace \(\mcal\). For notational brevity, we will use the shorthand \(u_{\mcal} = \Pi_{\mcal}(u)\).</p> <p>One property of the projection operator is that it is non-expansive, meaning that \begin{align} | \Pi(u) - \Pi(v) | \leq | u - v | \label{eq:non-expansive} \end{align} for some error norm \(\| \cdot \|\). In other words, it has Lipschitz constant 1.</p> <h1 id="problem-formulation">Problem Formulation</h1> <p>In our setup, we define the following quantities:</p> <ul> <li>\(Z_1^n \coloneqq \left\{ Z_1, \cdots, Z_n \right\}\) \(n\) i.i.d observations drawn from distribution \(\mathbb{P}\) with some parameter \(\theta^*\),</li> <li>\(\mathcal{L}: \mathbb{R}^p \times \mathcal{Z}^n \to \mathbb{R}\) a convex and differentiable loss function, such that \(\mathcal{L}(\theta; Z_1^n)\) returns the loss of \(\theta\) on observations \(Z_1^n\),</li> <li>\(\lambda_n &gt; 0\): a user-defined regularization penalty,</li> <li>\(\mathcal{R} : \mathbb{R}^p \to \mathbb{R}_+\) a norm-based regularizer.</li> </ul> <p>The purpose of the regularized \(M\)-estimator is then to solve for the convex optimization problem</p> \[\begin{align} \label{eq:opt} \widehat{\theta}_{\lambda_n} \in \argmin_{\theta \in \mathbb{R}^p} \left\{ \mathcal{L}(\theta; Z_1^n) + \lambda_n \mathcal{R} (\theta) \right\}, \end{align}\] <p>and we are interested in deriving bounds on \(\begin{align} \| \thatlambda - \theta^* \| \end{align}\) for some error norm \(\| \cdot \|\) induced by an inner product \(\langle \cdot, \cdot \rangle\) in \(\mathbb{R}^p\).</p> <h1 id="decomposability-of-the-regularizer-mathcalr">Decomposability of the Regularizer \(\mathcal{R}\)</h1> <p>The first key property in the result is decomposability of our norm-based regularizer \(\rcal\). Working in the ambient \(\mathbb{R}^p\), define \(\mcal \sse \mathbb{R}^p\) to be the model subspace that captures the constraints of the model that we are working with (i.e \(k\)-sparse vectors), and denote \(\mocal\) to be its closure, i.e the union of \(\mcal\) and all of its limit points. In addition, denote \(\mocalp\) to be the orthogonal complement of \(\mocal\), namely</p> \[\begin{align} \mocalp \coloneqq \left\{ v \in \mathbb{R}^p \mid \langle u, v \rangle = 0 \text{ for all \( u \in \mocal \) } \right\}. \end{align}\] <p>We call this the perturbation subspace, as they represent perturbations away from the model subspace \(\mocal\). The reason why we need to consider \(\mocal\) instead of \(\mcal\) is because there are some special cases of low-rank matrices and nuclear norms where it could be possible that \(\mcal\) is strictly contained in \(\mocal\).</p> <p>Now we can introduce the property of decomposability:</p> <div class="definition"> <div class="theorem-title">Definition (Regularizer Decomposability) </div> <div class="theorem-contents"> Given a pair of subspaces \( \mcal \sse \mocal \), a norm-based regularizer \( \rcal \) is <i>decomposable</i> with respect to \( (\mocal, \mocalp) \) if $$ \rcal(\theta + \gamma) = \rcal(\theta) + \rcal(\gamma) $$ for all \( \theta \in \mcal \) and \( \gamma \in \mocalp \). </div> </div> <p>Since \(\rcal\) is a norm-based regularizer, by the triangle inequality property of norms we know that always \begin{align} \rcal(\theta + \gamma) \leq \rcal(\theta) + \rcal(\gamma), \end{align} and hence this is a stronger condition which requires tightness in the inequality when we are specifically considering elements in the closure of the model subspace and its orthogonal complement.</p> <p>Decomposability of the regularizer is important as it allows us to penalize deviations \(\gamma\) away from the model subspace in \(\mcal\) to the maximum extent possible. We are usually interested to find model subspaces that are small, with a large orthogonal complement. We will see in the main theorem that when this is the case, we will obtain better rates for estimating \(\theta^*\).</p> <p>There are many natural contexts that admit regularizers which are decomposable with respect to subspaces, and the following example highlights one such case.</p> <div class="example"> <div class="theorem-title">Example (\( s \)-sparse Vectors) </div> <div class="theorem-contents"> Consider estimating the parameters \( \that \) with \( \ell_1 \)-regularization in \( \mathbb{R}^p \) where we assume that the model is \( s \)-sparse. Then for any set \( S \sse [p] \) where \( |S| = s \), we can define our model subspace \( \mcal \) as \[ \begin{align*} \mcal(S) \coloneqq \left\{ \theta \in \mathbb{R}^p \mid \theta_j = 0 \quad \forall j \not\in S \right\}, \end{align*} \] i.e all the vectors in \( \mathbb{R}^p \) that only has support in \( S \). In this case, \( \mcal = \mocal \), and our orthogonal complement \( \mocalp \) is just \[ \begin{align*} \mocalp(S) \coloneqq \left\{ \gamma \in \mathbb{R}^p \mid \gamma_j = 0 \quad \forall j \in S \right\}. \end{align*} \] Then this setup is decomposable: \[ \begin{align*} \| \theta + \gamma \|_1 = \| \theta_S + \gamma_{S^c} \|_1 = \| \theta_S \|_1 + \| \gamma_{S^c} \| = \| \theta \|_1 + \| \gamma \|_1 \end{align*} \] by the Pythagorean theorem. </div> </div> <h2 id="role-of-decomposability">Role of Decomposability</h2> <figure id="fig-1"> <picture> <img src="/assets/img/posts/high-dimensional-analysis-of-m-estimators/c_illust.webp" class="z-depth-1 center" width="500px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 1.</i> A visualization of \( \ctriplet \). The shaded area represents the set \( \ctriplet \), i.e all values of \( \theta \) that satisfies the inequality of the set in Lemma 1. </figcaption> </figure> <p>Decomposability is important because it allows us to bound the error of the estimator. This is given in the following result, which is known as Lemma 1 in <a href="https://arxiv.org/abs/1010.2731">(Negahban et al., 2009)</a>:</p> <div class="lemma" id="lemma-1"> <div class="theorem-title">Lemma (Lemma 1 in <a href="https://arxiv.org/abs/1010.2731"> (Negahban et al., 2009) </a>) </div> <div class="theorem-contents"> Suppose that \( \lcal \) is a convex and differentiable function, and consider any optimal solution \( \that \) to the optimization problem with a strictly positive regularization parameter satisfying $$ \begin{align*} \lambda_n \geq 2 \rcal^* (\nabla \lcal (\ts; Z_1^n)). \end{align*} $$ Then for any pair \( (\mcal, \mocalp) \) over which \( \rcal \) is decomposable, the error \( \hd = \thatlambda - \ts \) belongs to the set $$ \begin{align*} \label{eq:c} \C(\mcal, \mocalp; \ts) \coloneqq \left\{ \Delta \in \mathbb{R}^p \mid \rcal(\Delta_{\mocalp}) \leq 3 \rcal (\Delta_{\mocal}) + 4 \rcal (\ts_{\mcalp}) \right\}. \end{align*} $$ </div> </div> <p>Recall from the <a href="#projections">Projections Section</a> that \(\Delta_{\mocalp}\) represents the projection of \(\Delta\) onto \(\mocalp\), and similarly for the other quantities. Due to space constraints, we are unable to prove Lemma <a href="#lemma-1">Lemma 1</a> in this survey, but it is very important in the formulation of restricted strong convexity, and in proving <a href="#thm-1">Theorem 1</a>.</p> <p><a href="#fig-1">Figure 1</a> provides a visualization of \(\ctriplet\) in \(\mathbb{R}^3\) in the sparse vectors setting. In this case, \(S = \left\{ 3 \right\}\) with \(|S|=1\), and so the projection of \(\Delta\) onto the model subspace only has non-zero values on the third coordinate, and its orthogonal complement is where the third coordinate is zero. Formally,</p> \[\begin{align} \mcal(S) = \mocal(S) &amp; = \left\{ \Delta \in \mathbb{R}^3 \mid \Delta_1 = \Delta_2 = 0 \right\}, \\ \mocalp(S) &amp; = \left\{ \Delta \in \mathbb{R}^3 \mid \Delta_3 = 0 \right\}. \end{align}\] <p>The vertical axis of <a href="#fig-1">Figure 1</a> denotes the third coordinate, and the horizontal plane denotes the first two coordinates. The shaded area represents the set \(\ctriplet\), i.e all values of \(\theta\) that satisfies the inequality of the set in <a href="#lemma-1">Lemma 1</a>.</p> <p><a href="#fig-1">Figure 1(a)</a> shows the special case when \(\ts \in \mcal\). In this scenario, \(\rcal (\ts_{\mcalp}) = 0\), and so</p> \[\begin{align*} \C(\mcal, \mocalp; \ts) = \left\{ \Delta \in \mathbb{R}^p \mid \rcal(\Delta_{\mocalp}) \leq 3 \rcal (\Delta_{\mocal}) \right\}, \end{align*}\] <p>which is a cone.</p> <p>However, in the general setting where \(\ts \not\in \mcal\), then \(\rcal (\ts_{\mcalp}) &gt; 0\), and the set \(\ctriplet\) will become a star-shaped set like what is shown in <a href="#fig-1">Figure 1(b)</a>.</p> <h1 id="restricted-strong-convexity-rsc-of-the-loss-function">Restricted Strong Convexity (RSC) of the Loss Function</h1> <figure id="fig-2"> <picture> <img src="/assets/img/posts/high-dimensional-analysis-of-m-estimators/curvature.webp" class="z-depth-1 center" width="500px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 2.</i> An illustration of the role of curvature in guaranteeing that \( \hd = \thatlambda - \ts \) is small when \( \lcal(\thatlambda) - \lcal(\ts) \) is small. </figcaption> </figure> <p>In a classical setting, as the number of samples \(n\) increases, the difference in loss \(d \lcal = |\lcal(\thatlambda) - \lcal(\ts)|\) will converge to zero. However, the convergence in loss by itself is insufficient to also ensure the convergence in parameters, \(\hd = \thatlambda - \ts\). Instead, it also depends on the curvature of the loss function \(\lcal\).</p> <p><a href="#fig-2">Figure 2</a> illustrates the importance of curvature. In <a href="#fig-2">Figure 2(a)</a>, \(\lcal\) has high curvature, and so having a small \(d\lcal\) also implies a small \(\hd\). On the other hand, in <a href="#fig-2">Figure 2(b)</a>, \(\lcal\) has an almost flat landscape near \(\thatlambda\), and hence even when \(d \lcal\) is small, \(\hd\) could still be large.</p> <p>Consider performing a Taylor expansion of \(\lcal\) around \(\ts\):</p> \[\begin{align} \lcal(\ts + \Delta) &amp; = \lcal(\ts) + \dotprod{\nabla \lcal(\ts)}{\Delta} + \underbrace{\frac{1}{2} \Delta^T \nabla^2 \lcal(\ts) \Delta + \dots}_{\delta \lcal(\Delta, \ts)}. \end{align}\] <p>Then we can rearrange and write the error of the first-order Taylor series expansion at \(\ts\) as</p> \[\begin{align*} \delta \lcal(\Delta, \ts) = \lcal(\ts + \Delta) - \lcal(\ts) - \dotprod{\nabla \lcal(\ts)}{\Delta}. \end{align*}\] <p>The first-order Taylor approximation is a linear approximation, and hence the error \(\delta \lcal(\Delta, \ts)\), which is dominated by the quadratic term, can capture the curvature about \(\ts\).</p> <p>As such, one way to show that \(\lcal\) has good curvature about \(\ts\) is to show that \(\delta \lcal(\Delta, \ts) \geq \kappa \|\Delta \|^2\) holds for all \(\Delta\) in a neighborhood of \(\ts\). This is because we are enforcing a lower bound on its quadratic growth.</p> <p>This leads us to the definition of restricted strong convexity:</p> <div class="definition"> <div class="theorem-title">Definition (Restricted Strong Convexity) </div> <div class="theorem-contents"> The loss function satisfies a <i>restricted strong convexity</i> (RSC) condition with curvature \( \kl &gt; 0 \) and tolerance function \( \tl \) if \begin{align*} \delta \lcal(\Delta, \ts) \geq \kl \| \Delta \|^2 - \tl^2(\ts) \end{align*} for all \( \Delta \in \ctriplet \). </div> </div> <p>We only need to consider error terms \(\Delta \in \ctriplet\), since Lemma \ref{lemma:1} guarantees us that the error term will only lie in that set.</p> <p>In many statistical models, restricted strong convexity holds with \(\tl = 0\), however, it is required in more general settings, such as generalized linear models.</p> <h1 id="proof-of-theorem-1">Proof of Theorem 1</h1> <p>We can now state and prove the main result of the paper. This will hold under the decomposability of the regularizer (G1), and the restricted strong convexity of the loss function (G2).</p> <ul> <li> <p><strong>(G1)</strong> The regularizer \(\rcal\) is a norm and is decomposable with respect to the subspace pair \((\mcal, \mocalp)\), where \(\mcal \sse \mocalp\).</p> </li> <li> <p><strong>(G2)</strong> The loss function \(\lcal\) is convex and differentiable, and satisfies restricted strong convexity with curvature \(\kl\) and tolerance \(\tl\).</p> </li> </ul> <div class="theorem" id="thm-1"> <div class="theorem-title">Theorem 1 in (Negahban et al., 2009) (Bounds for General Models) </div> <div class="theorem-contents"> Under conditions (G1) and (G2), consider the convex optimization problem (\ref{eq:opt}) based on a strictly positive positive regularization constant \( \lambda_n \geq 2 \rs (\nabla \lcal (\ts)) \). Then any optimal solution \( \thatlambda \) to the convex program (\ref{eq:opt}) satisfies the bound \begin{align*} \| \thatlambda - \ts \|^2 \leq 9 \frac{\lambda_n^2}{\kl^2} \Psi^2(\mocal) + \frac{\lambda_n}{\kl} \left( 2 \tl^2 (\ts) + 4 \rcal (\ts_{\mcal^{\perp}}) \right). \end{align*} </div> </div> <p>We will rely on the following lemmas that will be stated without proof due to space constraints:</p> <div class="lemma"> <div class="theorem-title">Lemma 3 in (Negahban et al., 2009) (Deviation Inequalities) </div> <div class="theorem-contents"> For any decomposable regularizer and \( p \)-dimensional vectors \( \ts \) and \( \Delta \), we have \begin{align*} \rcal(\ts + \Delta) - \rcal(\ts) \geq \rcal(\Delta_{\mocalp}) - \rcal(\Delta_{\mocal}) - 2 \rcal(\ts_{\mcal^{\perp}}). \end{align*} Moreover, as long as \( \lambda_n \geq 2 \rs (\nabla \lcal(\ts)) \) and \( \lcal \) is convex, we have \begin{align*} \lcal(\ts + \Delta) - \lcal(\ts) \geq - \frac{\lambda_n}{2} [\rcal(\Delta_{\mocal}) + \rcal(\Delta_{\mocalp})]. \end{align*} </div> </div> <div class="lemma"> <div class="theorem-title">Lemma 4 in (Negahban et al., 2009) </div> <div class="theorem-contents"> If \( \fcal(\Delta) &gt; 0 \) for all vectors \( \Delta \in \mathbb{K}(\delta) \), then \( \| \hd \| \leq \delta \). </div> </div> <p>Note that this was similar to our previous analysis on restricted strong convexity where we only really need to consider error terms restricted to \(\ctriplet\) due to <a href="#lemma-1">Lemma 1</a>. Therefore, it suffices to show \(\fcal(\Delta) &gt; 0\) to obtain a bound on \(\| \hd \| = \| \thatlambda - \ts\|\), which completes the proof of Theorem 1.</p> <p>Define \(\fcal : \mathbb{R}^p \to \mathbb{R}\) by</p> \[\begin{align} \fcal(\Delta) \coloneqq \lcal(\ts + \Delta) - \lcal(\ts) + \lambda_n \left\{ \rcal(\ts + \Delta) - \rcal(\ts) \right\}, \end{align}\] <p>and define the set</p> \[\begin{align} \mathbb{K}(\delta) \coloneqq \ctriplet \cap \left\{ \| \Delta \| = \delta \right\}. \end{align}\] <p>Take any \(\Delta \in \kbb\). Then</p> \[\begin{align} \fcal(\Delta) = &amp; \lcal(\ts + \Delta) - \lcal(\ts) + \lambda_n \left\{ \rcal(\ts + \Delta) - \rcal(\ts) \right\} \tag{by definition} \\ \geq &amp; \langle \nabla \lcal (\ts), \Delta \rangle + \kl \| \Delta \|^2 - \tl^2(\ts) + \lambda_n \left\{ \rcal(\ts + \Delta) - \rcal(\ts) \right\} \\ &amp; \qquad \text{(by restricted strong convexity: \(\delta \lcal(\Delta, \ts) \geq \kl \| \Delta \|^2 - \tl^2(\ts)\),} \\ &amp; \qquad \text{ and \( \delta \lcal(\Delta, \ts) = \lcal(\ts + \Delta) - \lcal(\ts) - \dotprod{\nabla \lcal(\ts)}{\Delta} \) ) } \\ \geq &amp; \langle \nabla \lcal (\ts), \Delta \rangle + \kl \| \Delta \|^2 - \tl^2(\ts) + \lambda_n \left\{ \rcal(\Delta_{\mocalp}) - \rcal(\Delta_{\mocal}) - 2 \rcal(\ts_{\mcal^{\perp}}) \right\} \\ &amp; \qquad \text{(by Lemma 3)}. \label{thm-deriv:1} \end{align}\] <p>We lower bound the first term as \(\langle \nabla \lcal (\ts), \Delta \rangle \geq - \frac{\lambda_n}{2} \rcal(\Delta)\):</p> \[\begin{align} | \langle \nabla \lcal (\ts), \Delta \rangle | \leq &amp; \rs(\nabla \lcal(\ts)) \rcal(\Delta) &amp; \text{(Cauchy-Schwarz using dual norms \( \rcal \) and \( \rs \))} \\ \leq &amp; \frac{\lambda_n}{2} \rcal(\Delta) &amp; \text{Theorem 1 assumption: \( \lambda_n \geq 2 \rs (\nabla \lcal(\ts)) \))}, \end{align}\] <p>and hence,</p> \[\begin{align} \langle \nabla \lcal (\ts), \Delta \rangle \geq &amp; - \frac{\lambda_n}{2} \rcal(\Delta). \end{align}\] <p>So applying to (\ref{thm-deriv:1}),</p> \[\begin{align} \fcal(\Delta) \geq &amp; \kl \| \Delta \|^2 - \tl^2(\ts) + \lambda_n \left\{ \rcal(\Delta_{\mocalp}) - \rcal(\Delta_{\mocal}) - 2 \rcal(\ts_{\mcal^{\perp}}) \right\} - \frac{\lambda_n}{2} \rcal(\Delta) \\ \geq &amp; \kl \| \Delta \|^2 - \tl^2(\ts) + \lambda_n \left\{ \rcal(\Delta_{\mocalp}) - \rcal(\Delta_{\mocal}) - 2 \rcal(\ts_{\mcal^{\perp}}) \right\} - \frac{\lambda_n}{2} (\rcal(\Delta_{\mocalp}) + \rcal(\Delta_{\mocal})) \\ &amp; \qquad \text{(Triangle inequality: \( \rcal(\Delta) \leq \rcal(\Delta_{\mocalp}) + \rcal(\Delta_{\mocal}) \))} \\ = &amp; \kl \| \Delta \|^2 - \tl^2(\ts) + \lambda_n \left\{ \frac{1}{2}\rcal(\Delta_{\mocalp}) - \frac{3}{2}\rcal(\Delta_{\mocal}) - 2 \rcal(\ts_{\mcal^{\perp}}) \right\} \\ &amp; \qquad \text{(Moving terms in)} \\ \geq &amp; \kl \| \Delta \|^2 - \tl^2(\ts) + \lambda_n \left\{ - \frac{3}{2}\rcal(\Delta_{\mocal}) - 2 \rcal(\ts_{\mcal^{\perp}}) \right\} \\ &amp; \qquad \text{(Norms always non-negative)} \\ = &amp; \kl \| \Delta \|^2 - \tl^2(\ts) - \frac{\lambda_n }{2} \left\{ 3 \rcal(\Delta_{\mocal}) + 4 \rcal(\ts_{\mcal^{\perp}}) \right\} \label{eq:r-delta-lb} . \end{align}\] <p>To bound the term \(\rcal(\Delta_{\mocal})\), recall the definition of subspace compatibility:</p> \[\begin{align} \varPsi (\mcal) \coloneqq \sup_{u \in \mcal \setminus \left\{ 0 \right\}} \frac{\rcal(u)}{\| u \|}, \label{eq:r-delta-ub} \end{align}\] <p>and hence</p> \[\begin{align} \rcal(\Delta_{\mocal}) \leq \varPsi(\mocal) \| \Delta_{\mocal} \|. \end{align}\] <p>To upper bound \(\| \Delta_{\mocal} \|\), we have</p> \[\begin{align} \| \Delta_{\mocal} \| &amp; = \| \Pi_{\mocal} (\Delta) - \Pi_{\mocal}(0) \| &amp; \text{(Since \(0 \in \mocal \), \( \Pi_{\mocal}(0) = 0 \)) } \\ &amp; \leq \| \Delta - 0 \| &amp; \text{(Projection operator is non-expansive, see Equation \ref{eq:non-expansive})} \\ &amp; = \| \Delta \|, \end{align}\] <p>which substituting into Equation (\ref{eq:r-delta-ub}) gives</p> \[\begin{align} \rcal(\Delta_{\mocal}) \leq \varPsi(\mocal) \| \Delta \|. \end{align}\] <p>Now we can use this result to lower bound Equation \ref{eq:r-delta-lb}:</p> \[\begin{align} \fcal (\Delta) \geq &amp; \kl \| \Delta \|^2 - \tl^2(\ts) - \frac{\lambda_n }{2} \left\{ 3 \varPsi(\mocal) \| \Delta \| + 4 \rcal(\ts_{\mcal^{\perp}}) \right\}. \label{eq:strict-psd} \end{align}\] <p>The RHS of the inequality in Equation \ref{eq:strict-psd} has a strictly positive definite quadratic form in \(\| \Delta \|\), and hence by taking \(\| \Delta \|\) large, it will be strictly positive. To find such a sufficiently large \(\| \Delta \|\), write</p> \[\begin{align} a &amp; = \kl, \\ b &amp; = \frac{3\lambda_n}{2} \varPsi (\mocal), \\ c &amp; = \tau_{\lcal}^2 (\ts) + 2 \lambda_n \rcal(\ts_{\mcalp}), \\ \end{align}\] <p>such that we have</p> \[\begin{align} \fcal (\Delta) &amp; \geq a \| \Delta \|^2 - b \| \Delta \| - c. \end{align}\] <p>Then the square of the rightmost intercept is given by the squared quadratic formula</p> \[\begin{align} \| \Delta \|^2 &amp; = \left( \frac{-(-b) + \sqrt{b^2 - 4a(-c)}}{2a} \right)^2 \\ &amp; = \left( \frac{b + \sqrt{b^2 + 4ac}}{2a} \right)^2 \\ &amp; \leq \left( \frac{\sqrt{b^2 + 4ac}}{a} \right)^2 &amp; \text{($b \leq \sqrt{b^2 + 4ac}$)} \label{eq:coarse-bound} \\ &amp; = \frac{b^2 + 4ac}{a^2} \\ &amp; = \frac{9 \lambda_n^2 \varPsi^2 (\mocal)}{4 \kl^2} + \frac{ 4 \tau_{\lcal}^2 (\ts) + 8 \lambda_n \rcal(\ts_{\mcalp}) }{\kl}. &amp; \text{(Substituting in \(a, b, c\))} \\ \end{align}\] <p>In <a href="https://arxiv.org/abs/1010.2731">(Negahban et al., 2009)</a>, they were able to show an upper bound of</p> \[\begin{align} \| \Delta \|^2 &amp; \leq \frac{9 \lambda_n^2 \varPsi^2 (\mocal)}{\kl^2} + \frac{\lambda_n}{\kl} \left\{ 2\tau_{\lcal}^2 (\ts) + 4 \rcal(\ts_{\mcalp}) \right\}, \label{eq:ub} \end{align}\] <p>but I did not manage to figure out how they managed to produce a \(\lambda_n\) term beside the \(\tl^2(\ts)\) term. All other differences are just constant factors. It may be due to an overly coarse bound on my end applied in Equation \ref{eq:coarse-bound}, but it is unclear to me how the \(\lambda_n\) term can be applied on only the \(\tl^2(\ts)\) term without affecting the \(\rcal(\ts_{\mcalp})\) term.</p> <p>With Equation \ref{eq:ub}, we can hence apply Lemma 4 in <a href="https://arxiv.org/abs/1010.2731">(Negahban et al., 2009)</a> to obtain the desired result that</p> \[\begin{align} \| \thatlambda - \ts \|^2 \leq 9 \frac{\lambda_n^2}{\kl^2} \Psi^2(\mocal) + \frac{\lambda_n}{\kl} \left( 2 \tl^2 (\ts) + 4 \rcal (\ts_{\mcal^{\perp}}) \right). \end{align}\] <p>This concludes the proof.</p> <h1 id="conclusion">Conclusion</h1> <p>In the <a href="#proof-of-theorem-1">proof of Theorem 1</a>, we saw how the bound is derived from the two key ingredients of the decomposability of the regularizer, and restricted strong convexity of the loss function. The decomposability of the regularizer allowed us to ensure that the error vector \(\hd\) will stay in the set \(\ctriplet\). This condition is then required in Lemma 4 of <a href="https://arxiv.org/abs/1010.2731">(Negahban et al., 2009)</a>, which allows us to bound \(\| \hd \|\) given that \(\fcal(\Delta) &gt; 0\). In one of the steps where we were lower bounding \(\fcal(\Delta)\) in the proof, we made use of the properties of restricted strong convexity.</p> <p><a href="#thm-1">Theorem 1</a> provides a family of bounds for each decomposable regularizer under the choice of \((\mcal, \mocalp)\). The authors of <a href="https://arxiv.org/abs/1010.2731">(Negahban et al., 2009)</a> were able to use <a href="#thm-1">Theorem 1</a> to rederive both existing known results, and also derive new results on low-rank matrix estimation using the nuclear norm, minimax-optimal rates for noisy matrix completion, and noisy matrix decomposition. The reader is encouraged to refer to <a href="https://arxiv.org/abs/1010.2731">(Negahban et al., 2009)</a> for more details on the large number of corrollaries of <a href="#thm-1">Theorem 1</a>.</p> <h1 id="acknowledgments">Acknowledgments</h1> <p>I would like to thank my dear friend <a href="https://www.linkedin.com/in/josh-abrams-78a4a6134/">Josh Abrams</a> for helping to review and provide valuable suggestions for this post!</p> <h1 id="citations">Citations</h1> <ol> <li>Negahban, S., Yu, B., Wainwright, M. J., and Ravikumar, P. <a href="https://proceedings.neurips.cc/paper_files/paper/2009/file/dc58e3a306451c9d670adcd37004f48f-Paper.pdf">A unified framework for high-dimensional analysis of m-estimators with decomposable regularizers</a>. In Bengio, Y., Schuurmans, D., Lafferty, J., Williams, C., and Culotta, A. (eds.), Advances in Neural Information Processing Systems, volume 22. Curran Associates, Inc., 2009. URL https://proceedings.neurips.cc/paper_files/paper/2009/file/dc58e3a306451c9d670adcd37004f48f-Paper.pdf.</li> </ol>]]></content><author><name>fanpu</name></author><category term="statistics"/><category term="machine-learning"/><summary type="html"><![CDATA[Imagine doing high-dimensional statistical inference, but instead of repeatedly studying different settings with specific low-dimensional constraints (such as linear regression with sparsity constraints, or estimation of structured covariance matrices), there is a method for performing a unified analysis using appropriate notions. Well, you're in luck! 'A Unified Framework for High-Dimensional Analysis of \( M \)-Estimators with Decomposable Regularizers' by Negahban, Ravikumar, Wainwright, and Yu shows that the \( \ell_2 \) difference between any regularized \(M\)-estimator and its true parameter can be bounded if the regularization function is decomposable, and the loss function satisfies restricted strong convexity. The goal of this post is to provide intuition for the result and develop sufficient background for understanding the proof of this result, followed by a walkthrough of the proof itself.]]></summary></entry><entry><title type="html">The CMU Steam Tunnels and Wean 9</title><link href="https://fanpu.io/blog/2023/cmu-steam-tunnels/" rel="alternate" type="text/html" title="The CMU Steam Tunnels and Wean 9"/><published>2023-06-16T00:00:00+00:00</published><updated>2023-06-16T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/cmu-steam-tunnels</id><content type="html" xml:base="https://fanpu.io/blog/2023/cmu-steam-tunnels/"><![CDATA[<p>If you’re curious about the infamous steam tunnels at CMU, or what the views from the roof of Wean Hall looks like, this is for you! The week after course finals concluded, <a href="https://www.cmu.edu/student-affairs/slice/">CMU SLICE</a> (Student Leadership, Involvement, and Civic Engagement) organized an Underground Steam Tunnels Tour as a Senior Week event. I was technically not a senior as I am a graduate student, but they were nice enough to let me join.</p> <p>Before I continue, let me warn readers that you are not allowed to enter the steam tunnels by yourself. Please sign up for an official tour by SLICE that will be led by a facilities engineer. From <a href="https://www.cmu.edu/student-affairs/theword/community-policies/steam-tunnels.html">The Word Student Handbook</a>:</p> <blockquote class="block-danger"> <h4 id="steam-tunnels">Steam Tunnels</h4> <p>Because of the danger to all who enter them, the steam tunnels are locked and anyone found in the tunnels will be subject to serious disciplinary action and/or criminal action. The University Police are responsible for keeping the tunnels locked and apprehending anyone who trespasses in them.</p> </blockquote> <h1 id="the-steam-tunnels">The Steam Tunnels</h1> <p>We met at the fence, and all of us had to sign a waiver and don a helmet (the same white helmet that was used by builders during Spring Carnival booth).</p> <p>We proceeded to the basement of Margaret Morrison Hall, and the engineer guiding the expedition shared some history about how the Margaret Morrison basement was enhanced to be flood-resistant after a flooding incident a few decades ago caused water to also flood into the steam tunnels.</p> <p>We were warned that the tunnels will be hot and claustrophobic, that we should not touch any pipes as they will be extremely hot, and to not poke at any asbestos for obvious reasons. He then unlocked an unmarked door, and let us into the tunnels proper:</p> <figure> <picture> <img src="/assets/img/posts/cmu_steam_tunnels/main_tunnel.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> Inside the steam tunnel! </figcaption> </figure> <p>It was initially still quite cool near the door, but the temperature began rising as we went further in. Some sections of the pipes were hissing and you could really feel the warmth emanating from them. At some point I was slightly afraid that a pipe beside me might burst.</p> <figure> <picture> <img src="/assets/img/posts/cmu_steam_tunnels/phone_box.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> A phone box in the tunnel. Hopefully no one ever had to use it. </figcaption> </figure> <p>At some point, there was a fork where the tunnel on the left fork became very short and narrow. We took the right fork.</p> <figure> <picture> <img src="/assets/img/posts/cmu_steam_tunnels/side_tunnel.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> The short and narrow left fork of the tunnel </figcaption> </figure> <p>It was generally quite well-lit, until we were brought to a section of the tunnel where we had to ascend a rusty ladder to reach a cavern, which was unlit. It was known as the CFA cavern as it is located right under the steps of CFA:</p> <figure> <picture> <img src="/assets/img/posts/cmu_steam_tunnels/cfa_cavern.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> The CFA cavern, with flash photography </figcaption> </figure> <p>Apparently at some point in the past, a very resourceful CFA student decided to make this their home. Not only was rent cheap (free!), but it was also very close to the CFA building! However, they were found by campus police and booted out.</p> <p>I would not say that it was the most ideal living arrangement. There were plastic bottles strewn everywhere, and stalactites growing down from the ceiling. The air was very damp and musty, and would probably do something bad to your lungs if you stayed in there long enough. It was surprisingly much cooler than the steam tunnels right below it though.</p> <p>We then went back down into the tunnels, and continued on:</p> <figure> <picture> <img src="/assets/img/posts/cmu_steam_tunnels/another_tunnel.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> More tunnels! </figcaption> </figure> <p>As it got close to the end of the tunnels, we were each handed chalk that can be used for leaving our mark in the tunnel. Since public vandalism is <a href="https://en.wikipedia.org/wiki/Vandalism_Act#Michael_Fay_(1994)">punishable by caning</a> in my home country, of course I was not going to pass on this wonderful opportunity to defile the steam tunnels to my heart’s content:</p> <figure> <picture> <img src="/assets/img/posts/cmu_steam_tunnels/graffiti.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> SLICE-sanctioned vandalism </figcaption> </figure> <p>We then emerged from an exit deep inside Doherty Hall, which was nice as it was beginning to get rather uncomfortable and claustrophobic. Whew!</p> <h1 id="roof-of-wean">Roof of Wean</h1> <p>If you thought there were only 8 levels in Wean, then you will learn something new today. We took the freight elevator from the corner of Wean to floor PH (penthouse?), AKA Wean 9.</p> <p>Wean 9 was essentially a huge storeroom for CMU FMS (Facility Management Services). There were all sorts of supplies and tools, and even spare doors for classrooms. It made me realize just how much maintenance it took to operate a campus.</p> <figure> <picture> <img src="/assets/img/posts/cmu_steam_tunnels/wean_9.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> Our guide leading us through Wean 9 </figcaption> </figure> <p>We were finally brought to a door that led to the roof of Wean Hall, and had to adjust our eyes for a few seconds to the new blinding sunlight. It was beautiful!</p> <figure> <picture> <img src="/assets/img/posts/cmu_steam_tunnels/hammerschlag.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> A majestic view of Hammerschlag Hall. I wish I could take my graduation pictures from here. </figcaption> </figure> <p>Everyone got busy snapping photos, myself included. To my knowledge this is the only place on campus where you can take a side-by-side photo with the Hammerschlag radio tower:</p> <figure> <picture> <img src="/assets/img/posts/cmu_steam_tunnels/roof_photo.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> The Hammerschlag tower, which houses the Carnegie Tech Radio Club (W3VC) and contains both repeaters and transmitters. </figcaption> </figure> <figure> <picture> <img src="/assets/img/posts/cmu_steam_tunnels/cic.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> An interesting view of CIC and Tepper </figcaption> </figure> <figure> <picture> <img src="/assets/img/posts/cmu_steam_tunnels/gates.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> Gates, which is usually perceived to tower over all other campus buildings in its vicinity, look short from here </figcaption> </figure> <p>There was some open space on the roof, and I thought it would be pretty cool if they opened an open-air cafe here. It has pretty nice panoramic views of the entire campus.</p> <p>And that’s it for the tour!</p> <h1 id="acknowledgments">Acknowledgments</h1> <p>I would like to thank <a href="https://www.cmu.edu/student-affairs/slice/">SLICE</a> for organizing this trip, my friend <a href="https://www.linkedin.com/in/justin-sun-92b691169/">Justin Sun</a> who also went on this little adventure with me for proofreading this post, and <a href="https://www.linkedin.com/in/joseph-x-li/">Joey Li</a> for pointing out a mistake in the post, where I previously erroneously claimed that WRCT 88.3FM was also broadcast from Hammerschlag tower.</p>]]></content><author><name>fanpu</name></author><category term="general"/><category term="cmu"/><summary type="html"><![CDATA[If you're curious about the infamous steam tunnels at CMU, or what the views from the roof of Wean Hall looks like, this post is for you!]]></summary></entry><entry><title type="html">CMU 15712 Advanced Operating Systems and Distributed Systems Course Review</title><link href="https://fanpu.io/blog/2023/advanced-operating-systems-course-review/" rel="alternate" type="text/html" title="CMU 15712 Advanced Operating Systems and Distributed Systems Course Review"/><published>2023-06-09T00:00:00+00:00</published><updated>2023-06-09T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/advanced-operating-systems-course-review</id><content type="html" xml:base="https://fanpu.io/blog/2023/advanced-operating-systems-course-review/"><![CDATA[<p>This semester (Spring 2023), I took <a href="https://www.cs.cmu.edu/~15712/">15-712 Advanced Operating Systems and Distributed Systems</a> under professor <a href="http://www.cs.cmu.edu/~gibbons/">Phil Gibbons</a> and his TA and also PhD advisee <a href="http://nicebowlofsoup.com/">Val Choung</a>.</p> <p>This class exceeded my expectations significantly. I found it especially meaningful and apt since this was my last systems class before I graduate, and the topics and discussions from class helped to unify all the systems concepts that I had learnt from previous classes into a nice package informed by common underlying principles: from distributed systems, to networking, databases, filesystems, operating systems, and even machine learning systems.</p> <h1 id="the-first-lecture">The First Lecture</h1> <p>The first lecture went through 2 Wisdom Papers, which no one was expected to have read yet as it was the first class. You can refer to the <a href="https://www.cs.cmu.edu/~15712/lectures/01-intro.pdf">slides here</a> if you are curious.</p> <p>The first paper, <a href="https://www.cs.cmu.edu/~15712/papers/mythicalmanmonth00fred.pdf">Mythical Man-Month: Essays on Software Engineering</a> is a book by Turing-award winner Fred Brooks. It is about many of his observations and principles on software engineering based on his own vast experiences. What really brought it home to me was that a couple of them were also things that I had some suspicions about previously, but never really thought it was universally applicable, and thought they were simply artifacts of the way I approached things.</p> <p>For instance, one of the principles is “Plan to Throw One Away”, meaning that one should first build a worthwhile system in a short amount of time, and then re-build a better second version with the benefit of hindsight. This is because one would end up having to re-build the system anyway after being confronted with change and feedback, and also due to the following observation on program maintenance:</p> <blockquote> <p>“Program maintenance is an entropy-increasing process, and even its most skillful execution only delays the subsidence of the system into unfixable obsolescence”</p> </blockquote> <p>This had many parallels with my own experiences. For instance, my group ended up having 4 major re-writes of our kernel during 15-410, and I also did a complete re-write of my CloudFS filesystem for my 18-746 project. Similarly, many of my internship projects were also re-writes and improvements on design of existing systems that had accumulated too much technical debt. It does seem a lot more reasonable to plan for this eventual change to begin with.</p> <p>The paper also contained a lot of other great advice, such as the importance of conceptual integrity to separate architecture from implementation, structuring a team in a “surgical” fashion to drive software development where the best programmer leads the most critical development work like a surgeon and directs others on the other aspects, and of course the famous Brook’s law:</p> <blockquote> <p>“Adding manpower to a late software project makes it later”</p> </blockquote> <p>The second paper, <a href="https://www.cs.cmu.edu/~15712/papers/hamming86.pdf">You and Your Research</a> by Richard Hamming (of Hamming code fame), talks about how to become a great scientist. The following two slides gives a good sense of the spirit of the paper:</p> <figure> <picture> <img src="/assets/img/posts/adv_os/slide_1.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> How to be a Great Scientist (1) </figcaption> </figure> <figure> <picture> <img src="/assets/img/posts/adv_os/slide_2.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> How to be a Great Scientist (2) </figcaption> </figure> <p>I mention the first lecture and the two papers that were discussed here not simply because they were interesting, but because they helped to set the tone and expectations for the rest of the semester going forward. The message is clear: this is going to be a practical and useful class that will help you on your journey to becoming great systems designers and researchers.</p> <h1 id="course-content">Course Content</h1> <p>The class took us on a whirlwind tour through many <a href="https://www.sigops.org/awards/hof/">SIGOPS Hall of Fame papers</a>, which the award description states was “instituted in 2005 to recognize the most influential Operating Systems papers that were published at least ten years in the past”. Reading through the papers helped to consolidate a lot of the knowledge that I learned in previous systems classes, and it was cool to see how decades ago many of these ideas that were once unappreciated or heavily criticized now form the bedrock of many of the systems that we use today.</p> <p>In addition to the Hall of Fame papers, there were also several relatively recent papers that the course staff thought were conceptually interesting and promising.</p> <p>The following sections will go through each of the modules and the required papers that you will read (refer to the <a href="https://www.cs.cmu.edu/~15712/syllabus.html">course website</a> if you are also interested in the optional papers), and a short description of what the paper is about so you can get a pretty good sense of what is covered. A cool thing to note is that the scope of all the papers will touch almost all the systems classes offered at CMU.</p> <h2 id="part-1-concurrency-ordering-races">Part 1: Concurrency, Ordering, Races</h2> <ul> <li><a href="https://www.cs.cmu.edu/~15712/papers/birrell84.pdf">Implementing Remote Procedure Calls (Birrell’84), SigOps HoF paper</a> - introduced the now-standard design of RPC calls with interfaces and caller/callee stubs for distributed communication.</li> <li><a href="https://www.cs.cmu.edu/~15712/papers/lamport78.pdf">Time, Clocks, and the Ordering of Events in a Distributed System (Lamport’78), SigOps HoF paper</a> - introduced Lamport clocks, the foundation for ordering distributed systems today</li> <li><a href="https://www.cs.cmu.edu/~15712/papers/chandy85.pdf">Distributed Snapshots: Determining Global States of Distributed Systems (Chandy’85), SigOps HoF paper</a> - how to snapshot a consistent global state in a distributed system</li> <li><a href="https://www.cs.cmu.edu/~15712/papers/li19.pdf">Efficient Scalable Thread-Safety-Violation Detection (Li’19), SOSP’19 best paper</a> - using active testing to discover and reproduce concurrency bugs</li> </ul> <h2 id="part-2-file-systems-and-disks">Part 2: File Systems and Disks</h2> <ul> <li><a href="https://www.cs.cmu.edu/~15712/papers/mckusick84.pdf">A Fast File System for UNIX (McKusick’84), SigOps HoF paper</a> - addresses many of the problems of the original Unix filesystem by introducing the Fast File System (FFS), and many of its ideas are now staple in modern filesystems like the Linux <code class="language-plaintext highlighter-rouge">ext*</code> filesystems</li> <li><a href="https://www.cs.cmu.edu/~15712/papers/howard88.pdf">Scale and Performance in a Distributed File System (Howard’88), SigOps HoF paper</a> - introduces the Andrew File System (AFS) that significantly improved on NFS in terms of scalability. AFS was developed at CMU and is still widely used today.</li> <li><a href="https://www.cs.cmu.edu/~15712/papers/rosenblum92.pdf">The Design and Implementation of a Log-Structured File System (Rosenblum’92), SigOps HoF paper</a> - introduced log-structured filesystems that support high write throughput which addresses the problem of disk traffic being dominated by slow writes on traditional filesystems</li> <li><a href="https://www.cs.cmu.edu/~15712/papers/patterson88.pdf">A Case for Redundant Arrays of Inexpensive Disks (RAID) (Patterson’88), SigOps HoF paper</a> - introduced RAID, solved problem of how to get cheap fault tolerance</li> </ul> <h2 id="part-3-transactions-and-databases">Part 3: Transactions and Databases</h2> <ul> <li><a href="https://www.cs.cmu.edu/~15712/papers/kung81.pdf">On Optimistic Methods for Concurrency Control (Kung’81), SigOps HoF paper</a> - introduced optimistic concurrency control, now standard in many database environments with low contention and high throughput requirements</li> <li><a href="https://www.cs.cmu.edu/~15712/papers/franklin97.pdf">Concurrency Control and Recovery (Franklin’97)</a> - survey paper on concurrency control and recovering from crashes in database systems (write-ahead logging, ARIES)</li> </ul> <h2 id="part-4-fault-tolerance">Part 4: Fault Tolerance</h2> <ul> <li><a href="https://www.cs.cmu.edu/~15712/papers/paxos-simple.pdf">Paxos (Lamport’01), SigOps HoF paper</a> - simplified version of his original theatrical <a href="https://www.cs.cmu.edu/~15712/papers/part-time-parliament.pdf">The Part-Time Parliament</a> paper that was mostly ignored, introduced how to get replicated logs among unreliable (but not Byzantine) nodes</li> <li><a href="https://www.cs.cmu.edu/~15712/papers/castro99.pdf">Practical Byzantine Fault Tolerance (Castro’99)</a> - distributed consensus but in the presence of Byzantine faults (i.e a fraction of the nodes can collude and behave maliciously)</li> </ul> <h2 id="part-5-os-kernels-and-virtual-machines">Part 5: OS Kernels and Virtual Machines</h2> <ul> <li><a href="https://www.cs.cmu.edu/~15712/papers/liedtke95.pdf">Microkernels (Liedtke’95), SigOps HoF paper</a> - the first demonstration of an efficient microkernel designed with a very extreme minimality principle, where as much OS functionality is moved outside of the microkernel as possible, including even its memory manager, pagers, device drivers, software TLBs, etc.</li> <li><a href="https://www.cs.cmu.edu/~15712/papers/klein09.pdf">seL4: Formal Verification of an OS Kernel (Klein’09), SigOps HoF paper</a> - first paper to perform a formal, machine-checked verification of a microkernel using the Isabelle/HOL theorem prover</li> <li><a href="https://www.cs.cmu.edu/~15712/papers/waldspurger02.pdf">Memory Resource Management in VMware ESX Server (Waldspurger’02), SigOps HoF paper</a> - introduced many great ideas for hypervisor memory management, like memory ballooning, idle tax, and transparent page sharing that are now commonplace in modern virtual machines</li> <li><a href="https://www.cs.cmu.edu/~15712/papers/clements15.pdf">The Scalable Commutativity Rule: Designing Scalable Software for Multicore Processors (Clements’15), SOSP’13 best paper</a> - addresses the problem of deciding whether there exists a scalable implementation (with respect to number of processors) of a program based on a restricted form of commutativity of the interfaces that it uses called SIM commutativity (<strong>S</strong>tate-dependent, <strong>I</strong>nterface-based, <strong>M</strong>onotonic)</li> <li><a href="https://www.cs.cmu.edu/~15712/papers/baumann09.pdf">The Multikernel: A new OS architecture for scalable multicore systems (Baumann’09), SigOps HoF paper</a> - solves the problem of modern operating systems not being able to take advantage of the current trend of increasing core counts due to the inherent limitations of the shared-memory kernel design, by instead re-framing the OS as a distributed system split among different cores with event-driven execution, replicated state, and a hardware-neutral structure</li> </ul> <h2 id="part-6-big-data-systems">Part 6: Big Data Systems</h2> <ul> <li><a href="https://www.cs.cmu.edu/~15712/papers/decandia07.pdf">Dynamo: Amazon’s Highly Available Key-value Store (DeCandia’07), SigOps HoF paper</a> - the secret behind how Amazon can support very high availability with eventual consistency due to extreme business requirements (i.e users should never fail to add an item to their shopping carts), by incorporating established techniques like consistent hashing, sloppy quorums, gossip-based membership protocols, etc</li> <li><a href="https://www.cs.cmu.edu/~15712/papers/corbett12.pdf">Spanner: Google’s Globally-Distributed Database (Corbett’12), SigOps HoF paper</a> - built using lessons from <a href="https://cloud.google.com/bigtable">Google Bigtable</a>, Spanner powers Google as their globally replicated transactional database system with 5 nines of availability with several novel ideas like TrueTime to quantify uncertainty in wall clock time and distributed transactions</li> <li><a href="https://www.cs.cmu.edu/~15712/papers/qiao21.pdf">Pollux: Co-adaptive Cluster Scheduling for Goodput-Optimized Deep Learning (Qiao’21), OSDI’21 best paper</a> - introduces a new notion of goodput that combines throughput and statistical efficiency to evaluate the performance of schedulers for training deep learning systems, with a practical implementation that optimizes both cluster-wide and per-job parameters called Pollux</li> </ul> <h2 id="part-7-emerging-platforms">Part 7: Emerging Platforms</h2> <ul> <li><a href="https://www.cs.cmu.edu/~15712/papers/kim21.pdf">LineFS: Efficient SmartNIC Offload of a Distributed File System with Pipeline Parallelism (Kim’21), SOSP’21 best paper</a> - optimizing the performance of distributed file systems (DFS) by decomposing DFS operations into pipelined stages and offloading networked stages to a SmartNIC asynchronously</li> </ul> <h1 id="takeaways-from-the-class">Takeaways From The Class</h1> <p>Here are my thoughts on the key takeaways from the class.</p> <h2 id="class-discussion">Class Discussion</h2> <p>As a seminar-based class, one of the most surprising things for me was how fun and valuable the class discussions were. It was especially enlightening to hear the comments of Ph.D. students who are working in systems and other fields in computer science, who often had very different critiques and opinions of the papers than what I had come up with, which often led me to wonder how they got their perspectives and what their background is like. This was particularly true when someone mentioned glaring deficiencies and problems with the paper that I had completely not even thought of.</p> <p>However, one thing that made me sad was that attendance in class started to fall after the halfway point of the semester. This included quite a few of the students who used to give very insightful and interesting responses and so the diversity of perspectives of the discussions as a whole suffered.</p> <p>While attendance is not strictly enforced, actively participating in the discussions and being engaged in lectures is one of the most valuable takeaways from this class, and positively impacts not just you but also your classmates, and so I would strongly encourage anyone interested in the class to attend all the lectures that you can.</p> <h2 id="tribal-knowledge">Tribal Knowledge</h2> <p>Another aspect of the class that I really appreciated was how Phil taught us a lot of the spirit and tribal knowledge of doing CS research during his lively lectures. These were often presented as off-hand remarks while presenting the context or background of a paper, and provided insight into the zeitgeist of the time, the motivations and challenges that the paper authors faced, and what the authors went on to do in the future based on the impact (or lack of impact at that time) of their work.</p> <p>As someone who has not done a long-term research project with a faculty member but am thinking about possibly doing a Ph.D. in the future, all of these were very valuable wisdom which are not things that you can pick up easily yourself from reading past papers or books. In fact, it almost felt as if I had my own advisor at times.</p> <h2 id="witness-the-evolution-of-systems-research">Witness the Evolution of Systems Research</h2> <p>As you read through the papers, you almost feel as if you are being put into the driver’s seat and can see how systems research has matured and evolved over the past few decades. Seminal papers of the past tackled the most general problems, although many of them lacked implementations or proper benchmarks that would surely be grounds to be red-flagged and rejected from any systems conference today. Many of the more recent papers strive to anticipate and build for future changes in the computation landscape, have solid replicable implementations and evaluations, and are a lot more careful about anticipating and providing rebuttals for criticisms.</p> <h2 id="personal-attention-for-projects">Personal Attention for Projects</h2> <p>I also really appreciated the personal attention that Phil and Val gave to us by meeting with us every other week for our course projects. This is especially so if you consider that many advisors already have trouble meeting their own Ph.D. students for an hour a week, whereas in this case the course staff dedicated half an hour every two weeks for every single group in the class (there were around 10), which I thought was some real dedication. I will admit that I did not live up to my end of the bargain by spending as much time on the project as I would have wanted to (compared to when I took 15-410). One could always give excuses for anything so you don’t have to listen to mine, but if I had to reflect on it, it was due to a combination of high workloads from other classes, the fact that this was not the highest priority for the members in our group (my project partners were both quite busy with their own research and I was busy with other classes), and some unexpected obstacles in our project that forced us back to the drawing boards a few times (our project interim report was drastically different from our initial proposal).</p> <h2 id="fantastic-course-staff">Fantastic Course Staff</h2> <p>Phil is a really good lecturer. He is very clear, the class pacing is great, and the lecture slides are polished. He is very approachable and respectful towards students, and puts in great effort to give a good and satisfying answer to every question.</p> <p>Feedback for projects is prompt (there was no feedback for the paper summaries), and the midterms were graded fairly quickly.</p> <p>Overall it is clear that the class is pedagogically mature and has benefited from many rounds of feedback during past iterations. It is rich in content, is accessible and yet challenging to students from a wide range of backgrounds, and will prepare one well for building systems in the future, be it in academia or industry.</p> <h1 id="course-structure">Course Structure</h1> <p>There are three main components to the class: paper summaries, projects, and exams.</p> <h2 id="1-paper-summaries">1. Paper Summaries</h2> <p>Before each lecture, the class is assigned a required reading and an optional reading. A paper summary of the required reading must be submitted before the class, which will discuss both readings.</p> <p>The paper summary will contain 3 things:</p> <ol> <li>The 3 most important things in the paper,</li> <li>1 most glaring deficiency of the paper (even highly celebrated papers have faults!),</li> <li>A conclusion on how you will use lessons from this paper to inform you on how you will build systems in the future.</li> </ol> <p>It took me on average 2-4 hours to read each paper and around 15 minutes for the summary.</p> <p>The lectures for this class are front-loaded, meaning that during the first two-thirds of the semester, you will meet 3 times a week for 80 minutes each, while there will be no lectures at all during the final third of the semester, and so “on average” throughout the semester you will meet twice a week. This is so that students have enough knowledge and content to begin working on their course projects early on in the semester.</p> <p>There will be 3 short breaks in each lecture, where all students will get into breakout groups and share and discuss among themselves one of the prompts for the paper based on their paper summaries. Afterwards, all groups are invited to share what they thought.</p> <p>Reading and writing the paper summaries are the only “homework” you will get in this class.</p> <h2 id="2-course-project">2. Course Project</h2> <p>There is also a semester-long course project with a significant systems component in groups of three. This will begin in earnest after a third of the semester, and all the project groups met with Phil and the TA Val once every two weeks. The deliverables include a project proposal, an interim report, a final presentation, and a final report. The course project will be the largest constituent of your final grade.</p> <h2 id="3-midterms">3. Midterms</h2> <p>Finally, there are two midterm exams, which are taken during class time. The first is taken in the middle of the semester, and the second is taken after all lectures have concluded.</p> <p>Each midterm will cover content from a shortlisted selection of 10 of the required readings. There will be 9 questions on the midterm, which covers 9 of the 10 papers, and you are only required to answer 7 of the problems.</p> <p>The course staff will also provide two past year exams to practice on, though some of the readings may have changed since.</p> <p>It admittedly does seem quite daunting to have to study and be familiar with 10 papers spanning very different topics. I did not have time to actually re-read all 10 papers to prepare for the midterm, and so the way I prepared was to go through all the lecture slides again, re-read the most important sections of the paper, and skim through the rest. Afterward, I attempted the past exams to fill in any gaps that I may have missed. This strategy allowed me to do fairly well on the exam.</p> <h1 id="workload">Workload</h1> <p>The class has a moderate workload for a systems class. Expect to spend 10-12 hours a week on the readings and paper summaries while lectures are ongoing, probably a couple more hours once the projects get into motion midway through the semester, and for it to consume a significant portion of your existence in the last two weeks before the final presentations.</p> <p>It is a far less demanding and stressful class than the legendary <a href="https://www.cs.cmu.edu/~410/">15-410/605 Operating System Design and Implementation</a> class, so don’t let the “advanced” in the course title scare you off from taking this class. After all, most people taking this class are Ph.D. students who have their own research to work on and can’t exactly spend all their time on courses, unlike undergraduates.</p> <h1 id="our-course-project-and-reflections">Our Course Project, and Reflections</h1> <p>Our course project was on the automated optimal scheduling of data in dynamic neural networks over heterogeneous GPUs for inference tasks in a pipeline-parallelism fashion. This means that when a model is too large to fit on a single GPU but instead has to be distributed across multiple GPUs, we aim to solve the problem of finding the optimal way to perform this split in the presence of dynamism in the network. In our case we focused on input dynamism, meaning that the sizes of the inputs can vary, which can result in different execution times in different segments of the network. We built a system called <code class="language-plaintext highlighter-rouge">DynPartition</code>, a reinforcement-learning based scheduler that uses Deep-Q Learning to learn the optimal way of performing this split.</p> <figure> <picture> <img src="/assets/img/posts/adv_os/presentation.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> Giving our final project presentation in the Panther Hollow conference room at CIC </figcaption> </figure> <p>We had some positive empirical results on our benchmarks, but will require additional future work to verify the generality of these results. Overall, I thought it was a great experience working with PhD students and to learn from their working styles and approach to solving problems. It was also really cool to see the breadth and depth of projects presented by the other teams during the final presentation, which was structured like a conference.</p> <h1 id="is-this-class-suitable-for-me">Is This Class Suitable For Me?</h1> <p>I cannot recommend this course enough to anyone who has sufficient background and have an interest in building systems, or systems research.</p> <p>You should be sufficiently prepared for the class if you have taken <a href="https://www.cs.cmu.edu/~410/">15-410 Operating System Design and Implementation</a>, or any other equivalent rigorous operating systems design class in your undergraduate college. Most papers draw heavily on low-level concepts from operating systems and assume that the reader is familiar with them, and therefore familiarity with these ideas is critical to understanding the papers.</p> <p>I don’t feel any of the other classes are as critical, as any new concepts can be picked up relatively easily. For instance, a good grasp of considerations involved in operating systems design means that it’s not too hard to also understand the challenges involved in filesystems or virtual machine design. Having taken other classes would definitely still help to make the papers more approachable though. For instance, the Pollux paper was not very approachable for people who did not have prior exposure to machine learning systems, which led to the course staff deciding not to include that as one of the papers tested for the second midterm.</p> <p>When I took the class, all the students were either Masters or Ph.D. students. Strong undergraduates with sufficient background would also definitely do well in the class.</p> <h1 id="why-i-took-this-class">Why I Took This Class</h1> <p>I had to take a systems class this semester to fulfill my graduation requirements for the MSCS program. I initially did include this class in my shortlist of systems classes to take, but then thought it was just going to be a paper reading class (not that I had been in one of such classes before, but it just did not sound very interesting and felt like something I could do by myself asynchronously after I graduate) and therefore was quite hesitant to take it.</p> <p>As such, during registration week I settled on <a href="https://www.cs.cmu.edu/~418/">15-618 Parallel Computer Architecture and Programming</a>, since it included topics on GPU programming that aligned with my current interests in machine learning. However, I did not feel like the class was sufficiently challenging for me after the first lecture, as it was a bit too slow-paced and simple for my liking as I already had exposure to most of the topics from other system classes that I had taken. I decided to switch to 15-712, and I knew immediately that it was the right class for me after the first lecture.</p> <p>In a sense, this class was a hidden gem and I was really glad that I ended up taking it.</p> <h1 id="acknowledgments">Acknowledgments</h1> <p>I would like to express my gratitude to <a href="https://adbforlife.github.io/">Albert Gao</a> for helping to proofread this article, who took the class with me this semester.</p>]]></content><author><name>fanpu</name></author><category term="courses"/><category term="cmu"/><category term="systems"/><summary type="html"><![CDATA[15-712 Advanced OS was an excellent seminar-based graduate course that took us on a whirlwind tour through many of the most seminal SigOps Hall of Fame papers across several systems domains. It will prepare you to be a great systems designer and researcher. In this post, I will share my experience in the class, the course structure and content, what I thought were the biggest takeaways, and who this class might be suitable for.]]></summary></entry><entry><title type="html">Score-Based Diffusion Models</title><link href="https://fanpu.io/blog/2023/score-based-diffusion-models/" rel="alternate" type="text/html" title="Score-Based Diffusion Models"/><published>2023-06-07T00:00:00+00:00</published><updated>2023-06-07T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/score-based-diffusion-models</id><content type="html" xml:base="https://fanpu.io/blog/2023/score-based-diffusion-models/"><![CDATA[<p>\(\newcommand{\E}{\mathbb{E}} \newcommand{\bone}{\boldsymbol{1}} \newcommand{\bbeta}{\boldsymbol{\beta}} \newcommand{\bdelta}{\boldsymbol{\delta}} \newcommand{\bepsilon}{\boldsymbol{\epsilon}} \newcommand{\blambda}{\boldsymbol{\lambda}} \newcommand{\bomega}{\boldsymbol{\omega}} \newcommand{\bpi}{\boldsymbol{\pi}} \newcommand{\bphi}{\boldsymbol{\phi}} \newcommand{\bvphi}{\boldsymbol{\varphi}} \newcommand{\bpsi}{\boldsymbol{\psi}} \newcommand{\bsigma}{\boldsymbol{\sigma}} \newcommand{\btheta}{\boldsymbol{\theta}} \newcommand{\btau}{\boldsymbol{\tau}} \newcommand{\ba}{\boldsymbol{a}} \newcommand{\bb}{\boldsymbol{b}} \newcommand{\bc}{\boldsymbol{c}} \newcommand{\bd}{\boldsymbol{d}} \newcommand{\be}{\boldsymbol{e}} \newcommand{\boldf}{\boldsymbol{f}} \newcommand{\bg}{\boldsymbol{g}} \newcommand{\bh}{\boldsymbol{h}} \newcommand{\bi}{\boldsymbol{i}} \newcommand{\bj}{\boldsymbol{j}} \newcommand{\bk}{\boldsymbol{k}} \newcommand{\bell}{\boldsymbol{\ell}} \newcommand{\bm}{\boldsymbol{m}} \newcommand{\bn}{\boldsymbol{n}} \newcommand{\bo}{\boldsymbol{o}} \newcommand{\bp}{\boldsymbol{p}} \newcommand{\bq}{\boldsymbol{q}} \newcommand{\br}{\boldsymbol{r}} \newcommand{\bs}{\boldsymbol{s}} \newcommand{\bt}{\boldsymbol{t}} \newcommand{\bu}{\boldsymbol{u}} \newcommand{\bv}{\boldsymbol{v}} \newcommand{\bw}{\boldsymbol{w}} \newcommand{\bx}{\boldsymbol{x}} \newcommand{\by}{\boldsymbol{y}} \newcommand{\bz}{\boldsymbol{z}} \newcommand{\bA}{\boldsymbol{A}} \newcommand{\bB}{\boldsymbol{B}} \newcommand{\bC}{\boldsymbol{C}} \newcommand{\bD}{\boldsymbol{D}} \newcommand{\bE}{\boldsymbol{E}} \newcommand{\bF}{\boldsymbol{F}} \newcommand{\bG}{\boldsymbol{G}} \newcommand{\bH}{\boldsymbol{H}} \newcommand{\bI}{\boldsymbol{I}} \newcommand{\bJ}{\boldsymbol{J}} \newcommand{\bK}{\boldsymbol{K}} \newcommand{\bL}{\boldsymbol{L}} \newcommand{\bM}{\boldsymbol{M}} \newcommand{\bN}{\boldsymbol{N}} \newcommand{\bP}{\boldsymbol{P}} \newcommand{\bQ}{\boldsymbol{Q}} \newcommand{\bR}{\boldsymbol{R}} \newcommand{\bS}{\boldsymbol{S}} \newcommand{\bT}{\boldsymbol{T}} \newcommand{\bU}{\boldsymbol{U}} \newcommand{\bV}{\boldsymbol{V}} \newcommand{\bW}{\boldsymbol{W}} \newcommand{\bX}{\boldsymbol{X}} \newcommand{\bY}{\boldsymbol{Y}} \newcommand{\bZ}{\boldsymbol{Z}} \newcommand{\boldf}{\boldsymbol{f}} \newcommand{\bpi}{\boldsymbol{\pi}} \newcommand{\btheta}{\boldsymbol{\theta}} \DeclareMathOperator{\tr}{tr} \newcommand{\pdata}{p_{\text{data}}(\bx)} \newcommand{\st}{\mathbf{s}_\mathbf{\theta}} \newcommand{\xt}{\tilde{\bx}} \newcommand{\stx}{\mathbf{s}_\mathbf{\theta}(\bx)} \newcommand{\sdx}{\mathbf{s}_\text{data}(\bx)} \newcommand{\stxt}{\mathbf{s}_\mathbf{\theta}(\xt, \sigma)} \newcommand{\pv}{p_{\bv}} \newcommand{\score}{\nabla_\bx \log \pdata} \newcommand{\bov}{\bar{\beta}}\) <em>Joint work with <a href="https://www.linkedin.com/in/owen-wang/">Owen Wang</a>.</em></p> <p>There has recently been a flurry of work in score-based diffusion models as part of the broader area of generative models. This is due to the recent success of such score-based methods, which has achieved results comparable to the state-of-the-art of generative adversarial networks (GANs).</p> <p>Past techniques in generative modeling have either relied on the approximation of the partition function of the probability density, or the combination of an implicit network representation of the probability density and adversarial training. The former suffers from having to either constrain the model to make the partition function tractable, or otherwise relies on approximations with surrogate losses that may be inaccurate, and the latter suffers from training instability and mode collapse.</p> <p>Score-based diffusion models try to address the cons of both approaches, and instead, use score-matching to learn a model of the gradient of the log of the probability density function. This allows it to avoid computing the partition function completely.</p> <p>One of the first such approaches that rely on using score-matching to perform generative modeling does so by generating new samples via Langevin dynamics <a href="https://arxiv.org/abs/1907.05600">(Song &amp; Ermon, 2019)</a>. A key observation is that naively applying score-matching is that the model of score function will be inaccurate in areas of low density with respect to the data distribution, which results in improper Langevin dynamics in low-density areas. The solution that was proposed is the injection of noise into the data, which provides additional training signal and increases the dimensionality of the data.</p> <p>The next major step introduced in <a href="https://arxiv.org/abs/2011.13456">(Song et al., 2021)</a> is to perturb the data using a diffusion process which is a form of a stochastic differential equation (SDEs). The SDE is then reversed using annealed Langevin dynamics in order to recover the generative process, where the reversal process makes use of score matching.</p> <p>Other recent refinements that have been proposed include re-casting the objective as a Schrödinger bridge problem, which is an entropy-regularized optimal transport problem. The advantage of this approach is that it allows for fewer diffusion steps to be taken during the generative process.</p> <h1 id="survey-of-results">Survey of Results</h1> <p>We will be primarily focusing on the paper <a href="https://arxiv.org/abs/1907.05600">Generative Modeling by Estimating Gradients of the Data Distribution (Song &amp; Ermon, 2019)</a>.</p> <p>In this section, we provide the necessary background, provide derivations for important results, and explain the key ideas of score matching for diffusion models as proposed in the papers.</p> <h2 id="motivation-for-score-matching">Motivation for Score Matching</h2> <h3 id="limitations-of-likelihood-based-approaches">Limitations of Likelihood-Based Approaches</h3> <p>Score matching is motivated by the limitations of likelihood-based methods. In likelihood-based methods, we use a parameterized model \(f_\theta(\bx) \in \mathbb{R}\) and attempt it to recover the parameters \(\theta\) that best explains the observed data. For instance, in energy-based models, the probability mass function \(p_\theta(\bx)\) would be given as \begin{align} p_\theta(\bx) = \frac{\exp(-f_\theta(\bx))}{Z_\theta}, \end{align} where \(Z_\theta\) is the normalizing constant that causes the distribution to integrate to 1, i.e \begin{align} Z_\theta = \int \exp(-f_\theta(\bx)) \, d \bx. \end{align} The goal then is to maximize the log likelihood of the observed data \(\{\bx_i\}_i^N\), given by \begin{align} \max_\theta \sum_{i=1}^N \log p_\theta (\bx_i). \end{align}</p> <p>It is often computationally intractable to compute the partition function \(Z_\theta\) unless there are restrictions on what the model can be, since there are usually at least an exponential number of possible configurations. Examples of models where the partition function can be efficiently computed include causal convolutions in autoregressive models, and invertible networks in normalizing flow models However, such architecture restrictions are very undesirable as they limit the expressiveness of the models.</p> <p>A likelihood-based approach that tries to avoid computing the partition function is variational inference. In variational inference, we use the Evidence Lower Bound (ELBO) as a surrogate objective, where the approximation error is the smallest Kullback-Leibler divergence between the true distribution and a distribution that can be parameterized by our model.</p> <h3 id="limitations-of-adversarial-based-approaches">Limitations of Adversarial-Based Approaches</h3> <p>Adversarial-based approaches, like generative adversarial networks (GANs), have been shown to suffer from both instability in training and mode collapse.</p> <p>Training GANs can be viewed as finding a Nash equilibrium for a two-player non-cooperative game between the discriminator and the generator. Finding a Nash equilibrium is PPAD-complete which is computationally intractable, and therefore methods like gradient-based optimization techniques are used instead. However, the highly non-convex and high-dimensional optimization landscape means that small perturbations in the parameters of either player can change the cost function of the other player, which results in non-convergence.</p> <p>Another problem with training GANs is that when either the generator or discriminator becomes significantly better than the other, then the learning signal for the other player becomes very weak. For generators, this is when the discriminator is always able to tell it apart. For discriminators, this is when the generator performs so well it can hardly do better than random guessing.</p> <p>Finally, a common failure mode of GANs is mode collapse, where the generator only learns to produce a set of very similar outputs from a single mode instead of from all the modes. This is due to the non-convexity of the optimization landscape.</p> <h2 id="score-matching">Score Matching</h2> <p>Score matching is a non-likelihood-based method to perform sampling on an unknown data distribution, and seeks to address many of the limitations of likelihood-based methods and adversarial methods. This is achieved by learning the score of the probability density function, formally defined below:</p> <div class="definition"> <div class="theorem-title">Definition (Score Function) </div> <div class="theorem-contents"> The score function of a distribution \( \pdata \) is given by \begin{align*} f(\bx) = \nabla_\bx \log \pdata. \end{align*} </div> </div> <p>In practice, we try to learn the score function using a neural network \(\stx\) parameterized by \(\theta\).</p> <p>The objective of score matching is to minimize the Fisher Divergence between the score function and the score network:</p> \[\begin{align} \label{eq:score-matching-target-fisher-div} \argmin_\theta \frac{1}{2} \mathbb{E}_{\pdata} \left[ \| \stx - \nabla_\bx \log \pdata \|_2^2 \right]. \end{align}\] <p>However, the main problem here is that we do not know \(\nabla_\bx \log \pdata\), since it depends on knowing what \(\pdata\) is.</p> <p><a href="http://jmlr.org/papers/v6/hyvarinen05a.html">(Hyvärinen, 2005)</a> showed that Equation \ref{eq:score-matching-target-fisher-div} is equivalent to Equation \ref{eq:score-matching-target} below:</p> \[\begin{align} \label{eq:score-matching-target} \argmin_\theta \frac{1}{2} \mathbb{E}_{\pdata} \left[ \tr \left( \nabla_\bx \stx \right) + \frac{1}{2} \| \stx \|_2^2 \right]. \end{align}\] <p>We can now compute this using Monte Carlo methods by sampling from \(\pdata\), since it only depends on knowing \(\stx\).</p> <h2 id="sliced-score-matching">Sliced Score Matching</h2> <p>It is computationally difficult to compute the trace term \(\tr \left( \nabla_\bx \stx \right)\) in Equation \ref{eq:score-matching-target} when \(\bx\) is high-dimensional. This motivates another alternative cheaper approach for score matching, called sliced score matching <a href="http://arxiv.org/abs/1905.07088">(Song et al., 2019)</a>.</p> <p>In sliced score matching, we sample random vectors from some distribution \(\pv\) (such as the multivariate standard Gaussian) in order to optimize an analog of the Fisher Divergence:</p> \[\begin{align} L(\btheta, \pv) = \frac{1}{2} \mathbb{E}_{\pv} \mathbb{E}_{\pdata} \left[ (\bv^T \stx - \bv^T \sdx)^2 \right] \end{align}\] <p>We observe that</p> \[\begin{align} L(\btheta; \pv) &amp;= \frac{1}{2} \mathbb{E}_{\pv} \mathbb{E}_{\pdata} \left[ (\bv^T \stx - \bv^T \sdx)^2 \right]\\ &amp;=\frac{1}{2} \mathbb{E}_{\pv} \mathbb{E}_{\pdata} \left[ (\bv^T \stx )^2 + (\bv^T \sdx)^2 - 2(\bv^T \stx )(\bv^T \sdx) \right]\\ &amp;= \mathbb{E}_{\pv} \mathbb{E}_{\pdata} \left[ \frac{1}{2}(\bv^T \stx )^2 - (\bv^T \stx )(\bv^T \sdx) \right] + C\\ \end{align}\] <p>where the \(\sdx\) term is absorbed into \(C\) as it doesn’t depend on \(\theta\). Now note</p> \[\begin{align} &amp; -\mathbb{E}_{\pv} \mathbb{E}_{\pdata}\left[(\bv^T \stx )(\bv^T \sdx) \right] \\ =&amp; -\mathbb{E}_{\pv} \int \left[(\bv^T \stx )(\bv^T \sdx) \pdata d\bx\right]\\ =&amp; -\mathbb{E}_{\pv} \left[\int(\bv^T \stx )(\bv^T\nabla_{\bx}\log \pdata)\pdata d\bx\right] \\ =&amp; -\mathbb{E}_{\pv} \left[\int(\bv^T \stx )(\bv^T\nabla_{\bx}\pdata)d\bx\right] \\ =&amp; -\mathbb{E}_{\pv} \left[\int(\bv^T \stx )(\bv^T\nabla_{\bx}\pdata)d\bx\right] \\ =&amp; -\mathbb{E}_{\pv} \left[\sum_{i}\int(\bv^T \stx )(v_i\frac{\partial \pdata}{\partial x_i})d\bx\right] \\ =&amp; \mathbb{E}_{\pv} \left[\int \bv^T\stx\bv \cdot \pdata d\bx\right] \\ =&amp; \mathbb{E}_{\pv}\mathbb{E}_{\pdata}\left[\bv^T\stx\bv \right] \end{align}\] <p>where line 16 is obtained by applying multivariate integration by parts. This finally yields the equivalent objective:</p> \[\begin{align} J(\btheta; \pv) &amp;= \mathbb{E}_{\pv} \mathbb{E}_{\pdata} \left[ \bv^T \nabla_\bx \stx \bv + \frac{1}{2} \| \stx \|_2^2 \right] \end{align}\] <p>which no longer has a dependence on the unknown \(\nabla_{bx}\sdx\). This leads to the unbiased estimator:</p> \[\begin{align} \hat J_{N,M}(\btheta; \pv) &amp;=\frac{1}{N}\frac{1}{M}\sum_{i= 1}^N\sum_{j=1}^M \left[\bv_{ij}^T\nabla_{\bx}\mathbf{s}_\mathbf{\btheta}(\bx_i)\bv_{ij} + \frac{1}{2} \|\mathbf{s}_\mathbf{\btheta}(\bx_i)\|_2^2\right] \end{align}\] <p>where for each data point \(\bx_i\) we draw \(M\) projection vectors from \(\pv\).</p> <p><a href="http://arxiv.org/abs/1905.07088">(Song et al., 2019)</a> showed that under some regularity conditions, sliced score matching is an asymptotically consistent estimator:</p> \[\begin{align} \hat \btheta_{N,M} \overset{p}{\to} \btheta^* \text { as } \mathbb{N} \to \infty \end{align}\] <p>where</p> \[\begin{align} \btheta^* &amp;= \underset{\btheta}{\text{argmin }} J(\btheta; \pv), \\ \hat \btheta_{N,M} &amp;= \underset{\btheta}{\text{argmin }} \hat J_{N,M}(\btheta; \pv). \end{align}\] <p>Sliced score matching is computationally more efficient, since it now only involves Hessian-vector products, and continues to work well in high dimensions.</p> <h2 id="sampling-with-langevin-dynamics">Sampling with Langevin Dynamics</h2> <p>Once we have trained a score network, we can sample from the data distribution via Langevin dynamics. Langevin dynamics is a Markov Chain Monte Carlo method of sampling from a stationary distribution, where we can efficiently take gradients with respect to the probability of our samples \(\bx\). We satisfy this criteria since we have the trained score network.</p> <p>In Langevin dynamics, we start from some initial point \(\bx_0 \sim \bpi(\bx)\) sampled from some prior distribution \(\bpi\), and then iteratively obtain updated points based on the following recurrence: \begin{align} \xt_t = \xt_{t-1} + \frac{\epsilon}{2} \nabla_\bx \log p(\xt_{t-1}) + \sqrt{\epsilon} \bz_t, \end{align} where \(\bz_t \sim \mathcal{N}(0, I)\). The addition of the Gaussian noise is required, or otherwise the process simply converges to the nearest mode instead of converging to a stationary distribution.</p> <p>It can be shown that as \(\epsilon \to 0\) and \(T \to \infty\), we have that the distribution of the process \(\xt_T\) converges to \(\pdata\) <a href="https://dl.acm.org/doi/10.5555/3104482.3104568">(Welling &amp; Teh, 2011)</a>.</p> <h2 id="challenges-of-langevin-dynamics">Challenges of Langevin Dynamics</h2> <p>Langevin dynamics does not perform well with multi-modal distributions with poor conductance, since it will tend to stay in a single mode, which causes long mixing times. This is particularly a problem when the modes have disjoint supports, since there is very weak gradient information in the region where there is no support.</p> <h2 id="challenges-of-score-matching-for-generative-modeling">Challenges of Score Matching for Generative Modeling</h2> <h3 id="the-manifold-hypothesis">The Manifold Hypothesis</h3> <p>The manifold hypothesis postulates that real-world data often lies in a low-dimensional manifold embedded in a high-dimensional space. This has been empirically observed in many datasets.</p> <p>This poses problems for score matching. The first problem that the manifold hypothesis poses is that the score \(\score\) becomes undefined if \(\bx\) actually just lies in a low-dimensional manifold. The second problem is that the estimator in Equation \ref{eq:score-matching-target} is only consistent when the support of \(\pdata\) is that of the whole space.</p> <p>In order to increase the dimension of the data to match that of the ambient space, <a href="http://jmlr.org/papers/v6/hyvarinen05a.html">(Hyvärinen, 2005)</a> proposed injecting small amounts of Gaussian noise into the data, such that now the data distribution has full support. As long as the perturbation is sufficiently small (\(\mathcal{N}(0, 0.0001)\) was used in their paper), it is almost indistinguishable to humans.</p> <h3 id="low-data-density-regions">Low Data Density Regions</h3> <p>The other problem with score matching is that it may not be able to learn the score function in areas of low data density. This is due to the lack of samples drawn from these regions, resulting in the Monte Carlo estimation to have high variance.</p> <h2 id="noise-conditional-score-networks-ncsn">Noise Conditional Score Networks (NCSN)</h2> <p>The challenges mentioned in the previous sections are addressed by Noise Conditional Score Networks (NCSN).</p> <p>In NCSN, we define a geometric sequence of \(L\) noise levels \({\left\{ \sigma_i \right\}}_{i=1}^L\), with the property that \(\frac{\sigma_1}{\sigma_2} = \frac{\sigma_{L-1}}{\sigma_L} &gt; 1\). Each of these noise levels correspond to Gaussian noise that will be added to perturb the data distribution, i.e \(q_{\sigma_i} \sim \pdata + \mathcal{N}(0, \sigma_i)\).</p> <p>We augment the score network to also take the noise level \(\sigma\) into account, which is called the NCSN \(\stxt\). The goal of NCSN is then to estimate the score conditioned on the noise level. Once we have a trained NCSN, we use a similar apporach as simulated annealing in Langevin sampling, where we begin with a large noise level in order to cross the different modes easily, before gradually annealing down the noise to achieve convergence.</p> <p>The denoising score matching objective for each noise level \(\sigma_i\) is given as</p> \[\begin{align} \ell(\theta; \sigma) \triangleq \frac{1}{2} \mathbb{E}_{\pdata} \mathbb{E}_{\xt \sim \mathcal{N}(\bx, \sigma^2 I)} \left[ \left\| \stxt + \frac{\xt - \bx}{\sigma^2} \right\|_2^2 \right], \end{align}\] <p>and the unified objective for denoising across all levels is given as</p> \[\begin{align} \mathcal{L}\left(\theta; \left\{ \sigma_i\right\}_{i=1}^L \right) \triangleq \frac{1}{L} \sum_{i=1}^L \lambda(\sigma_i) \ell(\theta; \sigma_i). \end{align}\] <h2 id="score-based-generative-modeling-through-stochastic-differential-equations-song-et-al-2021">Score-Based Generative Modeling through Stochastic Differential Equations <a href="https://arxiv.org/abs/2011.13456">(Song et al., 2021)</a></h2> <p>We can extend the idea of having a finite number of noise scales to having an infinite continuous number of such noise scales by modeling the process as a diffusion process, which can be formalized as a stochastic differential equation (SDE). Such an SDE is given in the following form:</p> \[\begin{align} d\bx = \boldf(\bx, t) \, dt + g(t) \, d\bw. \end{align}\] <p>Here, \(\boldf\) represents the drift coefficient, which models the deterministic part of the SDE, and determines the rate at which the process \(d\bx\) is expected to change over time on average. \(g(t)\) is called the diffusion coefficient, which represents the random part of the SDE, and determines the magnitude of the noising process over time. Finally, \(\bw\) is Brownian motion. Thus \(g(t) \, d \bw\) represents the noising process.</p> <p>We want our diffusion process to be such that \(\bx(0) \sim p_0\) is the original data distribution, and \(\bx(T) \sim p_T\) is the Gaussian noise distribution that is independent of \(p_0\). Then since every SDE has a corresponding reverse SDE, we can start from the final noise distribution and run the reverse-time SDE in order to recover a sample from \(p_0\), given by the following process:</p> \[\begin{align} d \bx = [\boldf (\bx, t) - g(t)^2 \nabla_{\bx} \log_{p_t} (\bx) ] \, dt + g(t) \,d \overline{w}, \end{align}\] <p>where \(\overline{w}\) is Brownian motion that flows backwards in time from \(T\) to \(0\), and \(dt\) is an infinitesimal negative timestep.</p> <p>The objective function for score matching for the SDE is then given by</p> \[\begin{align} \argmin_{\theta} \mathbb{E}_t \left[ \lambda (t) \mathbb{E}_{\bx(0)} \mathbb{E}_{\bx (t) \mid \bx(0)} \left[ \| \bs_\theta (\bx(t), t) - \nabla_{\bx(t)} \log p_{0t}(\bx (t) \mid \bx(0)) \|_2^2 \right] \right]. \end{align}\] <h3 id="score-based-generative-modeling-techniques">Score-based Generative Modeling Techniques</h3> <p><a href="https://arxiv.org/abs/2011.13456">(Song et al., 2021)</a> covers two score-based generative models that uses SDEs to perform generative modeling. The first is called score matching with Langevin dynamics (SMLD), which performs score estimation at different noise scales and then performs sampling using Langevin dynamics with decreasing noise scales. The second is denoising diffusion probabilistic modeling (DDPM)</p> <p><a href="https://arxiv.org/abs/2006.11239">(Ho et al., 2020)</a>, which uses a parameterized Markov chain that is trained with a re-weighted variant of the evidence lower bound (ELBO), which is an instance of variational inference. The Markov chain is trained to reverse the noise diffusion process, which then allows sampling from the chain using standard Markov Chain Monte Carlo techniques.</p> <p><a href="https://arxiv.org/abs/2011.13456">(Song et al., 2021)</a> shows that SMLD and DDPM actually corresponds to discretizations of the Variance Exploding (VE) and Variance Preserving (VP) SDEs, which is the focus of the next two section. We believe expanding on this will be illuminating as it highlights the connections between SDEs and the discretized approaches that are used in practice.</p> <h3 id="smld-as-discretization-of-variance-exploding-ve-sde">SMLD As Discretization of Variance Exploding (VE) SDE</h3> <p>Recall that we use a geometric sequence of \(L\) noise levels \({\left\{ \sigma_i \right\}}_{i=1}^L\). that is added to the data distribution</p> <p>We can recursively define the distribution for each noise level \(i\) by incrementally adding noise:</p> \[\begin{align} \bx_i = \bx_{i-1} + \sqrt{\sigma_i^2 - \sigma_{i-1}^2} \bz_{i-1}, \qquad \qquad i = 1, \dots, L, \end{align}\] <p>where \(\bz_{i-1} \sim \mathcal{N}(\mathbf{0}, \bI)\), and \(\sigma_0 = 0\) so \(\bx_0 \sim \pdata\).</p> <p>If we view the noise levels as gradually changing in time, then the continuous time limit of the process is given by the following SDE: \begin{align} \bx(t + \Delta t) = \bx(t) + \sqrt{\sigma^2 (t + \Delta t ) - \sigma^2 (t)} \bz(t) \approx \bx(t) + \sqrt{\frac{d [\sigma^2 (t)]}{dt} \Delta t } \bz (t), \end{align} where the approximation holds when \(\Delta t \ll 1\). If we take \(\Delta t \to 0\), we recover the VE SDE: \begin{align} d \bx = \sqrt{\frac{d [\sigma^2 (t)]}{dt} } d \bw, \end{align} which causes the variance of \(d \bx(t)\) to go to infinity as \(t \to \infty\) due to its geometric growth, hence its name.</p> <h3 id="ddpm-as-discretization-of-variance-preserving-vp-sde">DDPM As Discretization of Variance Preserving (VP) SDE</h3> <p>Similarly, the Markov chain of the perturbation kernel of DDPM is given by \begin{align} \bx_i = \sqrt{1 - \beta_i} \bx_{i-1} + \sqrt{\beta_i} \bz_{i-1}, \qquad i = 1, \cdots, L, \end{align} where \(\left\{ \beta_i \right\}_{i=1}^L\) are the noise scales, and if we take \(L \to \infty\) with scaled noise scales \(\overline{\beta_i} = N \beta_i\), we get \begin{align} \bx_i = \sqrt{1 - \frac{\bov_i}{N} } \bx_{i-1} + \sqrt{ \frac{\bov_i}{N} } \bz_{i-1}, \qquad i = 1, \cdots, L. \end{align} Now taking limits with \(L \to \infty\), we get \begin{align} \bx(t + \Delta t) \approx \bx(t) - \frac{1}{2} \beta(t) \Delta t \bx(t) + \sqrt{\beta(t) \Delta t} \bz(t), \end{align} where the approximation comes from the second degree Taylor expansion of \(\sqrt{1 - \beta(t + \Delta t) \Delta t}\). Then taking the limit of \(\Delta t \to 0\), we obtain the VP SDE \begin{align} d \bx = - \frac{1}{2} \beta(t) \bx dt + \sqrt{\beta(t)} d \bw. \end{align} This process thus has bounded variance since \(\beta_i\) is bounded.</p> <h1 id="experiments">Experiments</h1> <p>We conduct the following preliminary series of experiments, based on released work by <a href="https://arxiv.org/abs/1907.05600">(Song &amp; Ermon, 2019)</a>.</p> <h2 id="investigating-the-manifold-hypothesis">Investigating the manifold hypothesis</h2> <figure id="fig-1"> <picture> <img src="/assets/img/posts/score-based-diffusion-models/sample_dist.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 1.</i> Comparison between true data density and sampling </figcaption> </figure> <p>In this experiment, we have plotted the true data density of a toy distribution along with samples drawn in three ways. The i.i.d samples are drawn directly from the underlying distribution and we can see that more samples are drawn in the area of high data density. However, applying Langevin dynamics without annealing, we see that there is an almost equal number of points in the top left and bottom right corners. This is evidence that the sampling method doesn’t conform to the true distribution. Finally, by injecting and decreasing the amount of noise through the annealing process, we can recover a representative sample of the distribution.</p> <h2 id="importance-of-annealing-when-sampling-via-langevin-dynamics">Importance of annealing when sampling via Langevin Dynamics</h2> <p>To better visualize the effects of annealing when sampling via Langevin Dynamics, we generated images from a model trained on the CelebA dataset. We first tried applying Langevin Dynamics with a fixed noise and then used annealing to gradually decrease the noise.</p> <figure id="fig-2"> <picture> <img src="/assets/img/posts/score-based-diffusion-models/annealing_ablation.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 2.</i> Langevin Dynamics with no annealing (top) and annealing (bottom) </figcaption> </figure> <p>Figure 2 shows that the results with annealing are significantly clearer and more varied, matching the performance of GANs in 2019.</p> <figure id="fig-3"> <picture> <img src="/assets/img/posts/score-based-diffusion-models/left_right.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 3.</i> Closer comparison of no annealing (left) and annealing (right) </figcaption> </figure> <p>We notice that the image generated without annealing manages to produce the structure of a human face but fails to capture finer details such as the hair, and the surrounding backdrop. There is also little variation in color between different samples. This is in agreement with our theory that without annealing, Langevin dynamics cannot properly explore regions of lower data density.</p> <h2 id="effect-of-noise-parameters-for-annealed-langevin-dynamics">Effect of noise parameters for annealed Langevin Dynamics</h2> <p>We also investigated the effect of changing the lowest noise standard deviation \(\sigma\) while keeping the number of different noises injected fixed at \(10\). The 10 noise values are determined by an interpolation in log scale.</p> <figure id="fig-4"> <picture> <img src="/assets/img/posts/score-based-diffusion-models/vary_sigma.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 4.</i> Left to right: \( \sigma_{\text{end}} = \{0.1, 0.01, 0.001\} \) </figcaption> </figure> <p>Our experiment shows that the effect of starting, ending, and the interval between noise values has a significant effect on the convergence of annealed Langevin sampling.</p> <h1 id="discussion-and-future-work">Discussion and Future Work</h1> <p>Having completed a survey of score-based diffusion models, and having run some experiments on them, we now turn our attention to discussing the pros and cons of this approach.</p> <p>As mentioned previously in this paper, the main draw of score-based diffusion models is that it has shown to be capable of generating impressive high-quality samples that is on-par with the state-of-the-art with GANs. We hence focus on its limitations and how they might be overcome, drawing from work in <a href="https://arxiv.org/abs/2209.02646">(Cao et al., 2022)</a>.</p> <h2 id="computation-cost">Computation Cost</h2> <p>A common refrain of score-based diffusion model is the high computational complexity in both training and sampling. This is because it requires thousands of small diffusion steps in order to ensure that the forward and reverse SDEs hold in their approximations <a href="https://arxiv.org/abs/2202.09671">(Zheng et al., 2022)</a>. If the diffusion steps are too large, then the Gaussian noise assumption may not hold, resulting in poor score estimates. This makes it significantly more expensive than other generative methods like GANs and VAEs. To this end, there are some directions being explored to improve its computation cost.</p> <p>The first technique seeks to reduce the number of sampling steps required by a method known as knowledge distillation <a href="http://arxiv.org/abs/1710.07535">(Lopes et al., 2017)</a>. In knowledge distillation, knowledge is transferred from a larger and more complex model (called the teacher), to one that is smaller and simpler (called the student). This technique has found success in other domains such as image classification, and has also been shown to result in improvements in diffusion models <a href="https://arxiv.org/abs/2202.00512">(Salimans &amp; Ho, 2022)</a>. It would be interesting to see how far we can take this optimization.</p> <p>Another technique known as truncated diffusion probabilistic modeling (TDPM) <a href="https://arxiv.org/abs/2202.09671">(Zheng et al., 2022)</a>. In this approach, instead of considering the diffusion process until it becomes pure noise, the process is stopped once it reaches a hidden noisy-data distribution that can be learnt by an auto-encoder by adversarial training. Then in order to produce samples, a sample is first drawn from the learnt noisy-data distribution, before being passed through the reverse-SDE diffusion steps.</p> <p>It also suffers from poor explainability and interpretability, but this is a common problem across other generative models.</p> <p><a href="https://arxiv.org/abs/2011.13456">(Song et al., 2021)</a> also notes that it is currently difficult to tune the myriad of hyperparameters introduced by the choice of noise levels and specific samplers chosen, and new methods to automatically select and tune these hyperparameters would make score-based diffusion models more easily deployable in practice.</p> <h2 id="modality-diversity">Modality Diversity</h2> <p>Diffusion models have mostly only seen applications for generating image data, and its potential for generating other data modalities has not been as thoroughly investigated. <a href="https://arxiv.org/abs/2107.03006">(Austin et al., 2021)</a> introduces Discrete Denoising Diffusion Probabilistic Models (D3PMs), which develops a diffusion process for corrupting text data into noise. It would be interesting to see how well diffusion models can be stretched to perform compared to state-of-the-art transformer models in text generation.</p> <h2 id="dimensionality-reduction">Dimensionality Reduction</h2> <p>Dimensionality reduction is another technique that can be used to speed up training and sampling speeds of diffusion models. Diffusion models are typically trained directly in data space. <a href="https://arxiv.org/abs/2106.05931">(Vahdat et al., 2021)</a> instead proposes for them to be trained in latent space, which results in dimensionality reduction in the representation learnt, and also potentially increases the expressiveness of the framework. In a similar vein, <a href="https://arxiv.org/abs/2211.16032">(Zhang et al., 2022)</a> argues that due to redundancy in spatial data, it is not necessary to learn in data space, and instead proposes a dimensionality-varying diffusion process (DVDP), where the dimensionality of the signal is dynamically adjusted during the both the diffusion and denoising process.</p> <h1 id="conclusion">Conclusion</h1> <p>We showed that score matching presents a promising new direction for generative models, which avoids many of the limitations of other approaches such as training instability and mode collapse in GANs, and poor approximation guarantees in variational inference. While score matching has several flaws, such as suffering from the manifold hypothesis and requiring an expensive Langevin dynamics process in order to draw samples, successive work has done well in addressing these limitations to make score matching on diffusion models a viable contender to displace GANs as the state-of-the-art for generative modeling.</p> <p>Our experiments in this blog post help to provide empirical context to the theoretical results we have derived. Most notably, we have shown how annealing is an essential part of sampling via Langevin dynamics.</p> <p>Finally, we discuss some future directions that can help to improve the viability of using score-based diffusion models, which includes improving its computational cost in both training and sampling and increasing the diversity of applicable modalities.</p> <h1 id="citation">Citation</h1> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{zeng2023diffusion,
  title   = {Score-Based Diffusion Models},
  author  = {Fan Pu Zeng and Owen Wang},
  journal = {fanpu.io},
  year    = {2023},
  month   = {Jun},
  url     = {https://fanpu.io/blog/2023/score-based-diffusion-models/}
}
</code></pre></div></div> <h1 id="references">References</h1> <ul> <li>Austin, J., Johnson, D. D., Ho, J., Tarlow, D., and van den Berg, R. <a href="https://arxiv.org/abs/2107.03006">Structured denoising diffusion models in discrete state-spaces.</a> CoRR, abs/2107.03006, 2021.</li> <li>Cao, H., Tan, C., Gao, Z., Chen, G., Heng, P.-A., and Li, S. Z. <a href="https://arxiv.org/abs/2209.02646">A survey on generative diffusion model</a>, 2022.</li> <li>Ho, J., Jain, A., and Abbeel, P. <a href="https://arxiv.org/abs/2006.11239">Denoising diffusion probabilistic models</a>. CoRR, abs/2006.11239, 2020. URL https://arxiv.org/abs/2006.11239.</li> <li>Hyva ̈rinen, A. <a href="http://jmlr.org/papers/v6/hyvarinen05a.html">Estimation of non-normalized statistical models by score matching</a>. Journal of Machine Learning Research, 6(24):695–709, 2005.</li> <li>Lopes, R. G., Fenu, S., and Starner, T. <a href="http://arxiv.org/abs/1710.07535">Data-free knowledge distillation for deep neural networks</a>. CoRR, abs/1710.07535, 2017.</li> <li>Salimans, T. and Ho, J. <a href="https://arxiv.org/abs/2202.00512">Progressive distillation for fast sampling of diffusion models</a>. CoRR, abs/2202.00512, 2022.</li> <li>Song, Y. and Ermon, S. <a href="http://arxiv.org/abs/1907.05600">Generative modeling by estimating gradients of the data distribution</a>. CoRR, abs/1907.05600, 2019.</li> <li>Song, Y., Garg, S., Shi, J., and Ermon, S. <a href="http://arxiv.org/abs/1905.07088">Sliced score matching: A scalable approach to density and score estimation</a>. CoRR, abs/1905.07088, 2019. URL http://arxiv.org/abs/1905.07088.</li> <li>Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B. <a href="https://arxiv.org/abs/2011.13456">Score-based generative modeling through stochastic differential equations</a>. ICLR, abs/1907.05600, 2021.</li> <li>Vahdat, A., Kreis, K., and Kautz, J. <a href="https://arxiv.org/abs/2106.05931">Score-based generative modeling in latent space</a>, 2021.</li> <li>Welling, M. and Teh, Y. W. <a href="https://dl.acm.org/doi/10.5555/3104482.3104568">Bayesian learning via stochastic gradient langevin dynamics</a>. In Proceedings of the 28th International Conference on International Conference on Machine Learning, ICML’11, pp. 681–688, Madison, WI, USA, 2011. Omnipress. ISBN 9781450306195.</li> <li>Zhang, H., Feng, R., Yang, Z., Huang, L., Liu, Y., Zhang, Y., Shen, Y., Zhao, D., Zhou, J., and Cheng, F. <a href="https://arxiv.org/abs/2211.16032">Dimensionality-varying diffusion process</a>, 2022.</li> <li>Zheng, H., He, P., Chen, W., and Zhou, M. <a href="https://arxiv.org/abs/2202.09671">Truncated diffusion probabilistic models and diffusion-based adversarial auto-encoders</a>, 2022.</li> </ul>]]></content><author><name>fanpu</name></author><category term="machine-learning"/><summary type="html"><![CDATA[Score-based diffusion models are a promising direction for generative models, as they improve on both likelihood-based approaches like variational autoencoders, as well as adversarial methods like Generative Adversarial Networks (GANs). In this blog post, we survey recent developments in the field centered around the line of results developed in (Song & Ermon, 2019), analyze the current strengths and limitations of score-based diffusion models, and discuss possible future directions that can address its drawbacks. Joint work with Owen Wang.]]></summary></entry><entry><title type="html">The Art of LaTeX: Common Mistakes, and Advice for Typesetting Beautiful, Delightful Proofs</title><link href="https://fanpu.io/blog/2023/latex-tips/" rel="alternate" type="text/html" title="The Art of LaTeX: Common Mistakes, and Advice for Typesetting Beautiful, Delightful Proofs"/><published>2023-01-02T00:00:00+00:00</published><updated>2023-01-02T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/latex-tips</id><content type="html" xml:base="https://fanpu.io/blog/2023/latex-tips/"><![CDATA[<p>When was the first time you had to use <a href="https://www.latex-project.org/">LaTeX</a>? If you are like most people, it was probably suddenly forced upon you during your first math or CS class where you had to start writing proofs, with minimal guidance on how to get started other than something along the lines of “hey, check out this link on how to get things setup, and here are some basic commands, now go wild!”.</p> <p>Unfortunately, this meant that while many people have good operational knowledge of LaTeX and can get the job done, there are still many small mistakes and best practices which are not followed, which are not corrected by TAs as they are either not severe enough to warrant a note, or perhaps even the TAs themselves are not aware of them.</p> <p>In this post, we cover some common mistakes that are made by LaTeX practitioners (even in heavily cited papers), and how to address them. This post assumes that the reader has some working knowledge of LaTeX.</p> <h2 id="typesetting-as-a-form-of-art">Typesetting as a Form of Art</h2> <p>It is important to get into the right mindset whenever you typeset a document. You are not simply “writing” a document — you are crafting a work of art that combines both the precision and creativity of your logical thinking, as well as the elegance of a beautifully typeset writing. The amount of attention and care you put into the presentation is indicative of the amount of thought you put into the content. Therefore, having good style is not only delightful and aesthetically pleasing to read, but it also serves to establish your ethos and character. One can tell that someone puts a lot of effort into their work and takes great pride in them when they pay attention even to the smallest of details.</p> <p>Furthermore, adopting good practices also helps to avoid you making typographical mistakes in your proof, such as missing parenthesis or wrong positioning. This could often lead to cascading errors that are very annoying to fix when you discover them later on. There are ways to replicate the strict typechecking of statically typed languages to ensure that mistakes in your expressions can be caught at compile-time.</p> <h2 id="common-mistakes-and-how-to-fix-them">Common Mistakes, and How To Fix Them</h2> <p>In the following section, we take a look at common mistakes that people make, and how they can be avoided or fixed. We cover style mistakes first, since the ideas behind them are more general. All the screenshotted examples come from peer-reviewed papers that have been published to top conferences, so they are definitely very common mistakes and you shouldn’t feel bad for making them. The important thing is that you are aware of them now so that your style will gradually improve over time.</p> <h2 id="style-mistakes">Style Mistakes</h2> <p>We take a look at style mistakes, which impairs reader understanding, and makes it easy to commit other sorts of errors.</p> <h3 id="paired-delimiters">Paired Delimiters</h3> <p>Parenthesis, brackets, and pipes are examples of delimiters that are used to mark the start and end of formula expressions. As they come in pairs, a common mistake is accidentally leaving out the closing delimiter, especially for nested expressions. Even if you don’t forget to do so, there is the issue of incorrect sizing.</p> <p>For instance, consider the following way of expressing the Topologist’s sine curve, which is an example of a topology that is connected but not path connected:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex">T = <span class="k">\{</span> ( x, <span class="k">\sin</span> <span class="k">\frac</span><span class="p">{</span>1<span class="p">}{</span>x<span class="p">}</span> ) : x <span class="k">\in</span> (0, 1] <span class="k">\}</span> <span class="k">\cup</span> <span class="k">\{</span> ( 0, 0 ) <span class="k">\}</span></code></pre></figure> <p>which is rendered as follows:</p> \[T = \{(x, \sin \frac{1}{x} ) : x \in (0, 1] \} \cup \{ ( 0, 0 ) \}\] <p>The problem here is that the curly braces have the wrong size, as they should be large enough to cover the \(\sin \frac{1}{x}\) expression vertically.</p> <p>The wrong way of resolving this would be to use delimiter size modifiers, i.e <code class="language-plaintext highlighter-rouge">\bigl, \Bigl, \biggl</code> paired with <code class="language-plaintext highlighter-rouge">\bigr, \Bigr, \biggr</code> and the like. This is tedious and error-prone, since it will even happily let you match delimiters with different sizes. Indeed, I came across the following formula in a paper recently, where the outer right square brackets was missing and the left one had the wrong size:</p> <figure> <picture> <img src="/assets/img/posts/latex-mistakes/paired_delim.webp" class="z-depth-1 center" width="500px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> What happens when you don't use paired delimiters </figcaption> </figure> <p>The correct way to do this would be to use paired delimiters, which will automatically adjust its size based on its contents, and automatically result in a compile error if the matching right delimiter is not included, or nested at the wrong level. Some of them are given below:</p> <table class="table table-bordered table-sm"> <thead> <tr> <th>Raw LaTeX</th> <th>Rendered</th> </tr> </thead> <tbody> <tr> <td><code class="language-plaintext highlighter-rouge">\left( \frac{1}{x} \right) </code></td> <td>\(\left( \frac{1}{x} \right)\)</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">\left[ \frac{1}{x} \right] </code></td> <td>\(\left[ \frac{1}{x} \right]\)</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">\left\{ \frac{1}{x} \right\} </code></td> <td>\(\left\{ \frac{1}{x} \right\}\)</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">\left\lvert \frac{1}{x} \right\lvert </code></td> <td>\(\left\lvert \frac{1}{x} \right\rvert\)</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">\left\lceil \frac{1}{x} \right\rceil </code></td> <td>\(\left\lceil \frac{1}{x} \right\rceil\)</td> </tr> </tbody> </table> <p>In fact, to make things even simpler and more readable, you can declare paired delimiters for use based on the <code class="language-plaintext highlighter-rouge">mathtools</code> package, with the following commands due to <a href="http://www.cs.cmu.edu/~odonnell/">Ryan O’Donnell</a>:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="c">% Make sure you include \usepackage{mathtools}</span>
<span class="k">\DeclarePairedDelimiter\parens</span><span class="p">{</span><span class="k">\lparen</span><span class="p">}{</span><span class="k">\rparen</span><span class="p">}</span>
<span class="k">\DeclarePairedDelimiter\abs</span><span class="p">{</span><span class="k">\lvert</span><span class="p">}{</span><span class="k">\rvert</span><span class="p">}</span>
<span class="k">\DeclarePairedDelimiter\norm</span><span class="p">{</span><span class="k">\lVert</span><span class="p">}{</span><span class="k">\rVert</span><span class="p">}</span>
<span class="k">\DeclarePairedDelimiter\floor</span><span class="p">{</span><span class="k">\lfloor</span><span class="p">}{</span><span class="k">\rfloor</span><span class="p">}</span>
<span class="k">\DeclarePairedDelimiter\ceil</span><span class="p">{</span><span class="k">\lceil</span><span class="p">}{</span><span class="k">\rceil</span><span class="p">}</span>
<span class="k">\DeclarePairedDelimiter\braces</span><span class="p">{</span><span class="k">\lbrace</span><span class="p">}{</span><span class="k">\rbrace</span><span class="p">}</span>
<span class="k">\DeclarePairedDelimiter\bracks</span><span class="p">{</span><span class="k">\lbrack</span><span class="p">}{</span><span class="k">\rbrack</span><span class="p">}</span>
<span class="k">\DeclarePairedDelimiter\angles</span><span class="p">{</span><span class="k">\langle</span><span class="p">}{</span><span class="k">\rangle</span><span class="p">}</span></code></pre></figure> <p>Then you can now use the custom delimiters as follows, taking note that you need the <code class="language-plaintext highlighter-rouge">*</code> for it to auto-resize:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex">T = <span class="k">\braces*</span><span class="p">{</span> <span class="k">\parens*</span><span class="p">{</span> x, <span class="k">\sin</span> <span class="k">\frac</span><span class="p">{</span>1<span class="p">}{</span>x<span class="p">}</span> <span class="p">}</span> : x <span class="k">\in</span> (0, 1] <span class="p">}</span> <span class="k">\cup</span> <span class="k">\braces*</span><span class="p">{</span> <span class="k">\parens*</span><span class="p">{</span> 0, 0 <span class="p">}}</span></code></pre></figure> <p>which gives</p> \[T = \left\{ \left( x, \sin \frac{1}{x} \right) : x \in (0, 1] \right\} \cup \left\{ \left( 0, 0 \right) \right\} \\\] <p>The biggest downside of using custom paired delimiters is having to remember to add the <code class="language-plaintext highlighter-rouge">*</code>, otherwise, the delimiters will not auto-resize. This is pretty unfortunate as it still makes it error-prone. There is a <a href="https://tex.stackexchange.com/questions/1742/automatic-left-and-right-commands/1744#1744">proposed solution</a> floating around on StackExchange that relies on a custom command that makes auto-resizing the default, but it’s still a far cry from a parsimonious solution.</p> <h3 id="macros-for-saving-time-and-preventing-mistakes">Macros for Saving Time and Preventing Mistakes</h3> <p>Macros can be defined using the <code class="language-plaintext highlighter-rouge">\newcommand</code> command. The basic syntax is <code class="language-plaintext highlighter-rouge">\newcommand{command_name}{command_definition}</code>. For instance, it might get tiring to always type <code class="language-plaintext highlighter-rouge">\boldsymbol{A}</code> to refer to a matrix \(\boldsymbol{A}\), so you can use the following macro:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="c">% Macro</span>
<span class="k">\newcommand</span><span class="p">{</span><span class="k">\bA</span><span class="p">}{</span><span class="k">\boldsymbol</span><span class="p">{</span>A<span class="p">}}</span>

<span class="p">$$</span><span class="nv">\min</span><span class="p">_</span><span class="nb">x </span><span class="nv">\lvert</span><span class="nb"> </span><span class="nv">\bA</span><span class="nb"> x </span><span class="o">-</span><span class="nb"> b </span><span class="nv">\rvert</span><span class="p">_</span><span class="m">2</span><span class="p">^</span><span class="m">2</span><span class="p">$$</span></code></pre></figure> \[\min_x \left\lvert \boldsymbol{A} x - b \right\rvert_2^2\] <p>Macros can also take arguments to be substituted within the definition. This is done by adding a <code class="language-plaintext highlighter-rouge">[n]</code> argument after your command name, where <code class="language-plaintext highlighter-rouge">n</code> is the number of arguments that it should take. You can then reference the positional arguments using <code class="language-plaintext highlighter-rouge">#1, #2,</code> and so on. Here, we create a <code class="language-plaintext highlighter-rouge">\dotprod</code> macro that takes two arguments:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="c">% Macros</span>
<span class="k">\newcommand</span><span class="p">{</span><span class="k">\dotprod</span><span class="p">}</span>[2]<span class="p">{</span><span class="k">\langle</span> #1, #2 <span class="k">\rangle</span><span class="p">}</span>
<span class="k">\newcommand</span><span class="p">{</span><span class="k">\bu</span><span class="p">}{</span><span class="k">\boldsymbol</span><span class="p">{</span>u<span class="p">}}</span>
<span class="k">\newcommand</span><span class="p">{</span><span class="k">\bv</span><span class="p">}{</span><span class="k">\boldsymbol</span><span class="p">{</span>v<span class="p">}}</span>

<span class="p">$$</span><span class="nv">\left\lvert</span><span class="nb"> </span><span class="nv">\dotprod</span><span class="p">{</span><span class="nv">\bu</span><span class="p">}{</span><span class="nv">\bv</span><span class="p">}</span><span class="nb"> </span><span class="nv">\right\rvert</span><span class="p">^</span><span class="m">2</span><span class="nb"> </span><span class="nv">\leq</span><span class="nb"> </span><span class="nv">\dotprod</span><span class="p">{</span><span class="nv">\bu</span><span class="p">}{</span><span class="nv">\bu</span><span class="p">}</span><span class="nb"> </span><span class="nv">\cdot</span><span class="nb"> </span><span class="nv">\dotprod</span><span class="p">{</span><span class="nv">\bv</span><span class="p">}{</span><span class="nv">\bv</span><span class="p">}$$</span></code></pre></figure> \[\left\lvert \dotprod{\bu}{\bv} \right\rvert^2 \leq \dotprod{\bu}{\bu} \cdot \dotprod{\bv}{\bv}\] <p>Macros are incredibly helpful as they help to save time, and ensure that our notation is consistent. However, they can also be used to help to catch mistakes when typesetting grammatically structured things.</p> <p>For instance, when expressing types and terms in programming language theory, there is often a lot of nested syntactical structure, which could make it easy to make mistakes. Consider the following proof:</p> <figure> <picture> <img src="/assets/img/posts/latex-mistakes/macros.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> A proof with a lot of syntactical structure </figcaption> </figure> <p>The details are unimportant, but it is clear that it is easy to miss a letter here or a term there in the proof, given how cumbersome the notation is. To avoid this, I used the following macros, due to <a href="http://www.cs.cmu.edu/~rwh/">Robert Harper</a>:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="k">\newcommand</span><span class="p">{</span><span class="k">\inval</span><span class="p">}</span>[2]<span class="p">{</span><span class="k">\in</span><span class="p">^{</span>(#1)<span class="p">}_</span><span class="k">\mathsf</span><span class="p">{</span>val<span class="p">}</span> #2<span class="p">}</span>
<span class="k">\newcommand</span><span class="p">{</span><span class="k">\foldex</span><span class="p">}</span>[2]<span class="p">{</span><span class="k">\mathsf</span><span class="p">{</span>fold<span class="p">}_{</span>#1<span class="p">}</span>(#2)<span class="p">}</span>
<span class="k">\newcommand</span><span class="p">{</span><span class="k">\recty</span><span class="p">}</span>[2]<span class="p">{</span><span class="k">\mathsf</span><span class="p">{</span>rec<span class="p">}</span>(#1.#2)<span class="p">}</span>
<span class="k">\newcommand</span><span class="p">{</span><span class="k">\Subst</span><span class="p">}</span>[3]<span class="p">{</span><span class="k">\sqbracks</span><span class="p">{{</span>#1<span class="p">}</span><span class="k">\mathord</span><span class="p">{</span>/<span class="p">}{</span>#2<span class="p">}}{</span>#3<span class="p">}}</span></code></pre></figure> <p>And the source for the proof looks like the following:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex">We check that anti-monotonicity continues to hold for recursive types,
by showing that if <span class="p">$</span><span class="nb">m </span><span class="nv">\leq</span><span class="nb"> n</span><span class="p">$</span>, then
<span class="p">$$</span><span class="nv">\foldex</span><span class="p">{</span><span class="nb">X.A</span><span class="p">}{</span><span class="nb">V</span><span class="p">}</span><span class="nb"> </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">n</span><span class="p">}{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}</span><span class="nb"> </span><span class="nv">\text</span><span class="p">{</span><span class="nb"> implies </span><span class="p">}</span><span class="nb"> </span><span class="nv">\foldex</span><span class="p">{</span><span class="nb">X.A</span><span class="p">}{</span><span class="nb">V</span><span class="p">}</span><span class="nb"> </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">m</span><span class="p">}{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}</span><span class="nb">. </span><span class="p">$$</span>

<span class="nt">\begin{proof}</span>
We proceed by induction on <span class="p">$</span><span class="nb">n</span><span class="p">$</span>. 
When <span class="p">$</span><span class="nb">n</span><span class="o">=</span><span class="m">0</span><span class="p">$</span>, the result is trivial, so consider <span class="p">$</span><span class="nb">n </span><span class="nv">\geq</span><span class="nb"> </span><span class="m">0</span><span class="p">$</span>, with the intent to prove it for <span class="p">$</span><span class="nb">n</span><span class="o">+</span><span class="m">1</span><span class="p">$</span>.

Let <span class="p">$</span><span class="nb">m </span><span class="nv">\leq</span><span class="nb"> n </span><span class="o">+</span><span class="nb"> </span><span class="m">1</span><span class="p">$</span>, and assume
<span class="p">$</span><span class="nv">\foldex</span><span class="p">{</span><span class="nb">X.A</span><span class="p">}{</span><span class="nb">V</span><span class="p">}</span><span class="nb"> </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">n</span><span class="o">+</span><span class="m">1</span><span class="p">}{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}$</span>. If <span class="p">$</span><span class="nb">m </span><span class="o">=</span><span class="nb"> n </span><span class="o">+</span><span class="nb"> </span><span class="m">1</span><span class="p">$</span> or <span class="p">$</span><span class="nb">m</span><span class="o">=</span><span class="m">0</span><span class="p">$</span>, we are trivially done, so let <span class="p">$</span><span class="m">0</span><span class="nb"> &lt; m &lt; n</span><span class="o">+</span><span class="m">1</span><span class="p">$</span>.

We want to show that
<span class="p">$</span><span class="nv">\foldex</span><span class="p">{</span><span class="nb">X.A</span><span class="p">}{</span><span class="nb">V</span><span class="p">}</span><span class="nb"> </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">m</span><span class="p">}{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}$</span>.
By definition of step-indexed logical relations~(SILR), it suffices to show
<span class="p">$</span><span class="nb">V </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">m</span><span class="o">-</span><span class="m">1</span><span class="p">}{</span><span class="nv">\Subst</span><span class="p">{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}$</span>.

Since <span class="p">$</span><span class="nv">\foldex</span><span class="p">{</span><span class="nb">X.A</span><span class="p">}{</span><span class="nb">V</span><span class="p">}</span><span class="nb"> </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">n</span><span class="o">+</span><span class="m">1</span><span class="p">}{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}$</span>, by definition of SILR,
<span class="p">$</span><span class="nb">V </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">n</span><span class="p">}{</span><span class="nv">\Subst</span><span class="p">{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}$</span>.

By IH on <span class="p">$</span><span class="nb">V </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">n</span><span class="p">}{</span><span class="nv">\Subst</span><span class="p">{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}$</span>,
we also know <span class="p">$</span><span class="nb">V </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">m</span><span class="o">-</span><span class="m">1</span><span class="p">}{</span><span class="nv">\Subst</span><span class="p">{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}$</span>.

But then by definition of SILR,
<span class="p">$</span><span class="nv">\foldex</span><span class="p">{</span><span class="nb">X.A</span><span class="p">}{</span><span class="nb">V</span><span class="p">}</span><span class="nb"> </span><span class="nv">\inval</span><span class="p">{</span><span class="nb">m</span><span class="p">}{</span><span class="nv">\recty</span><span class="p">{</span><span class="nb">X</span><span class="p">}{</span><span class="nb">A</span><span class="p">}}$</span>, as desired. <span class="k">\qedhere</span>
<span class="nt">\end{proof}</span></code></pre></figure> <p>It is definitely still not the most pleasant thing to read, but at least now you will be less likely to miss an argument or forget to close a parenthesis.</p> <h3 id="non-breaking-lines">Non-breaking lines</h3> <p>Expressions which are logically a single unit should stay on the same line, instead of being split apart mid-sentence. Cue the following bad example from another paper:</p> <figure> <picture> <img src="/assets/img/posts/latex-mistakes/nbsp.webp" class="z-depth-1 center" width="300px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> Expressions that are broken apart </figcaption> </figure> <p>In the area marked in red, we had the expression that was defining \(\tau^i\) get cut in half, which is very jarring visually and interrupts the reader’s train of thought.</p> <p>To ensure that expressions do not get split, simply wrap it around in curly braces. For instance,</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="k">\tau</span>=<span class="k">\left</span>(s<span class="p">_</span>1, a<span class="p">_</span>1, <span class="k">\ldots</span>, a<span class="p">_{</span>t-1<span class="p">}</span>, s<span class="p">_</span>t<span class="k">\right</span>)</code></pre></figure> <p>would be wrapped by <code class="language-plaintext highlighter-rouge">{</code> and <code class="language-plaintext highlighter-rouge">}</code> on both sides and become</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="p">{</span> <span class="k">\tau</span>=<span class="k">\left</span>(s<span class="p">_</span>1, a<span class="p">_</span>1, <span class="k">\ldots</span>, a<span class="p">_{</span>t-1<span class="p">}</span>, s<span class="p">_</span>t<span class="k">\right</span>) <span class="p">}</span></code></pre></figure> <p>So if we render the following snippet, which would otherwise have expressions split in half without the wrapped curly braces:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex">We denote the historical trajectory as 
<span class="p">${</span><span class="nb"> </span><span class="nv">\tau</span><span class="o">=</span><span class="nv">\left</span><span class="o">(</span><span class="nb">s</span><span class="p">_</span><span class="m">1</span><span class="nb">, a</span><span class="p">_</span><span class="m">1</span><span class="nb">, </span><span class="nv">\ldots</span><span class="nb">, a</span><span class="p">_{</span><span class="nb">t</span><span class="o">-</span><span class="m">1</span><span class="p">}</span><span class="nb">, s</span><span class="p">_</span><span class="nb">t</span><span class="nv">\right</span><span class="o">)</span><span class="nb"> </span><span class="p">}$</span>
and action-observation history <span class="p">$</span><span class="o">(</span><span class="nv">\mathrm</span><span class="p">{</span><span class="nb">AOH</span><span class="p">}</span><span class="o">)</span><span class="p">$</span> for
player <span class="p">$</span><span class="nb">i</span><span class="p">$</span> as 
<span class="p">${</span><span class="nb"> </span><span class="nv">\tau</span><span class="p">^</span><span class="nb">i</span><span class="o">=</span><span class="nv">\left</span><span class="o">(</span><span class="nv">\Omega</span><span class="p">^</span><span class="nb">i</span><span class="nv">\left</span><span class="o">(</span><span class="nb">s</span><span class="p">_</span><span class="m">1</span><span class="nv">\right</span><span class="o">)</span><span class="nb">, a</span><span class="p">_</span><span class="m">1</span><span class="nb">, </span><span class="nv">\ldots</span><span class="nb">, a</span><span class="p">_{</span><span class="nb">t</span><span class="o">-</span><span class="m">1</span><span class="p">}</span><span class="nb">, </span><span class="nv">\Omega</span><span class="p">^</span><span class="nb">i</span><span class="nv">\left</span><span class="o">(</span><span class="nb">s</span><span class="p">_</span><span class="nb">t</span><span class="nv">\right</span><span class="o">)</span><span class="nv">\right</span><span class="o">)</span><span class="nb"> </span><span class="p">}$</span>,
 which encodes the trajectory from player <span class="p">$</span><span class="nb">i</span><span class="p">$</span> 's point of view.</code></pre></figure> <p>we get the following positive result where there is additional whitespace between the justified text on the first line, to compensate for the expression assigning \(\tau\) to stay on the same line:</p> <figure> <picture> <img src="/assets/img/posts/latex-mistakes/nbsp-positive.webp" class="z-depth-1 center" width="300px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> Expressions that brace together stays together </figcaption> </figure> <h3 id="non-breaking-space-with-">Non-breaking space with <code class="language-plaintext highlighter-rouge">~</code></h3> <p>When referencing figures and equations, you want the text and number (i.e Figure 10) to end up on the same line. This is a negative example, where the region underlined in red shows how it was split up:</p> <figure> <picture> <img src="/assets/img/posts/latex-mistakes/figure-truncated.webp" class="z-depth-1 center" width="500px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> The phrase "Figure 2" was truncated in half </figcaption> </figure> <p>To remedy this, add a <code class="language-plaintext highlighter-rouge">~</code> after <code class="language-plaintext highlighter-rouge">Figure</code>, which LaTeX interprets as a non-breaking space:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex">We evaluated the policy periodically during training by testing it without exploration noise.
Figure~<span class="k">\ref</span><span class="p">{</span>fig:env-perf<span class="p">}</span> shows the performance curve for a selection of environments. </code></pre></figure> <p>This would ensure that “Figure 2” always appears together.</p> <h3 id="expressions-should-be-punctuated-like-sentences">Expressions Should Be Punctuated Like Sentences</h3> <p>Your document is meant to be read, and it should follow the rules and structures of English (or whichever language you are writing in). This means that mathematical expressions should also be punctuated appropriately, which allows it to flow more naturally and make it easier for the reader to follow.</p> <p>Consider the following example that does not use punctuation:</p> <figure> <picture> <img src="/assets/img/posts/latex-mistakes/sentence-negative.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> Expressions which are not punctuated are tiring to read </figcaption> </figure> <p>In the region highlighted in red, the expressions do not carry any punctuation at all, and by the end of the last equation (Equation 15), I am almost out of breath trying to process all of the information. In addition, it does not end in a full stop, which does not give me an affordance to take a break mentally until the next paragraph.</p> <p>Instead, commas should be added after each expression where the expression does not terminate, and the final equation should be ended by a full stop. Here is a good example of punctuation that helps to guide the reader along the author’s train of thought:</p> <figure> <picture> <img src="/assets/img/posts/latex-mistakes/sentence-multiline.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> Appropriate use of commas and full stop to guide the reader </figcaption> </figure> <p>Here is another good example of how using commas for the equations allow the text to flow naturally, where it takes the form of “analogously, observe that we have [foo] and [bar], where the inequality…”:</p> <figure> <picture> <img src="/assets/img/posts/latex-mistakes/sentence-two-exp.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> Punctuation allows the content to flow naturally </figcaption> </figure> <p>This even extends to when you pack several equations on a single line, which is common when you are trying to fit the page limit for conference submissions:</p> <figure> <picture> <img src="/assets/img/posts/latex-mistakes/sentence-singleline.webp" class="z-depth-1 center" width="400px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> Appropriate use of punctuation when multiple equations are on a single line </figcaption> </figure> <h3 id="the-proof-environment">The <code class="language-plaintext highlighter-rouge">proof</code> environment</h3> <p>The <code class="language-plaintext highlighter-rouge">proof</code> environment from the <code class="language-plaintext highlighter-rouge">amsthm</code> package is great for signposting to your readers where a proof starts and ends. For instance, consider how it is used in the following example:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="k">\textit</span><span class="p">{</span>Problem: Show that if <span class="p">$</span><span class="o">(</span><span class="nb">x</span><span class="p">_</span><span class="nb">n</span><span class="o">)</span><span class="p">_</span><span class="nb">n</span><span class="p">$</span> converges to <span class="p">$</span><span class="nb">x</span><span class="p">$</span> in the usual sense, then
<span class="p">$</span><span class="nv">\lim</span><span class="p">_{</span><span class="nb">n </span><span class="nv">\to</span><span class="nb"> </span><span class="nv">\infty</span><span class="p">}</span><span class="nb"> x</span><span class="p">_</span><span class="nb">n </span><span class="o">=</span><span class="nb"> </span><span class="nv">\lim</span><span class="p">_{</span><span class="nv">\mathcal</span><span class="p">{</span><span class="nb">F</span><span class="p">}}</span><span class="nb"> x</span><span class="p">_</span><span class="nb">n</span><span class="p">$</span>.<span class="p">}</span>

Suppose that <span class="p">$</span><span class="o">(</span><span class="nb">x</span><span class="p">_</span><span class="nb">n</span><span class="o">)</span><span class="p">_</span><span class="nb">n</span><span class="p">$</span> converges to <span class="p">$</span><span class="nb">x</span><span class="p">$</span>. We show that this <span class="p">$</span><span class="nb">x</span><span class="p">$</span> is also the
<span class="p">$</span><span class="nv">\mathcal</span><span class="p">{</span><span class="nb">F</span><span class="p">}$</span>-limit of <span class="p">$</span><span class="o">(</span><span class="nb">x</span><span class="p">_</span><span class="nb">n</span><span class="o">)</span><span class="p">_</span><span class="nb">n</span><span class="p">$</span>.

<span class="nt">\begin{proof}</span>
    Take any <span class="p">$</span><span class="nv">\varepsilon</span><span class="p">$</span>. Then we know that for some large enough <span class="p">$</span><span class="nb">N</span><span class="p">$</span>, if <span class="p">$</span><span class="nb">n </span><span class="nv">\geq</span><span class="nb"> N</span><span class="p">$</span>, then
    <span class="p">$</span><span class="nb">x</span><span class="p">_</span><span class="nb">n </span><span class="nv">\in</span><span class="nb"> B</span><span class="p">_</span><span class="nv">\varepsilon</span><span class="o">(</span><span class="nb">x</span><span class="o">)</span><span class="p">$</span>. Since every non-principal ultrafilter on <span class="p">$</span><span class="nv">\N</span><span class="p">$</span> contains
    <span class="p">$</span><span class="nv">\mathcal</span><span class="p">{</span><span class="nb">F</span><span class="p">}_</span><span class="nv">\infty</span><span class="p">$</span>, then <span class="p">$</span><span class="nv">\mathcal</span><span class="p">{</span><span class="nb">F</span><span class="p">}$</span> also contains <span class="p">$</span><span class="nb"> </span><span class="nv">\left\{</span><span class="nb"> n : n </span><span class="nv">\geq</span><span class="nb"> N </span><span class="nv">\right\}</span><span class="nb"> </span><span class="p">$</span>,
    since the complement is finite. Therefore since filters are closed upwards, any
    sequence items <span class="p">$</span><span class="nb">x</span><span class="p">_</span><span class="nb">n</span><span class="p">$</span> with <span class="p">$</span><span class="nb">n &lt; N</span><span class="p">$</span> that happen to fall in the ball around <span class="p">$</span><span class="nb">x</span><span class="p">$</span>,
    i.e, <span class="p">$</span><span class="nb">x</span><span class="p">_</span><span class="nb">n </span><span class="nv">\in</span><span class="nb"> B</span><span class="p">_</span><span class="nv">\varepsilon</span><span class="o">(</span><span class="nb">x</span><span class="o">)</span><span class="p">$</span>
    is also contained in some filter element, so 
    <span class="p">$</span><span class="nv">\left\{</span><span class="nb">  n </span><span class="nv">\in</span><span class="nb"> </span><span class="nv">\N</span><span class="nb"> : </span><span class="nv">\lvert</span><span class="nb"> x</span><span class="p">_</span><span class="nb">n </span><span class="o">-</span><span class="nb"> x </span><span class="nv">\rvert</span><span class="nb"> &lt; </span><span class="nv">\varepsilon</span><span class="nb"> </span><span class="nv">\right\}</span><span class="nb"> </span><span class="nv">\in</span><span class="nb"> </span><span class="nv">\mathcal</span><span class="p">{</span><span class="nb">F</span><span class="p">}$</span>,
    as desired.
<span class="nt">\end{proof}</span></code></pre></figure> <figure> <picture> <img src="/assets/img/posts/latex-mistakes/proof.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> Signposting using the `proof` environment </figcaption> </figure> <p>This will helpfully highlight the start of your argument with <em>“Proof”</em>, and terminate it with a square that symbolizes QED.</p> <h3 id="terminate-proofs-with-explicit-qedhere">Terminate Proofs with Explicit <code class="language-plaintext highlighter-rouge">\qedhere</code></h3> <p>Consider the same example as previously, but now you accidentally added an additional newline before the closing <code class="language-plaintext highlighter-rouge">\end{proof}</code>, which happens pretty often:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="c">% Same as previously, contents elided for brevity</span>
<span class="nt">\begin{proof}</span>
    <span class="c">% Same as previously, contents elided for brevity</span>
    <span class="p">$</span><span class="nb">x</span><span class="p">_</span><span class="nb">n </span><span class="nv">\in</span><span class="nb"> B</span><span class="p">_</span><span class="nv">\varepsilon</span><span class="o">(</span><span class="nb">x</span><span class="o">)</span><span class="p">$</span>
    is also contained in some filter element, so 
    <span class="p">$</span><span class="nv">\left\{</span><span class="nb">  n </span><span class="nv">\in</span><span class="nb"> </span><span class="nv">\N</span><span class="nb"> : </span><span class="nv">\lvert</span><span class="nb"> x</span><span class="p">_</span><span class="nb">n </span><span class="o">-</span><span class="nb"> x </span><span class="nv">\rvert</span><span class="nb"> &lt; </span><span class="nv">\varepsilon</span><span class="nb"> </span><span class="nv">\right\}</span><span class="nb"> </span><span class="nv">\in</span><span class="nb"> </span><span class="nv">\mathcal</span><span class="p">{</span><span class="nb">F</span><span class="p">}$</span>,
    as desired.

    <span class="c">% Extra newline here!</span>
<span class="nt">\end{proof}</span></code></pre></figure> <figure> <picture> <img src="/assets/img/posts/latex-mistakes/qedhere.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> Misaligned QED symbol </figcaption> </figure> <p>This results in the above scenario, where the QED symbol now appears on the next line by itself, which throws the entire text off-balance visually. To avoid such things happening, always include an explicit <code class="language-plaintext highlighter-rouge">\qedhere</code> marker at the end of your proof, which would cause it to always appear on the line that it appears after:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="c">% Same as previously, contents elided for brevity</span>
<span class="nt">\begin{proof}</span>
    <span class="c">% Same as previously, contents elided for brevity</span>
    <span class="p">$</span><span class="nb">x</span><span class="p">_</span><span class="nb">n </span><span class="nv">\in</span><span class="nb"> B</span><span class="p">_</span><span class="nv">\varepsilon</span><span class="o">(</span><span class="nb">x</span><span class="o">)</span><span class="p">$</span>
    is also contained in some filter element, so 
    <span class="p">$</span><span class="nv">\left\{</span><span class="nb">  n </span><span class="nv">\in</span><span class="nb"> </span><span class="nv">\N</span><span class="nb"> : </span><span class="nv">\lvert</span><span class="nb"> x</span><span class="p">_</span><span class="nb">n </span><span class="o">-</span><span class="nb"> x </span><span class="nv">\rvert</span><span class="nb"> &lt; </span><span class="nv">\varepsilon</span><span class="nb"> </span><span class="nv">\right\}</span><span class="nb"> </span><span class="nv">\in</span><span class="nb"> </span><span class="nv">\mathcal</span><span class="p">{</span><span class="nb">F</span><span class="p">}$</span>,
    as desired. <span class="k">\qedhere</span> <span class="c">% Always add \qedhere once you are done!</span>

    <span class="c">% Extra newline here!</span>
<span class="nt">\end{proof}</span></code></pre></figure> <p>We would then get the same result as before originally, when we did not have the extra newline.</p> <h3 id="spacing">Spacing</h3> <p>Spacing matters a lot in readability, as it helps to separate logical components. For instance, the following example fails to add spacing before the differential of the variable \(dz\):</p> <figure> <picture> <img src="/assets/img/posts/latex-mistakes/integral.webp" class="z-depth-1 center" width="500px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> Lack of spacing before "dz" </figcaption> </figure> <p>This might seem innocuous, but consider the following example that makes the issue more explicit:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex">P(X) = <span class="k">\int</span> xyz dx</code></pre></figure> \[P(X) = \int xyz dx\] <p>Now we can really see that the quantities are running into each other, and it becomes hard to interpret. Instead, we can add math-mode spacing, summarized in the following table:</p> <table class="table table-bordered table-sm"> <thead> <tr> <th>Spacing Expression</th> <th>Type</th> </tr> </thead> <tbody> <tr> <td><code class="language-plaintext highlighter-rouge">\;</code></td> <td>Thick space</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">\:</code></td> <td>Medium space</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">\,</code></td> <td>Thin space</td> </tr> </tbody> </table> <p>So our new expression now looks like:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex">P(X) = <span class="k">\int</span> xyz <span class="k">\,</span> dx</code></pre></figure> \[P(X) = \int xyz \, dx\] <p>which is much more readable.</p> <h3 id="align-environment-for-multiline-equations"><code class="language-plaintext highlighter-rouge">align*</code> Environment for Multiline Equations</h3> <p>When using the <code class="language-plaintext highlighter-rouge">align*</code> environment, make sure that your ampersands <code class="language-plaintext highlighter-rouge">&amp;</code> appear before the symbol that you are aligning against. This ensures that you get the correct spacing.</p> <p>For instance, the following is wrong, where the <code class="language-plaintext highlighter-rouge">&amp;</code> appears after the <code class="language-plaintext highlighter-rouge">=</code>:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="nt">\begin{align*}</span>
    <span class="k">\nabla</span><span class="p">_{</span><span class="k">\mu</span><span class="p">}</span> (<span class="k">\mathbb</span><span class="p">{</span>E<span class="p">}_{</span>x<span class="k">\sim</span> q<span class="p">_{</span><span class="k">\mu</span><span class="p">}}</span> f(x))  = <span class="p">&amp;</span> <span class="k">\nabla</span><span class="p">_{</span><span class="k">\mu</span><span class="p">}</span> <span class="k">\int</span><span class="p">_</span>x f(x) q<span class="p">_{</span><span class="k">\mu</span><span class="p">}</span>(x) dx                                     <span class="k">\\</span>
                                                    = <span class="p">&amp;</span> <span class="k">\int</span><span class="p">_</span>x f(x) (<span class="k">\nabla</span><span class="p">_{</span><span class="k">\mu</span><span class="p">}</span> <span class="k">\log</span> q<span class="p">_{</span><span class="k">\mu</span><span class="p">}</span>(x))  q<span class="p">_{</span><span class="k">\mu</span><span class="p">}</span>(x) dx                  <span class="k">\\</span>
                                                    = <span class="p">&amp;</span> <span class="k">\mathbb</span><span class="p">{</span>E<span class="p">}_{</span>x <span class="k">\sim</span> q<span class="p">_{</span><span class="k">\mu</span><span class="p">}}</span> <span class="k">\left</span>(f(x) <span class="k">\nabla</span><span class="p">_{</span><span class="k">\mu</span><span class="p">}</span> <span class="k">\log</span> q<span class="p">_{</span><span class="k">\mu</span><span class="p">}</span>(x)<span class="k">\right</span>)
<span class="nt">\end{align*}</span></code></pre></figure> \[\begin{align*} \nabla_{\mu} (\mathbb{E}_{x\sim q_{\mu}} f(x)) = &amp; \nabla_{\mu} \int_x f(x) q_{\mu}(x) dx \\ = &amp; \int_x f(x) (\nabla_{\mu} \log q_{\mu}(x)) q_{\mu}(x) dx \\ = &amp; \mathbb{E}_{x \sim q_{\mu}} \left(f(x) \nabla_{\mu} \log q_{\mu}(x)\right) \end{align*}\] <p>This is because there is too little spacing after the <code class="language-plaintext highlighter-rouge">=</code> sign on each line, which feels very cramped. Putting the <code class="language-plaintext highlighter-rouge">&amp;</code> before the <code class="language-plaintext highlighter-rouge">=</code> is correct:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="nt">\begin{align*}</span>
    <span class="k">\nabla</span><span class="p">_{</span><span class="k">\mu</span><span class="p">}</span> (<span class="k">\mathbb</span><span class="p">{</span>E<span class="p">}_{</span>x<span class="k">\sim</span> q<span class="p">_{</span><span class="k">\mu</span><span class="p">}}</span> f(x)) <span class="p">&amp;</span> = <span class="k">\nabla</span><span class="p">_{</span><span class="k">\mu</span><span class="p">}</span> <span class="k">\int</span><span class="p">_</span>x f(x) q<span class="p">_{</span><span class="k">\mu</span><span class="p">}</span>(x) dx                                     <span class="k">\\</span>
                                                   <span class="p">&amp;</span> =  <span class="k">\int</span><span class="p">_</span>x f(x) (<span class="k">\nabla</span><span class="p">_{</span><span class="k">\mu</span><span class="p">}</span> <span class="k">\log</span> q<span class="p">_{</span><span class="k">\mu</span><span class="p">}</span>(x))  q<span class="p">_{</span><span class="k">\mu</span><span class="p">}</span>(x) dx                 <span class="k">\\</span>
                                                   <span class="p">&amp;</span> = <span class="k">\mathbb</span><span class="p">{</span>E<span class="p">}_{</span>x <span class="k">\sim</span> q<span class="p">_{</span><span class="k">\mu</span><span class="p">}}</span> <span class="k">\left</span>(f(x) <span class="k">\nabla</span><span class="p">_{</span><span class="k">\mu</span><span class="p">}</span> <span class="k">\log</span> q<span class="p">_{</span><span class="k">\mu</span><span class="p">}</span>(x)<span class="k">\right</span>)
<span class="nt">\end{align*}</span></code></pre></figure> \[\begin{align*} \nabla_{\mu} (\mathbb{E}_{x\sim q_{\mu}} f(x)) &amp; = \nabla_{\mu} \int_x f(x) q_{\mu}(x) dx \\ &amp; = \int_x f(x) (\nabla_{\mu} \log q_{\mu}(x)) q_{\mu}(x) dx \\ &amp; = \mathbb{E}_{x \sim q_{\mu}} \left(f(x) \nabla_{\mu} \log q_{\mu}(x)\right) \end{align*}\] <p>The spacing is much more comfortable now.</p> <h2 id="command-mistakes">Command Mistakes</h2> <p>We now look at some mistakes that arise from using the wrong commands.</p> <h3 id="math-operators">Math Operators</h3> <p>Instead of <code class="language-plaintext highlighter-rouge">sin (x)</code> \((sin(x))\) or <code class="language-plaintext highlighter-rouge">log (x)</code> \((log (x))\), use <code class="language-plaintext highlighter-rouge">\sin (x)</code> \((\sin (x))\) and <code class="language-plaintext highlighter-rouge">\log (x)</code> \((\log (x))\). The idea extends to many other common math functions. These are math operators that will de-italicize the commands and also take care of the appropriate math-mode spacing between characters:</p> <table class="table table-sm"> <tbody> <tr> <td><code class="language-plaintext highlighter-rouge">O(n log n)</code></td> <td>\(O(n log n)\)</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">O(n \log n)</code></td> <td>\(O(n \log n)\)</td> </tr> </tbody> </table> <p>Many times there is a math operator that you need to use repeatedly, but which does not come out of the box. You can define custom math operators with the <code class="language-plaintext highlighter-rouge">\DeclareMathOperator</code> command. For instance, here are some commonly used in probability:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="k">\DeclareMathOperator*</span><span class="p">{</span><span class="k">\Pr</span><span class="p">}{</span><span class="k">\mathbf</span><span class="p">{</span>Pr<span class="p">}}</span>
<span class="k">\DeclareMathOperator*</span><span class="p">{</span><span class="k">\E</span><span class="p">}{</span><span class="k">\mathbf</span><span class="p">{</span>E<span class="p">}}</span>
<span class="k">\DeclareMathOperator*</span><span class="p">{</span><span class="k">\Ex</span><span class="p">}{</span><span class="k">\mathbf</span><span class="p">{</span>E<span class="p">}}</span>
<span class="k">\DeclareMathOperator*</span><span class="p">{</span><span class="k">\Var</span><span class="p">}{</span><span class="k">\mathbf</span><span class="p">{</span>Var<span class="p">}}</span>
<span class="k">\DeclareMathOperator*</span><span class="p">{</span><span class="k">\Cov</span><span class="p">}{</span><span class="k">\mathbf</span><span class="p">{</span>Cov<span class="p">}}</span>
<span class="k">\DeclareMathOperator*</span><span class="p">{</span><span class="k">\stddev</span><span class="p">}{</span><span class="k">\mathbf</span><span class="p">{</span>stddev<span class="p">}}</span></code></pre></figure> <p>Then you can use it as follows:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="k">\Pr</span> <span class="k">\left</span><span class="na">[ X \geq a \right]</span> <span class="k">\leq</span> <span class="k">\frac</span><span class="p">{</span><span class="k">\Ex</span><span class="na">[X]</span><span class="p">}{</span>a<span class="p">}</span></code></pre></figure> \[\Pr \left[ X \geq a \right] \leq \frac{\Ex[X]}{a}\] <h3 id="double-quotes">Double quotes</h3> <p>This is more of a rookie mistake since it’s visually very obvious something is wrong. Double quotes don’t work the way you would expect:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="k">\text</span><span class="p">{</span>"Hello World!"<span class="p">}</span></code></pre></figure> \[\text{"Hello World!"}\] <p>Instead, surround them in double backticks and single quotes, which is supposed to be reminiscent of the directional strokes of an actual double quote. This allows it to know which side to orient the ticks:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex"><span class="k">\text</span><span class="p">{</span>``Hello World!''<span class="p">}</span></code></pre></figure> <figure> <picture> <img src="/assets/img/posts/latex-mistakes/quotes.webp" class="z-depth-1 center" width="100px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> Output of correct usage of quotes </figcaption> </figure> <p>Unfortunately I had to demonstrate this with a screenshot since MathJax only performs math-mode typesetting, but this is an instance of text-mode typesetting.</p> <h3 id="epsilons">Epsilons</h3> <p>This is a common mistake due to laziness. Many times, people use <code class="language-plaintext highlighter-rouge">\epsilon</code> (\(\epsilon\)) when they really meant to write <code class="language-plaintext highlighter-rouge">\varepsilon</code> (\(\varepsilon\)). For instance, in analysis this is usually the case, and therefore writing <code class="language-plaintext highlighter-rouge">\epsilon</code> results in a very uncomfortable read:</p> <figure> <picture> <img src="/assets/img/posts/latex-mistakes/epsilon-wrong.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> Using "\epsilon" looks weird </figcaption> </figure> <p>Using <code class="language-plaintext highlighter-rouge">\varepsilon</code> makes the reader feel much more at peace:</p> <figure> <picture> <img src="/assets/img/posts/latex-mistakes/epsilon-right.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> "\varepsilon" is usually what should be used </figcaption> </figure> <p>Similarly, people tend to get lazy and mix up <code class="language-plaintext highlighter-rouge">\phi, \Phi, \varphi</code> (\(\phi, \Phi, \varphi\)), since they are “about the same”. Details matter!</p> <h3 id="sets-mathbbm-instead-of-mathbb">Sets: <code class="language-plaintext highlighter-rouge">mathbbm</code> Instead Of <code class="language-plaintext highlighter-rouge">mathbb</code></h3> <p>For sets like \(\mathbb{N}\), you should use <code class="language-plaintext highlighter-rouge">\mathbbm{N}</code> (from <code class="language-plaintext highlighter-rouge">bbm</code> package) instead of <code class="language-plaintext highlighter-rouge">mathbb{N}</code> (from <code class="language-plaintext highlighter-rouge">amssymb</code>). See the difference in how the rendering of the set of natural numbers \(\mathbb{N}\) differs, using the same example as the previous section:</p> <figure> <picture> <img src="/assets/img/posts/latex-mistakes/mathbbm.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> Use `mathbbm` instead of `mathbb` </figcaption> </figure> <p><code class="language-plaintext highlighter-rouge">mathbbm</code> causes the symbols to be bolded, which is what you want.</p> <h3 id="dots">Dots</h3> <p><code class="language-plaintext highlighter-rouge">...</code> and <code class="language-plaintext highlighter-rouge">\dots</code> are different. See the difference:</p> <figure class="highlight"><pre><code class="language-latex" data-lang="latex">X = <span class="k">\left</span>( X<span class="p">_</span>1, ..., X<span class="p">_</span>n <span class="k">\right</span>)
X = <span class="k">\left</span>( X<span class="p">_</span>1, <span class="k">\dots</span>, X<span class="p">_</span>n <span class="k">\right</span>)</code></pre></figure> <figure> <picture> <img src="/assets/img/posts/latex-mistakes/dots.webp" class="z-depth-1 center" width="300px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> Output of "..." versus "\dots" </figcaption> </figure> <p>When using “…”, the spacing between each dot, and between the final dot and the comma character is wrong. Always use “\dots”.</p> <h3 id="summation-and-product">Summation and Product</h3> <p>When writing summation or products of terms, use <code class="language-plaintext highlighter-rouge">\sum</code> and <code class="language-plaintext highlighter-rouge">\prod</code> instead of <code class="language-plaintext highlighter-rouge">\Sigma</code> and <code class="language-plaintext highlighter-rouge">\Pi</code>. This helps to handle the relative positioning of the limits properly, and is much more idiomatic to read from the raw script:</p> <table class="table table-bordered table-sm"> <thead> <tr> <th>Raw LaTeX</th> <th>Rendered</th> </tr> </thead> <tbody> <tr> <td><code class="language-plaintext highlighter-rouge">\Sigma_{i=1}^n X_i</code></td> <td>\(\Sigma_{i=1}^n X_i\)</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">\sum_{i=1}^n X_i</code></td> <td>\(\sum_{i=1}^n X_i\)</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">\Pi_{i=1}^n X_i</code></td> <td>\(\Pi_{i=1}^n X_i\)</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">\prod_{i=1}^n X_i</code></td> <td>\(\prod_{i=1}^n X_i\)</td> </tr> </tbody> </table> <h3 id="multiplication">Multiplication</h3> <p>To denote multiplication, use <code class="language-plaintext highlighter-rouge">\cdot</code> or <code class="language-plaintext highlighter-rouge">times</code> instead of <code class="language-plaintext highlighter-rouge">*</code>. See the difference below in the equation:</p> <figure> <picture> <img src="/assets/img/posts/latex-mistakes/multiplication.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> Use "\cdot" looks much better than "*" </figcaption> </figure> <h3 id="mid">Mid</h3> <p>For set builder notation or conditional probability, use <code class="language-plaintext highlighter-rouge">\mid</code> instead of the pipe <code class="language-plaintext highlighter-rouge">|</code>. This helps to handle the spacing between the terms properly:</p> <table class="table table-bordered table-sm"> <thead> <tr> <th>Raw LaTeX</th> <th>Rendered</th> </tr> </thead> <tbody> <tr> <td><code class="language-plaintext highlighter-rouge">p(\mathbf{z}, \mathbf{x}) = p(\mathbf{z}) p(\mathbf{z} | \mathbf{z})</code></td> <td>\(p(\mathbf{z}, \mathbf{x}) = p(\mathbf{z}) p(\mathbf{z} | \mathbf{z})\)</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">p(\mathbf{z}, \mathbf{x}) = p(\mathbf{z}) p(\mathbf{z} \mid \mathbf{z})</code></td> <td>\(p(\mathbf{z}, \mathbf{x}) = p(\mathbf{z}) p(\mathbf{z} \mid \mathbf{z})\)</td> </tr> </tbody> </table> <h3 id="angle-brackets">Angle Brackets</h3> <p>When writing vectors, use the <code class="language-plaintext highlighter-rouge">\langle</code> and <code class="language-plaintext highlighter-rouge">\rangle</code> instead of the keyboard angle brackets:</p> <table class="table table-bordered table-sm"> <thead> <tr> <th>Raw LaTeX</th> <th>Rendered</th> </tr> </thead> <tbody> <tr> <td><code class="language-plaintext highlighter-rouge">&lt;u, v&gt;</code></td> <td>\(&lt;u, v&gt;\)</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">\langle u, v \rangle</code></td> <td>\(\langle u, v \rangle\)</td> </tr> </tbody> </table> <h3 id="labels">Labels</h3> <p>Use <code class="language-plaintext highlighter-rouge">\label</code> to label your figures, equations, tables, and so on, and reference them using <code class="language-plaintext highlighter-rouge">\ref</code>, instead of hardcoding the number. For instance, <code class="language-plaintext highlighter-rouge">\label{fig:myfig}</code> and <code class="language-plaintext highlighter-rouge">\ref{fig:myfig}</code>. Including the type of the object in the tag helps to keep track of what it is and ensures that you are referencing it correctly, i.e making sure you write <code class="language-plaintext highlighter-rouge">Figure \ref{fig:myfig}</code> instead of accidentally saying something like <code class="language-plaintext highlighter-rouge">Table \ref{fig:myfig}</code>.</p> <h2 id="conclusion">Conclusion</h2> <p>That was a lot, and I hope it has been a helpful read! I will continue updating this post in the future as and when I feel like there are other important things which should be noted which I missed.</p> <p>I would like to thank my friend <a href="https://github.com/zack-lee">Zack Lee</a> for reviewing this article and for providing valuable suggestions. I would also like to express my thanks to <a href="http://www.cs.cmu.edu/~odonnell/">Ryan O’Donnell</a>, and my 15-751 A Theorist’s Toolkit TAs <a href="https://jthsieh.github.io/">Tim Hsieh</a> and <a href="https://www.cs.cmu.edu/~eyolcu/">Emre Yolcu</a> for helping me realize a lot of the style-related LaTeX issues mentioned in this post, many of which I made personally in the past.</p>]]></content><author><name>fanpu</name></author><category term="code"/><category term="general"/><summary type="html"><![CDATA[When was the first time you had to use LaTeX? If you are like most people, it was probably suddenly forced upon you during your first math or CS class where you had to start writing proofs, with minimal guidance on how to get started. Unfortunately, this meant that while many people have good operational knowledge of LaTeX, there are still many small mistakes and best practices which are not followed, which are not corrected by TAs as they are either not severe enough to warrant a note, or perhaps even the TAs themselves are not aware of them. In this post, we cover some common mistakes that are made by LaTeX practitioners (even in heavily cited papers), and how to address them.]]></summary></entry></feed>