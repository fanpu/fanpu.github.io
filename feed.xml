<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="https://fanpu.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://fanpu.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-06-06T07:12:53+00:00</updated><id>https://fanpu.io/feed.xml</id><title type="html">blank</title><subtitle>Homepage </subtitle><entry><title type="html">A Unified Framework for High-Dimensional Analysis of M-Estimators with Decomposable Regularizers: A Guided Walkthrough</title><link href="https://fanpu.io/blog/2023/high-dimensional-analysis-of-m-estimators/" rel="alternate" type="text/html" title="A Unified Framework for High-Dimensional Analysis of M-Estimators with Decomposable Regularizers: A Guided Walkthrough"/><published>2023-06-02T00:00:00+00:00</published><updated>2023-06-02T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/high-dimensional-analysis-of-m-estimators</id><content type="html" xml:base="https://fanpu.io/blog/2023/high-dimensional-analysis-of-m-estimators/"><![CDATA[\[\newcommand{\rcal}{\mathcal{R}} \newcommand{\lcal}{\mathcal{L}} \newcommand{\mcal}{\mathcal{M}} \newcommand{\mocal}{\overline{\mathcal{M}}} \newcommand{\mocalp}{\overline{\mathcal{M}}^\perp} \newcommand{\mcalp}{\mathcal{M}^\perp} \newcommand{\sse}{\subseteq} \newcommand{\kl}{\kappa_{\lcal}} \newcommand{\tl}{\tau_{\lcal}} \newcommand{\ts}{\theta^*} \newcommand{\hd}{\widehat{\Delta}} \newcommand{\thatn}{\hat{\theta}_n} \newcommand{\that}{\hat{\theta}} \newcommand{\thatlambda}{\widehat{\theta}_{\lambda_n}} \newcommand{\thatl}{\thatlambda} \newcommand{\rs}{\rcal^*} \newcommand{\ctriplet}{ \C(\mcal, \mocalp; \ts) } \newcommand{\fcal}{\mathcal{F}} \newcommand{\kbb}{\mathbb{K}}\] <p>TODO: on page 16 of the slides, change the 2 to s for the second equation</p> <h1 id="introduction">Introduction</h1> <p>In high-dimensional statistical inference, it is common for the number of parameters \(p\) to be comparable to or greater than the sample size \(n\). However, for an estimator \(\thatn\) to be consistent in such a regime, meaning that it converges to the true parameter \(\theta\), it is necessary to make additional low-dimensional assumptions on the model. Examples of such constraints that have been well-studied include linear regression with sparsity constraints, estimation of structured covariance or inverse covariance matrices, graphical model selection, sparse principal component analysis (PCA), low-rank matrix estimation, matrix decomposition problems and estimation of sparse additive nonparametric models \cite{paper}.</p> <p>In recent years, there has been a flurry of work on each of these individual specific cases. However, the authors of the paper in discussion poses the question of whether there is a way of unifying these analysis to understand all of such estimators in a common framework, and answers it in the affirmative. They showed that it is possible to bound the squared difference between any regularized \(M\)-estimator and its true parameter by (1) the decomposability of the regularization function, and (2) restricted strong convexity of the loss function. We will call this the “main theorem” in the remainder of the blog post, and this is referred to as ``Theorem 1’’ in \(\cite{paper}\).</p> <p>In the remainder of the paper, we will develop the tools necessary to deeply understand and prove the result. Notation used will be consistent with the original paper for expositional clarity.</p> <h1 id="background">Background</h1> <p>In this section, we develop some of the necessary background and notation to build up to the proof.</p> <h2 id="regularized-m-estimators">Regularized \(M\)-estimators</h2> <p>\(M\)-estimators (\(M\) for ``maximum likelihood-type’’) are solutions that minimize the sum of loss functions \(\rho\): \begin{align} \that \in \argmin_\theta \sum_{i=1}^n \rho(x_i, \theta). \end{align}</p> <p>If we add a regularization term \(\rcal\) to penalize complexity of the model, scaled by weights \(\lambda\), the method is known as a regularized \(M\)-estimator: \begin{align} \that \in \argmin_\theta \sum_{i=1}^n \rho(x_i, \theta) + \lambda \rcal(\theta). \end{align}</p> <div class="example"> <div class="theorem-title">Example (Lasso Program) </div> <div class="theorem-contents"> The Lasso program is an example of a regularized \( M \)-estimator, where a \( \ell_1 \) regurization penalty is applied: $$ \that \in \argmin_{\theta \in \R^d} \left\{ \frac{1}{2n} \| y - \bX \theta \|_2^2 + \lambda_n \| \theta \|_1 \right\}. $$ </div> </div> <h2 id="dual-norms">Dual Norms</h2> <div class="definition"> <div class="theorem-title">Definition (Dual Norms) </div> <div class="theorem-contents"> Let \(\rcal\) be a norm induced by an inner product \(\dotprod{\cdot}{\cdot}\). Then the dual norm of \(\rcal\) is defined as $$ \rs(v) \coloneqq \sup_{u \in \R^p \setminus \left\{ 0 \right\}} \frac{ \dotprod{u}{v} }{\rcal (u)} = \sup_{\rcal(u) \leq 1} \dotprod{u}{v}. $$ </div> </div> <div class="example"> <div class="theorem-title">Example (\(\ell_1\) and \(\ell_\infty\) norms are dual norms) </div> <div class="theorem-contents"> We will show that the dual of the \( \ell_1 \) norm is the \( \ell_\infty \) norm. Well, to see that \( \rs(v) \leq \| v \|_\infty \), observe that \begin{align*} \rs(v) &amp; = \sup_{\| u \|_1 \leq 1} \dotprod{u}{v} \\ &amp; = \sup_{\| u \|_1 \leq 1} \sum_{k=1}^p | u_k | | v_k | \\ &amp; \leq \sup_{\| u \|_1 \leq 1} \left( \sum_{k=1}^p | u_k | \right) \| v \|_\infty \\ &amp; = | v |_\infty \tag{since \( \| u \|_1 \leq 1 \) }. \end{align*} For the opposite direction, \begin{align*} \sup_{\| u \|_1 \leq 1} \dotprod{u}{v} &amp; = \sup_{\| u \|_1 \leq 1} \sum_{k=1}^p |u_k| |v_k| \\ &amp; \geq 1 \cdot |v_j| \tag{ set \( j = \argmax_j |v_j|, u = \be_j \) } \\ &amp; = \| v \|_\infty, \end{align*} hence we have equality. </div> </div> <h2 id="subspace-compatibility-constant">Subspace Compatibility Constant</h2> <p>The subspace compatibility constant measures how much the regularizer \(\rcal\) can change with respect to the error norm \(\| \cdot \|\) restricted to the subspace \(\mcal\). This concept will show up later in showing that the restricted strong convexity condition will hold with certain parameters.</p> <p>The subspace compatibility constant is defined as follows:</p> <div class="definition"> <div class="theorem-title">Definition (Subspace Compatibility Constant) </div> <div class="theorem-contents"> For any subspace \( \mcal \) of \( \R^p \), the \textit{subspace compatibility constant} with respect to the pair \( (\rcal, \| \cdot \|) \) is given by \begin{align} \varPsi (\mcal) \coloneqq \sup_{u \in \mcal \setminus \left\{ 0 \right\}} \frac{\rcal(u)}{\| u \|}. \end{align} </div> </div> <p>It can be thought of as the Lipschitz constant of the regularizer with respect to the error norm restricted to values in \(\mcal\), by considering the point where it can vary the most.</p> <h2 id="projections-todo-check-label-labelsecprojection">Projections [TODO check label] \label{sec:projection}</h2> <p>Define the projection operator \begin{align} \Pi_{\mcal}(u) \coloneqq \argmin_{v \in \mcal} | u - v | \end{align} to be the projection of \(u\) onto the subspace \(\mcal\). For notational brevity, we will use the shorthand \(u_{\mcal} = \Pi_{\mcal}(u)\).</p> <p>One property of the projection operator is that it is non-expansive, meaning that \begin{align} | \Pi(u) - \Pi(v) | \leq | u - v | \label{eq:non-expansive} \end{align} for some error norm \(\| \cdot \|\). In other words, it has Lipschitz constant 1.</p> <h1 id="problem-formulation">Problem Formulation</h1> <p>In our setup, we define the following quantities:</p> <ul> <li>\(Z_1^n \coloneqq \left\{ Z_1, \cdots, Z_n \right\}\) \(n\) i.i.d observations drawn from distribution \(\mathbb{P}\) with some parameter \(\theta^*\),</li> <li>\(\mathcal{L}: \mathbb{R}^p \times \mathcal{Z}^n \to \mathbb{R}\) a convex and differentiable loss function, such that \(\mathcal{L}(\theta; Z_1^n)\) returns the loss of \(\theta\) on observations \(Z_1^n\),</li> <li>\(\lambda_n &gt; 0\): a user-defined regularization penalty,</li> <li>\(\mathcal{R} : \R^p \to \R_+\) a norm-based regularizer.</li> </ul> <p>The purpose of the regularized \(M\)-estimator is then to solve for the convex optimization problem</p> \[\begin{align} \label{eq:opt} \widehat{\theta}_{\lambda_n} \in \argmin_{\theta \in \R^p} \left\{ \mathcal{L}(\theta; Z_1^n) + \lambda_n \mathcal{R} (\theta) \right\}, \end{align}\] <p>and we are interested in deriving bounds on \(\begin{align} \| \thatlambda - \theta^* \| \end{align}\) for some error norm \(\| \cdot \|\) induced by an inner product \(\langle \cdot, \cdot \rangle\) in \(\R^p\).</p> <h1 id="decomposability-of-the-regularizer-mathcalr">Decomposability of the Regularizer \(\mathcal{R}\)</h1> <p>The first key property in the result is decomposability of our norm-based regularizer \(\rcal\). Working in the ambient \(\R^p\), define \(\mcal \sse \R^p\) to be the model subspace that captures the constraints of the model that we are working with (i.e \(k\)-sparse vectors), and denote \(\mocal\) to be its closure, i.e the union of \(\mcal\) and all of its limit points. In addition, denote \(\mocalp\) to be the orthogonal complement of \(\mocal\), namely</p> \[\begin{align} \mocalp \coloneqq \left\{ v \in \R^p \mid \langle u, v \rangle = 0 \text{ for all \( u \in \mocal \) } \right\}. \end{align}\] <p>We call this the perturbation subspace, as they represent perturbations away from the model subspace \(\mocal\). The reason why we need to consider \(\mocal\) instead of \(\mcal\) is because there are some special cases of low-rank matrices and nuclear norms where it could be possible that \(\mcal\) is strictly contained in \(\mocal\).</p> <p>Now we can introduce the property of decomposability:</p> <div class="definition"> <div class="theorem-title">Definition (Regularizer Decomposability) </div> <div class="theorem-contents"> Given a pair of subspaces \( \mcal \sse \mocal \), a norm-based regularizer \( \rcal \) is \textit{decomposable} with respect to \( (\mocal, \mocalp) \) if \begin{align} \rcal(\theta + \gamma) = \rcal(\theta) + \rcal(\gamma) \end{align} for all \( \theta \in \mcal \) and \( \gamma \in \mocalp \). </div> </div> <p>Since \(\rcal\) is a norm-based regularizer, by the triangle inequality property of norms we know that always \begin{align} \rcal(\theta + \gamma) \leq \rcal(\theta) + \rcal(\gamma), \end{align} and hence this is a stronger condition which requires tightness in the inequality when we are specifically considering elements in the closure of the model subspace and its orthogonal complement.</p> <p>Decomposability of the regularizer is important as it allows us to penalize deviations \(\gamma\) away from the model subspace in \(\mcal\) to the maximum extent possible. We are usually interested to find model subspaces that are small, with a large orthogonal complement. We will see in the main theorem that when this is the case, we will obtain better rates for estimating \(\theta^*\).</p> <p>There are many natural contexts that admit regularizers which are decomposable with respect to subspaces, and the following example highlights one such case.</p> <div class="example"> <div class="theorem-title">Example (\( s \)-sparse Vectors) </div> <div class="theorem-contents"> Consider estimating the parameters \( \that \) with \( \ell_1 \)-regularization in \( \R^p \) where we assume that the model is \( s \)-sparse. Then for any set \( S \sse [p] \) where \( |S| = s \), we can define our model subspace \( \mcal \) as \[ \begin{align} \mcal(S) \coloneqq \left\{ \theta \in \R^p \mid \theta_j = 0 \quad \forall j \not\in S \right\}, \end{align} \] i.e all the vectors in \( \R^p \) that only has support in \( S \). In this case, \( \mcal = \mocal \), and our orthogonal complement \( \mocalp \) is just \[ \begin{align} \mocalp(S) \coloneqq \left\{ \gamma \in \R^p \mid \gamma_j = 0 \quad \forall j \in S \right\}. \end{align} \] Then this setup is decomposable: \[ \begin{align} \| \theta + \gamma \|_1 = \| \theta_S + \gamma_{S^c} \|_1 = \| \theta_S \|_1 + \| \gamma_{S^c} \| = \| \theta \|_1 + \| \gamma \|_1 \end{align} \] by the Pythagorean theorem. </div> </div> <h2 id="role-of-decomposability">Role of Decomposability</h2> <figure> <picture> <img src="/assets/img/posts/high-dimensional-analysis-of-m-estimators/c_illust.png" class="z-depth-1 center" width="500px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> A visualization of \( \ctriplet \). The shaded area represents the set \( \ctriplet \), i.e all values of \( \theta \) that satisfies the inequality in Equation \ref{eq:c}. </figcaption> </figure> <p>Decomposability is important because it allows us to bound the error of the estimator. This is given in the following result, which is known as Lemma 1 in \cite{paper}:</p> <div class="lemma"> <div class="theorem-title">Lemma (Lemma 1 in \cite{paper}) </div> <div class="theorem-contents"> Suppose that \( \lcal \) is a convex and differentiable function, and consider any optimal solution \( \that \) to the optimization problem with a strictly positive regularization parameter satisfying $$ \begin{align} \lambda_n \geq 2 \rcal^* (\nabla \lcal (\ts; Z_1^n)). \end{align} $$ Then for any pair \( (\mcal, \mocalp) \) over which \( \rcal \) is decomposable, the error \( \hd = \thatlambda - \ts \) belongs to the set $$ \begin{align} \label{eq:c} \C(\mcal, \mocalp; \ts) \coloneqq \left\{ \Delta \in \R^p \mid \rcal(\Delta_{\mocalp}) \leq 3 \rcal (\Delta_{\mocal}) + 4 \rcal (\ts_{\mcalp}) \right\}. \end{align} $$ </div> </div> <p>Recall from Section \ref{sec:projection} that \(\Delta_{\mocalp}\) represents the projection of \(\Delta\) onto \(\mocalp\), and similarly for the other quantities. Due to space constraints we are unable to prove Lemma \ref{lemma:1} in this survey, but it is very important in the formulation of restricted strong convexity, and in proving Theorem \ref{thm:1}.</p> <p>Figure \ref{fig:cone} provides a visualization of \(\ctriplet\) in \(\R^3\) in the sparse vectors setting. In this case, \(S = \left\{ 3 \right\}\) with \(|S|=1\), and so the projection of \(\Delta\) onto the model subspace only has non-zero values on the third coordinate, and its orthogonal complement is where the third coordinate is zero. Formally,</p> \[\begin{align} \mcal(S) = \mocal(S) &amp; = \left\{ \Delta \in \R^3 \mid \Delta_1 = \Delta_2 = 0 \right\}, \\ \mocalp(S) &amp; = \left\{ \Delta \in \R^3 \mid \Delta_3 = 0 \right\}. \end{align}\] <p>The vertical axis of Figure \ref{fig:cone} denotes the third coordinate, and the horizontal plane denotes the first two coordinates. The shaded area represents the set \(\ctriplet\), i.e all values of \(\theta\) that satisfies the inequality in Equation \ref{eq:c}.</p> <p>Figure \ref{fig:cone}(a) shows the special case when \(\ts \in \mcal\). In this scenario, \(\rcal (\ts_{\mcalp}) = 0\), and so</p> \[\begin{align*} \C(\mcal, \mocalp; \ts) = \left\{ \Delta \in \R^p \mid \rcal(\Delta_{\mocalp}) \leq 3 \rcal (\Delta_{\mocal}) \right\}, \end{align*}\] <p>which is a cone.</p> <p>However, in the general setting where \(\ts \not\in \mcal\), then \(\rcal (\ts_{\mcalp}) &gt; 0\), and the set \(\ctriplet\) will become a star-shaped set like what is shown in Figure \ref{fig:cone}(b).</p> <h2 id="restricted-strong-convexity-rsc-of-the-loss-function">Restricted Strong Convexity (RSC) of the Loss Function</h2> <figure> <picture> <img src="/assets/img/posts/high-dimensional-analysis-of-m-estimators/curvature.png" class="z-depth-1 center" width="500px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"> An illustration of the role of curvature in guaranteeing that \( \hd = \thatlambda - \ts \) is small when \( \lcal(\thatlambda) - \lcal(\ts) \) is small. </figcaption> </figure> <p>In a classical setting, as the number of samples \(n\) increases, the difference in loss \(d \lcal = |\lcal(\thatlambda) - \lcal(\ts)|\) will converge to zero. However, the convergence in loss by itself is insufficient to also ensure the convergence in parameters, \(\hd = \thatlambda - \ts\). Instead, it also depends on the curvature of the loss function \(\lcal\).</p> <p>Figure \ref{fig:curvature} illustrates the importance of curvature. In Figure \ref{fig:curvature}(a), \(\lcal\) has high curvature, and so having a small \(d\lcal\) also implies a small \(\hd\). On the other hand, in Figure \ref{fig:curvature}(b), \(\lcal\) has an almost flat landscape near \(\thatlambda\), and hence even when \(d \lcal\) is small, \(\hd\) could still be large.</p> <p>Consider performing a Taylor expansion of \(\lcal\) around \(\ts\):</p> \[\begin{align} \lcal(\ts + \Delta) &amp; = \lcal(\ts) + \dotprod{\nabla \lcal(\ts)}{\Delta} + \underbrace{\frac{1}{2} \Delta^T \nabla^2 \lcal(\ts) \Delta + \dots}_{\delta \lcal(\Delta, \ts)}. \end{align}\] <p>Then we can rearrange and write the error of the first-order Taylor series expansion at \(\ts\) as</p> \[\begin{align*} \delta \lcal(\Delta, \ts) = \lcal(\ts + \Delta) - \lcal(\ts) - \dotprod{\nabla \lcal(\ts)}{\Delta}. \end{align*}\] <p>The first-order Taylor approximation is a linear approximation, and hence the error \(\delta \lcal(\Delta, \ts)\), which is dominated by the quadratic term, can capture the curvature about \(\ts\).</p> <p>As such, one way to show that \(\lcal\) has good curvature about \(\ts\) is to show that \(\delta \lcal(\Delta, \ts) \geq \kappa \|\Delta \|^2\) holds for all \(\Delta\) in a neighborhood of \(\ts\). This is because we are enforcing a lower bound on its quadratic growth.</p> <p>This leads us to the definition of restricted strong convexity:</p> <div class="definition"> <div class="theorem-title">Definition (Restricted Strong Convexity) </div> <div class="theorem-contents"> The loss function satisfies a \textit{restricted strong convexity} (RSC) condition with curvature \( \kl &gt; 0 \) and tolerance function \( \tl \) if \begin{align} \delta \lcal(\Delta, \ts) \geq \kl \| \Delta \|^2 - \tl^2(\ts) \end{align} for all \( \Delta \in \ctriplet \). </div> </div> <p>We only need to consider error terms \(\Delta \in \ctriplet\), since Lemma \ref{lemma:1} guarantees us that the error term will only lie in that set.</p> <p>In many statistical models, restricted strong convexity holds with \(\tl = 0\), however it is required in more general settings, such as generalized linear models.</p> <h2 id="proof-of-theorem-1-todo-check-labelsecthm1-proof">Proof of Theorem 1 [TODO check] \label{sec:thm1-proof}</h2> <p>We can now state and prove the main result of the paper. This will hold under the decomposability of the regularizer (G1), and the restricted strong convexity of the loss function (G2).</p> <ul> <li> <p><strong>(G1)</strong> The regularizer \(\rcal\) is a norm and is decomposable with respect to the subspace pair \((\mcal, \mocalp)\), where \(\mcal \sse \mocalp\).</p> </li> <li> <p><strong>(G2)</strong> The loss function \(\lcal\) is convex and differentiable, and satisfies restricted strong convexity with curvature \(\kl\) and tolerance \(\tl\).</p> </li> </ul> <div class="theorem"> <div class="theorem-title">Theorem 1 in (Negahban et al., 2009) (Bounds for General Models) </div> <div class="theorem-contents"> Under conditions (G1) and (G2), consider the convex optimization problem (\ref{eq:opt}) based on a strictly positive positive regularization constant \( \lambda_n \geq 2 \rs (\nabla \lcal (\ts)) \). Then any optimal solution \( \thatlambda \) to the convex program (\ref{eq:opt}) satisfies the bound \begin{align} \| \thatlambda - \ts \|^2 \leq 9 \frac{\lambda_n^2}{\kl^2} \Psi^2(\mocal) + \frac{\lambda_n}{\kl} \left( 2 \tl^2 (\ts) + 4 \rcal (\ts_{\mcal^{\perp}}) \right). \end{align} </div> </div> <p>We will rely on the following lemmas that will be stated without proof due to space constraints:</p> <div class="lemma"> <div class="theorem-title">Lemma 3 in (Negahban et al., 2009) (Deviation Inequalities) </div> <div class="theorem-contents"> For any decomposable regularizer and \( p \)-dimensional vectors \( \ts \) and \( \Delta \), we have \begin{align} \rcal(\ts + \Delta) - \rcal(\ts) \geq \rcal(\Delta_{\mocalp}) - \rcal(\Delta_{\mocal}) - 2 \rcal(\ts_{\mcal^{\perp}}). \end{align} Moreover, as long as \( \lambda_n \geq 2 \rs (\nabla \lcal(\ts)) \) and \( \lcal \) is convex, we have \begin{align} \lcal(\ts + \Delta) - \lcal(\ts) \geq - \frac{\lambda_n}{2} [\rcal(\Delta_{\mocal}) + \rcal(\Delta_{\mocalp})]. \end{align} </div> </div> <div class="lemma"> <div class="theorem-title">Lemma 4 in (Negahban et al., 2009) </div> <div class="theorem-contents"> If \( \fcal(\Delta) &gt; 0 \) for all vectors \( \Delta \in \mathbb{K}(\delta) \), then \( \| \hd \| \leq \delta \). </div> </div> <p>Note that this was similar to our previous analysis on restricted strong convexity where we only really need to consider error terms restricted to ( \ctriplet ) due to Lemma \ref{lemma:1}. Therefore, it suffices to show ( \fcal(\Delta) &gt; 0 ) to obtain a bound on ( | \hd | = | \thatlambda - \ts| ), which completes the proof of Theorem 1.</p> <p>Define \(\fcal : \R^p \to \R\) by</p> \[\begin{align} \fcal(\Delta) \coloneqq \lcal(\ts + \Delta) - \lcal(\ts) + \lambda_n \left\{ \rcal(\ts + \Delta) - \rcal(\ts) \right\}, \end{align}\] <p>and define the set</p> \[\begin{align} \mathbb{K}(\delta) \coloneqq \ctriplet \cap \left\{ \| \Delta \| = \delta \right\}. \end{align}\] <p>Take any \(\Delta \in \kbb\). Then</p> \[\begin{align} \fcal(\Delta) = &amp; \lcal(\ts + \Delta) - \lcal(\ts) + \lambda_n \left\{ \rcal(\ts + \Delta) - \rcal(\ts) \right\} \tag{by definition} \\ \geq &amp; \langle \nabla \lcal (\ts), \Delta \rangle + \kl \| \Delta \|^2 - \tl^2(\ts) + \lambda_n \left\{ \rcal(\ts + \Delta) - \rcal(\ts) \right\} \\ &amp; \qquad \text{(by restricted strong convexity: \(\delta \lcal(\Delta, \ts) \geq \kl \| \Delta \|^2 - \tl^2(\ts)\),} \\ &amp; \qquad \text{ and \( \delta \lcal(\Delta, \ts) = \lcal(\ts + \Delta) - \lcal(\ts) - \dotprod{\nabla \lcal(\ts)}{\Delta} \) ) } \\ \geq &amp; \langle \nabla \lcal (\ts), \Delta \rangle + \kl \| \Delta \|^2 - \tl^2(\ts) + \lambda_n \left\{ \rcal(\Delta_{\mocalp}) - \rcal(\Delta_{\mocal}) - 2 \rcal(\ts_{\mcal^{\perp}}) \right\} \\ &amp; \qquad \text{(by Lemma 3 in \cite{paper})}. \label{thm-deriv:1} \end{align}\] <p>We lower bound the first term as \(\langle \nabla \lcal (\ts), \Delta \rangle \geq - \frac{\lambda_n}{2} \rcal(\Delta)\):</p> \[\begin{align} | \langle \nabla \lcal (\ts), \Delta \rangle | \leq &amp; \rs(\nabla \lcal(\ts)) \rcal(\Delta) &amp; \text{(Cauchy-Schwarz using dual norms \( \rcal \) and \( \rs \))} \\ \leq &amp; \frac{\lambda_n}{2} \rcal(\Delta) &amp; \text{(Theorem \ref{thm:1} assumption: \( \lambda_n \geq 2 \rs (\nabla \lcal(\ts)) \))}, \end{align}\] <p>and hence,</p> \[\begin{align} \langle \nabla \lcal (\ts), \Delta \rangle \geq &amp; - \frac{\lambda_n}{2} \rcal(\Delta). \end{align}\] <p>So applying to (\ref{thm-deriv:1}),</p> \[\begin{align} \fcal(\Delta) \geq &amp; \kl \| \Delta \|^2 - \tl^2(\ts) + \lambda_n \left\{ \rcal(\Delta_{\mocalp}) - \rcal(\Delta_{\mocal}) - 2 \rcal(\ts_{\mcal^{\perp}}) \right\} - \frac{\lambda_n}{2} \rcal(\Delta) \\ \geq &amp; \kl \| \Delta \|^2 - \tl^2(\ts) + \lambda_n \left\{ \rcal(\Delta_{\mocalp}) - \rcal(\Delta_{\mocal}) - 2 \rcal(\ts_{\mcal^{\perp}}) \right\} - \frac{\lambda_n}{2} (\rcal(\Delta_{\mocalp}) + \rcal(\Delta_{\mocal})) \\ &amp; \qquad \text{(Triangle inequality: \( \rcal(\Delta) \leq \rcal(\Delta_{\mocalp}) + \rcal(\Delta_{\mocal}) \))} \\ = &amp; \kl \| \Delta \|^2 - \tl^2(\ts) + \lambda_n \left\{ \frac{1}{2}\rcal(\Delta_{\mocalp}) - \frac{3}{2}\rcal(\Delta_{\mocal}) - 2 \rcal(\ts_{\mcal^{\perp}}) \right\} \\ &amp; \qquad \text{(Moving terms in)} \\ \geq &amp; \kl \| \Delta \|^2 - \tl^2(\ts) + \lambda_n \left\{ - \frac{3}{2}\rcal(\Delta_{\mocal}) - 2 \rcal(\ts_{\mcal^{\perp}}) \right\} \\ &amp; \qquad \text{(Norms always non-negative)} \\ = &amp; \kl \| \Delta \|^2 - \tl^2(\ts) - \frac{\lambda_n }{2} \left\{ 3 \rcal(\Delta_{\mocal}) + 4 \rcal(\ts_{\mcal^{\perp}}) \right\} \label{eq:r-delta-lb} . \end{align}\] <p>To bound the term \(\rcal(\Delta_{\mocal})\), recall the definition of subspace compatibility:</p> \[\begin{align} \varPsi (\mcal) \coloneqq \sup_{u \in \mcal \setminus \left\{ 0 \right\}} \frac{\rcal(u)}{\| u \|}, \label{eq:r-delta-ub} \end{align}\] <p>and hence</p> \[\begin{align} \rcal(\Delta_{\mocal}) \leq \varPsi(\mocal) \| \Delta_{\mocal} \|. \end{align}\] <p>To upper bound \(\| \Delta_{\mocal} \|\), we have</p> \[\begin{align} \| \Delta_{\mocal} \| &amp; = \| \Pi_{\mocal} (\Delta) - \Pi_{\mocal}(0) \| &amp; \text{(Since \(0 \in \mocal \), \( \Pi_{\mocal}(0) = 0 \)) } \\ &amp; \leq \| \Delta - 0 \| &amp; \text{(Projection operator is non-expansive, see Equation \ref{eq:non-expansive})} \\ &amp; = \| \Delta \|, \end{align}\] <p>which substituting into Equation (\ref{eq:r-delta-ub}) gives</p> \[\begin{align} \rcal(\Delta_{\mocal}) \leq \varPsi(\mocal) \| \Delta \|. \end{align}\] <p>Now we can use this result to lower bound Equation \ref{eq:r-delta-lb}:</p> \[\begin{align} \fcal (\Delta) \geq &amp; \kl \| \Delta \|^2 - \tl^2(\ts) - \frac{\lambda_n }{2} \left\{ 3 \varPsi(\mocal) \| \Delta \| + 4 \rcal(\ts_{\mcal^{\perp}}) \right\}. \label{eq:strict-psd} \end{align}\] <p>The RHS of the inequality in Equation \ref{eq:strict-psd} has a strictly positive definite quadratic form in \(\| \Delta \|\), and hence by taking \(\| \Delta \|\) large, it will be strictly positive. To find such a sufficiently large \(\| \Delta \|\), write</p> \[\begin{align} a &amp; = \kl, \\ b &amp; = -\frac{3\lambda_n}{2} \varPsi (\mocal), \\ c &amp; = -\tau_{\lcal}^2 (\ts) - 2 \lambda_n \rcal(\ts_{\mcalp}), \\ \end{align}\] <p>such that we have</p> \[\begin{align} \fcal (\Delta) &amp; \geq a \| \Delta \|^2 + b \| \Delta \| + c. \end{align}\] <p>Then the square of the rightmost intercept is given by the squared quadratic formula</p> \[\begin{align} \| \Delta \|^2 &amp; = \left( \frac{-b + \sqrt{b^2 - 4ac}}{2a} \right)^2 \\ &amp; = \frac{b^2 - 2b\sqrt{b^2 - 4ac} + b^2 - 4ac}{4a^2} \\ &amp; = \frac{b^2 - 2ac - b\sqrt{b^2 - 4ac}}{2a^2} \\ &amp; \leq \frac{b^2 - 2ac}{2a^2} \label{eq:coarse-bound} \\ &amp; = \frac{b^2}{2a^2} - \frac{c}{a} \\ &amp; = \frac{9 \lambda_n^2 \varPsi (\mocal)}{8 \kl^2} + \frac{ \tau_{\lcal}^2 (\ts) + 2 \lambda_n \rcal(\ts_{\mcalp}) }{\kl} &amp; \text{(Substituting in \(a, b, c\))} \\ &amp; \leq \frac{9 \lambda_n^2 \varPsi (\mocal)}{\kl^2} + \frac{1}{\kl} \left\{ 2\tau_{\lcal}^2 (\ts) + 4 \lambda_n \rcal(\ts_{\mcalp}) \right\}. \end{align}\] <p>In \cite{paper}, they were able to show an upper bound of</p> \[\begin{align} \| \Delta \|^2 &amp; \leq \frac{9 \lambda_n^2 \varPsi (\mocal)}{\kl^2} + \frac{\lambda_n}{\kl} \left\{ 2\tau_{\lcal}^2 (\ts) + 4 \rcal(\ts_{\mcalp}) \right\}, \label{eq:ub} \end{align}\] <p>but I am unsure about how they managed to place the \(\lambda_n\) term on the \(\tl^2(\ts)\) term. It may be due to an overly coarse bound on my end applied in Equation \ref{eq:coarse-bound}, but it is still unclear to me how the \(\lambda_n\) term can be produced.</p> <p>With Equation \ref{eq:ub}, we can hence apply Lemma 4 in \cite{paper} to obtain the desired result that</p> \[\begin{align} \| \thatlambda - \ts \|^2 \leq 9 \frac{\lambda_n^2}{\kl^2} \Psi^2(\mocal) + \frac{\lambda_n}{\kl} \left( 2 \tl^2 (\ts) + 4 \rcal (\ts_{\mcal^{\perp}}) \right). \end{align}\] <p>This concludes the proof.</p> <h1 id="conclusion">Conclusion</h1> <p>In the proof of Theorem \ref{thm:1} in Section \ref{sec:thm1-proof}, we saw how the bound is derived from the two key ingredients of the decomposability of the regularizer, and restricted strong convexity of the loss function. The decomposability of the regularizer allowed us to ensure that the error vector \(\hd\) will stay in the set \(\ctriplet\). This condition is then required in Lemma 4 of \cite{paper}, which allows us to bound \(\| \hd \|\) given that \(\fcal(\Delta) &gt; 0\). In one of the steps where we were lower bounding \(\fcal(\Delta)\) in the proof, we made use of the properties of restricted strong convexity.</p> <p>Theorem \ref{thm:1} provides a family of bounds for each decomposable regularizer under the choice of \((\mcal, \mocalp)\). The authors of \cite{paper} were able to use Theorem \ref{thm:1} to rederive both existing known results, and also derive new results on low-rank matrix estimation using the nuclear norm, minimax-optimal rates for noisy matrix completion, and noisy matrix decomposition. The reader is encouraged to refer to \cite{paper} for more details on the large number of corrollaries of Theorem \ref{thm:1}.</p> <h1 id="slides">Slides</h1> <p>A condensed slide deck that introduces the key ideas of the post, but without any of the proofs is provided below.</p> <style>.pdf-embed-wrap-7a894e63-7f08-4975-b1f6-bb3b2cadfe2e{display:flex;flex-direction:column;width:100%;height:650px}.pdf-embed-container-7a894e63-7f08-4975-b1f6-bb3b2cadfe2e{height:100%}.pdf-embed-container-7a894e63-7f08-4975-b1f6-bb3b2cadfe2e iframe{width:100%;height:100%}</style> <div class="pdf-embed-wrap-7a894e63-7f08-4975-b1f6-bb3b2cadfe2e"> <div class="pdf-embed-container-7a894e63-7f08-4975-b1f6-bb3b2cadfe2e"> <iframe src="/assets/presentations/A-Unified-Framework-For-High-Dimensional-Analysis-Of-M-Estimators.pdf" frameborder="0" allowfullscreen=""></iframe> </div> </div> <h1 id="citations">Citations</h1> <ul> <li>Negahban, S., Yu, B., Wainwright, M. J., and Ravikumar, P. <a href="https://proceedings.neurips.cc/paper_files/paper/2009/file/dc58e3a306451c9d670adcd37004f48f-Paper.pdf">A unified framework for high-dimensional analysis of m-estimators with decomposable regularizers</a>. In Bengio, Y., Schuurmans, D., Lafferty, J., Williams, C., and Culotta, A. (eds.), Advances in Neural Information Processing Systems, volume 22. Curran Associates, Inc., 2009. URL https://proceedings.neurips.cc/paper_files/paper/2009/file/dc58e3a306451c9d670adcd37004f48f-Paper.pdf.</li> </ul>]]></content><author><name>fanpu</name></author><category term="machine-learning"/><category term="statistics"/><summary type="html"><![CDATA[This post provides a gentle walkthrough of the paper ``A Unified Framework for High-Dimensional Analysis of \( M \)-Estimators with Decomposable Regularizers'' by Negahban, Ravikumar, Wainwright, and Yu. The main result of the paper proves that the \( \ell_2 \) difference between any regularized \(M\)-estimator and its true parameter can be bounded if the regularization function is decomposabile, and the loss function satisfies restricted strong convexity. The goal of this blog post is to provide the sufficient background for understanding the proof of this result, followed by a walkthrough of the proof itself.]]></summary></entry><entry><title type="html">Score-Based Diffusion Models</title><link href="https://fanpu.io/blog/2023/score-based-diffusion-models/" rel="alternate" type="text/html" title="Score-Based Diffusion Models"/><published>2023-06-02T00:00:00+00:00</published><updated>2023-06-02T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/score-based-diffusion-models</id><content type="html" xml:base="https://fanpu.io/blog/2023/score-based-diffusion-models/"><![CDATA[\[\newcommand{\pdata}{p_{\text{data}}(\bx)} \newcommand{\st}{\mathbf{s}_\mathbf{\theta}} \newcommand{\xt}{\tilde{\bx}} \newcommand{\stx}{\mathbf{s}_\mathbf{\theta}(\bx)} \newcommand{\sdx}{\mathbf{s}_\text{data}(\bx)} \newcommand{\stxt}{\mathbf{s}_\mathbf{\theta}(\xt, \sigma)} \newcommand{\pv}{p_{\bv}} \newcommand{\score}{\nabla_\bx \log \pdata} \newcommand{\bov}{\bar{\beta}}\] <h1 id="introduction">Introduction</h1> <p>There has recently been a flurry of work in score-based diffusion models as part of the broader area of generative models. This is due to the recent success of such score-based methods, which has achieved results comparable to the state-of-the-art of generative adversarial networks (GANs).</p> <p>Past techniques in generative modeling have either relied on the approximation of the partition function of the probability density, or the combination of an implicit network representation of the probability density and adversarial training. The former suffers from having to either constrain the model to make the partition function tractable, or otherwise relies on approximations with surrogate losses that may be inaccurate, and the latter suffers from training instability and mode collapse.</p> <p>Score-based diffusion models try to address the cons of both approaches, and instead, use score-matching to learn a model of the gradient of the log of the probability density function. This allows it to avoid computing the partition function completely.</p> <p>One of the first such approaches that rely on using score-matching to perform generative modeling does so by generating new samples via Langevin dynamics \cite{generative-modeling-by-estimating-gradients}. A key observation is that naively applying score-matching is that the model of score function will be inaccurate in areas of low density with respect to the data distribution, which results in improper Langevin dynamics in low-density areas. The solution that was proposed is the injection of noise into the data, which provides additional training signal and increases the dimensionality of the data.</p> <p>The next major step introduced in \cite{generative-modeling-sde} is to perturb the data using a diffusion process which is a form of a stochastic differential equation (SDEs). The SDE is then reversed using annealed Langevin dynamics in order to recover the generative process, where the reversal process makes use of score matching.</p> <p>Other recent refinements that have been proposed include re-casting the objective as a Schr"{o}dinger bridge problem, which is an entropy-regularized optimal transport problem. The advantage of this approach is that it allows for fewer diffusion steps to be taken during the generative process.</p> <h1 id="survey-of-results">Survey of Results</h1> <p>We will be primarily focusing on the paper ``Generative Modeling by Estimating Gradients of the Data Distribution’’ \cite{generative-modeling-by-estimating-gradients}.</p> <p>In this section, we provide the necessary background, provide derivations for important results, and explain the key ideas of score matching for diffusion models as proposed in the papers.</p> <h2 id="motivation-for-score-matching">Motivation for Score Matching</h2> <h3 id="limitations-of-likelihood-based-approaches">Limitations of Likelihood-Based Approaches</h3> <p>Score matching is motivated by the limitations of likelihood-based methods. In likelihood-based methods, we use a parameterized model \(f_\theta(\bx) \in \mathbb{R}\) and attempt it to recover the parameters \(\theta\) that best explains the observed data. For instance, in energy-based models, the probability mass function \(p_\theta(\bx)\) would be given as \begin{align} p_\theta(\bx) = \frac{\exp(-f_\theta(\bx))}{Z_\theta}, \end{align} where \(Z_\theta\) is the normalizing constant that causes the distribution to integrate to 1, i.e \begin{align} Z_\theta = \int \exp(-f_\theta(\bx)) \, d \bx. \end{align} The goal then is to maximize the log likelihood of the observed data \(\{\bx_i\}_i^N\), given by \begin{align} \max_\theta \sum_{i=1}^N \log p_\theta (\bx_i). \end{align}</p> <p>It is often computationally intractable to compute the partition function \(Z_\theta\) unless there are restrictions on what the model can be, since there are usually at least an exponential number of possible configurations. Examples of models where the partition function can be efficiently computed include causal convolutions in autoregressive models, and invertible networks in normalizing flow models However, such architecture restrictions are very undesirable as they limit the expressiveness of the models.</p> <p>A likelihood-based approach that tries to avoid computing the partition function is variational inference. In variational inference, we use the Evidence Lower Bound (ELBO) as a surrogate objective, where the approximation error is the smallest Kullback-Leibler divergence between the true distribution and a distribution that can be parameterized by our model.</p> <h3 id="limitations-of-adversarial-based-approaches">Limitations of Adversarial-Based Approaches</h3> <p>Adversarial-based approaches, like generative adversarial networks (GANs), have been shown to suffer from both instability in training and mode collapse.</p> <p>Training GANs can be viewed as finding a Nash equilibrium for a two-player non-cooperative game between the discriminator and the generator. Finding a Nash equilibrium is PPAD-complete which is computationally intractable, and therefore methods like gradient-based optimization techniques are used instead. However, the highly non-convex and high-dimensional optimization landscape means that small perturbations in the parameters of either player can change the cost function of the other player, which results in non-convergence.</p> <p>Another problem with training GANs is that when either the generator or discriminator becomes significantly better than the other, then the learning signal for the other player becomes very weak. For generators, this is when the discriminator is always able to tell it apart. For discriminators, this is when the generator performs so well it can hardly do better than random guessing.</p> <p>Finally, a common failure mode of GANs is mode collapse, where the generator only learns to produce a set of very similar outputs from a single mode instead of from all the modes. This is due to the non-convexity of the optimization landscape.</p> <h2 id="score-matching">Score Matching</h2> <p>Score matching is a non-likelihood-based method to perform sampling on an unknown data distribution, and seeks to address many of the limitations of likelihood-based methods and adversarial methods. This is achieved by learning the score of the probability density function, formally defined below:</p> <div class="definition"> <div class="theorem-title">Definition (Score Function) </div> <div class="theorem-contents"> The score function of a distribution \( \pdata \) is given by \begin{align*} f(\bx) = \nabla_\bx \log \pdata. \end{align*} </div> </div> <p>In practice, we try to learn the score function using a neural network \(\stx\) parameterized by \(\theta\).</p> <p>The objective of score matching is to minimize the Fisher Divergence between the score function and the score network:</p> \[\begin{align} \label{eq:score-matching-target-fisher-div} \argmin_\theta \frac{1}{2} \E_{\pdata} \left[ \| \stx - \nabla_\bx \log \pdata \|_2^2 \right]. \end{align}\] <p>However, the main problem here is that we do not know \(\nabla_\bx \log \pdata\), since it depends on knowing what \(\pdata\) is. \cite{estimation-non-normalized-score-matching} showed that Equation \ref{eq:score-matching-target-fisher-div} is equivalent to Equation \ref{eq:score-matching-target} below: \begin{align} \label{eq:score-matching-target} \argmin_\theta \frac{1}{2} \E_{\pdata} \left[ \tr \left( \nabla_\bx \stx \right) + \frac{1}{2} | \stx |_2^2 \right]. \end{align} We can now compute this using Monte Carlo methods by sampling from \(\pdata\), since it only depends on knowing \(\stx\).</p> <h2 id="sliced-score-matching">Sliced Score Matching</h2> <p>It is computationally difficult to compute the trace term \(\tr \left( \nabla_\bx \stx \right)\) in Equation \ref{eq:score-matching-target} when \(\bx\) is high-dimensional. This motivates another alternative cheaper approach for score matching, called sliced score matching \cite{sliced-score-matching}.</p> <p>In sliced score matching, we sample random vectors from some distribution \(\pv\) (such as the multivariate standard Gaussian) in order to optimize an analog of the Fisher Divergence:</p> \[\begin{align} L(\btheta, \pv) = \frac{1}{2} \E_{\pv} \E_{\pdata} \left[ (\bv^T \stx - \bv^T \sdx)^2 \right] \end{align}\] <p>We observe that</p> \[\begin{align} L(\btheta; \pv) &amp;= \frac{1}{2} \E_{\pv} \E_{\pdata} \left[ (\bv^T \stx - \bv^T \sdx)^2 \right]\\ &amp;=\frac{1}{2} \E_{\pv} \E_{\pdata} \left[ (\bv^T \stx )^2 + (\bv^T \sdx)^2 - 2(\bv^T \stx )(\bv^T \sdx) \right]\\ &amp;= \E_{\pv} \E_{\pdata} \left[ \frac{1}{2}(\bv^T \stx )^2 - (\bv^T \stx )(\bv^T \sdx) \right] + C\\ \end{align}\] <p>where the \(\sdx\) term is absorbed into \(C\) as it doesn’t depend on \(\theta\). Now note</p> \[\begin{align} -\E_{\pv} \E_{\pdata}\left[(\bv^T \stx )(\bv^T \sdx) \right] &amp;= -\E_{\pv} \int \left[(\bv^T \stx )(\bv^T \sdx) \pdata d\bx\right]\\ &amp;= -\E_{\pv} \left[\int(\bv^T \stx )(\bv^T\nabla_{\bx}\log \pdata)\pdata d\bx\right] \\ &amp;= -\E_{\pv} \left[\int(\bv^T \stx )(\bv^T\nabla_{\bx}\pdata)d\bx\right] \\ &amp;= -\E_{\pv} \left[\int(\bv^T \stx )(\bv^T\nabla_{\bx}\pdata)d\bx\right] \\ &amp;= -\E_{\pv} \left[\sum_{i}\int(\bv^T \stx )(v_i\frac{\partial \pdata}{\partial x_i})d\bx\right] \\ &amp;= \E_{\pv} \left[\int \bv^T\stx\bv \cdot \pdata d\bx\right] \\ &amp;= \E_{\pv}\E_{\pdata}\left[\bv^T\stx\bv \right] \end{align}\] <p>where [TODO FIX] line 16 is obtained by applying multivariate integration by parts. This finally yields the equivalent objective:</p> \[\begin{align} J(\btheta; \pv) &amp;= \E_{\pv} \E_{\pdata} \left[ \bv^T \nabla_\bx \stx \bv + \frac{1}{2} \| \stx \|_2^2 \right] \end{align}\] <p>which no longer has a dependence on the unknown \(\nabla_{bx}\sdx\). This leads to the unbiased estimator:</p> \[\begin{align} \hat J_{N,M}(\btheta; \pv) &amp;=\frac{1}{N}\frac{1}{M}\sum_{i= 1}^N\sum_{j=1}^M \left[\bv_{ij}^T\nabla_{\bx}\mathbf{s}_\mathbf{\btheta}(\bx_i)\bv_{ij} + \frac{1}{2} \|\mathbf{s}_\mathbf{\btheta}(\bx_i)\|_2^2\right] \end{align}\] <p>where for each data point \(\bx_i\) we draw \(M\) projection vectors from \(\pv\).</p> <p>\cite{sliced-score-matching} showed that under some regularity conditions, sliced score matching is an asymptotically consistent estimator:</p> \[\begin{align} \hat \btheta_{N,M} \overset{p}{\to} \btheta^* \text { as } \N \to \infty \end{align}\] <p>where</p> \[\begin{align} \btheta^* &amp;= \underset{\btheta}{\text{argmin }} J(\btheta; \pv), \\ \hat \btheta_{N,M} &amp;= \underset{\btheta}{\text{argmin }} \hat J_{N,M}(\btheta; \pv). \end{align}\] <p>Sliced score matching is computationally more efficient, since it now only involves Hessian-vector products, and continues to work well in high dimensions.</p> <h2 id="sampling-with-langevin-dynamics">Sampling with Langevin Dynamics</h2> <p>Once we have trained a score network, we can sample from the data distribution via Langevin dynamics. Langevin dynamics is a Markov Chain Monte Carlo method of sampling from a stationary distribution, where we can efficiently take gradients with respect to the probability of our samples \(\bx\). We satisfy this criteria since we have the trained score network.</p> <p>In Langevin dynamics, we start from some initial point \(\bx_0 \sim \bpi(\bx)\) sampled from some prior distribution \(\bpi\), and then iteratively obtain updated points based on the following recurrence: \begin{align} \xt_t = \xt_{t-1} + \frac{\epsilon}{2} \nabla_\bx \log p(\xt_{t-1}) + \sqrt{\epsilon} \bz_t, \end{align} where \(\bz_t \sim \mathcal{N}(0, I)\). The addition of the Gaussian noise is required, or otherwise the process simply converges to the nearest mode instead of converging to a stationary distribution.</p> <p>It can be shown that as \(\epsilon \to 0\) and \(T \to \infty\), we have that the distribution of the process \(\xt_T\) converges to \(\pdata\) \cite{langevin}.</p> <h2 id="challenges-of-langevin-dynamics">Challenges of Langevin Dynamics</h2> <p>Langevin dynamics does not perform well with multi-modal distributions with poor conductance, since it will tend to stay in a single mode, which causes long mixing times. This is particularly a problem when the modes have disjoint supports, since there is very weak gradient information in the region where there is no support.</p> <h2 id="challenges-of-score-matching-for-generative-modeling">Challenges of Score Matching for Generative Modeling</h2> <h3 id="the-manifold-hypothesis">The Manifold Hypothesis</h3> <p>The manifold hypothesis postulates that real-world data often lies in a low-dimensional manifold embedded in a high-dimensional space. This has been empirically observed in many datasets.</p> <p>This poses problems for score matching. The first problem that the manifold hypothesis poses is that the score \(\score\) becomes undefined if \(\bx\) actually just lies in a low-dimensional manifold. The second problem is that the estimator in Equation \ref{eq:score-matching-target} is only consistent when the support of \(\pdata\) is that of the whole space.</p> <p>In order to increase the dimension of the data to match that of the ambient space, \cite{estimation-non-normalized-score-matching} proposed injecting small amounts of Gaussian noise into the data, such that now the data distribution has full support. As long as the perturbation is sufficiently small (\(\mathcal{N}(0, 0.0001)\) was used in their paper), it is almost indistinguishable to humans.</p> <h3 id="low-data-density-regions">Low Data Density Regions</h3> <p>The other problem with score matching is that it may not be able to learn the score function in areas of low data density. This is due to the lack of samples drawn from these regions, resulting in the Monte Carlo estimation to have high variance.</p> <h2 id="noise-conditional-score-networks-ncsn">Noise Conditional Score Networks (NCSN)</h2> <p>The challenges mentioned in the previous sections are addressed by Noise Conditional Score Networks (NCSN).</p> <p>In NCSN, we define a geometric sequence of \(L\) noise levels \({\left\{ \sigma_i \right\}}_{i=1}^L\), with the property that \(\frac{\sigma_1}{\sigma_2} = \frac{\sigma_{L-1}}{\sigma_L} &gt; 1\). Each of these noise levels correspond to Gaussian noise that will be added to perturb the data distribution, i.e \(q_{\sigma_i} \sim \pdata + \mathcal{N}(0, \sigma_i)\).</p> <p>We augment the score network to also take the noise level \(\sigma\) into account, which is called the NCSN \(\stxt\). The goal of NCSN is then to estimate the score conditioned on the noise level. Once we have a trained NCSN, we use a similar apporach as simulated annealing in Langevin sampling, where we begin with a large noise level in order to cross the different modes easily, before gradually annealing down the noise to achieve convergence.</p> <p>The denoising score matching objective for each noise level \(\sigma_i\) is given as</p> \[\begin{align} \ell(\theta; \sigma) \triangleq \frac{1}{2} \E_{\pdata} \E_{\xt \sim \mathcal{N}(\bx, \sigma^2 I)} \left[ \left\| \stxt + \frac{\xt - \bx}{\sigma^2} \right\|_2^2 \right], \end{align}\] <p>and the unified objective for denoising across all levels is given as</p> \[\begin{align} \mathcal{L}\left(\theta; \left\{ \sigma_i\right\}_{i=1}^L \right) \triangleq \frac{1}{L} \sum_{i=1}^L \lambda(\sigma_i) \ell(\theta; \sigma_i). \end{align}\] <h2 id="score-based-generative-modeling-through-stochastic-differential-equations-citegenerative-modeling-sde">Score-Based Generative Modeling through Stochastic Differential Equations \cite{generative-modeling-sde}</h2> <p>We can extend the idea of having a finite number of noise scales to having an infinite continuous number of such noise scales by modeling the process as a diffusion process, which can be formalized as a stochastic differential equation (SDE). Such an SDE is given in the following form:</p> \[\begin{align} d\bx = \boldf(\bx, t) \, dt + g(t) \, d\bw. \end{align}\] <p>Here, \(\boldf\) represents the drift coefficient, which models the deterministic part of the SDE, and determines the rate at which the process \(d\bx\) is expected to change over time on average. \(g(t)\) is called the diffusion coefficient, which represents the random part of the SDE, and determines the magnitude of the noising process over time. Finally, \(\bw\) is Brownian motion. Thus \(g(t) \, d \bw\) represents the noising process.</p> <p>We want our diffusion process to be such that \(\bx(0) \sim p_0\) is the original data distribution, and \(\bx(T) \sim p_T\) is the Gaussian noise distribution that is independent of \(p_0\). Then since every SDE has a corresponding reverse SDE, we can start from the final noise distribution and run the reverse-time SDE in order to recover a sample from \(p_0\), given by the following process:</p> \[\begin{align} d \bx = [\boldf (\bx, t) - g(t)^2 \nabla_{\bx} \log_{p_t} (\bx) ] \, dt + g(t) \,d \overline{w}, \end{align}\] <p>where \(\overline{w}\) is Brownian motion that flows backwards in time from \(T\) to \(0\), and \(dt\) is an infinitesimal negative timestep.</p> <p>The objective function for score matching for the SDE is then given by</p> \[\begin{align} \argmin_{\theta} \E_t \left[ \lambda (t) \E_{\bx(0)} \E_{\bx (t) \mid \bx(0)} \left[ \| \bs_\theta (\bx(t), t) - \nabla_{\bx(t)} \log p_{0t}(\bx (t) \mid \bx(0)) \|_2^2 \right] \right]. \end{align}\] <h3 id="score-based-generative-modeling-techniques">Score-based Generative Modeling Techniques</h3> <p>\cite{generative-modeling-sde} covers two score-based generative models that uses SDEs to perform generative modeling. The first is called score matching with Langevin dynamics (SMLD), which performs score estimation at different noise scales and then performs sampling using Langevin dynamics with decreasing noise scales. The second is denoising diffusion probabilistic modeling (DDPM) \cite{ddpm}, which uses a parameterized Markov chain that is trained with a re-weighted variant of the evidence lower bound (ELBO), which is an instance of variational inference. The Markov chain is trained to reverse the noise diffusion process, which then allows sampling from the chain using standard Markov Chain Monte Carlo techniques.</p> <p>\cite{generative-modeling-sde} shows that SMLD and DDPM actually corresponds to discretizations of the Variance Exploding (VE) and Variance Preserving (VP) SDEs, which is the focus of the next two section. We believe expanding on this will be illuminating as it highlights the connections between SDEs and the discretized approaches that are used in practice.</p> <h3 id="smld-as-discretization-of-variance-exploding-ve-sde">SMLD As Discretization of Variance Exploding (VE) SDE</h3> <p>Recall that we use a geometric sequence of \(L\) noise levels \({\left\{ \sigma_i \right\}}_{i=1}^L\). that is added to the data distribution</p> <p>We can recursively define the distribution for each noise level \(i\) by incrementally adding noise:</p> \[\begin{align} \bx_i = \bx_{i-1} + \sqrt{\sigma_i^2 - \sigma_{i-1}^2} \bz_{i-1}, \qquad \qquad i = 1, \dots, L, \end{align}\] <p>where \(\bz_{i-1} \sim \mathcal{N}(\mathbf{0}, \bI)\), and \(\sigma_0 = 0\) so \(\bx_0 \sim \pdata\).</p> <p>If we view the noise levels as gradually changing in time, then the continuous time limit of the process is given by the following SDE: \begin{align} \bx(t + \Delta t) = \bx(t) + \sqrt{\sigma^2 (t + \Delta t ) - \sigma^2 (t)} \bz(t) \approx \bx(t) + \sqrt{\frac{d [\sigma^2 (t)]}{dt} \Delta t } \bz (t), \end{align} where the approximation holds when \(\Delta t \ll 1\). If we take \(\Delta t \to 0\), we recover the VE SDE: \begin{align} d \bx = \sqrt{\frac{d [\sigma^2 (t)]}{dt} } d \bw, \end{align} which causes the variance of \(d \bx(t)\) to go to infinity as \(t \to \infty\) due to its geometric growth, hence its name.</p> <h3 id="ddpm-as-discretization-of-variance-preserving-vp-sde">DDPM As Discretization of Variance Preserving (VP) SDE</h3> <p>Similarly, the Markov chain of the perturbation kernel of DDPM is given by \begin{align} \bx_i = \sqrt{1 - \beta_i} \bx_{i-1} + \sqrt{\beta_i} \bz_{i-1}, \qquad i = 1, \cdots, L, \end{align} where \(\left\{ \beta_i \right\}_{i=1}^L\) are the noise scales, and if we take \(L \to \infty\) with scaled noise scales \(\overline{\beta_i} = N \beta_i\), we get \begin{align} \bx_i = \sqrt{1 - \frac{\bov_i}{N} } \bx_{i-1} + \sqrt{ \frac{\bov_i}{N} } \bz_{i-1}, \qquad i = 1, \cdots, L. \end{align} Now taking limits with \(L \to \infty\), we get \begin{align} \bx(t + \Delta t) \approx \bx(t) - \frac{1}{2} \beta(t) \Delta t \bx(t) + \sqrt{\beta(t) \Delta t} \bz(t), \end{align} where the approximation comes from the second degree Taylor expansion of \(\sqrt{1 - \beta(t + \Delta t) \Delta t}\). Then taking the limit of \(\Delta t \to 0\), we obtain the VP SDE \begin{align} d \bx = - \frac{1}{2} \beta(t) \bx dt + \sqrt{\beta(t)} d \bw. \end{align} This process thus has bounded variance since \(\beta_i\) is bounded.</p> <h1 id="experiments">Experiments</h1> <p>We conduct the following preliminary series of experiments, based on released work by \cite{generative-modeling-by-estimating-gradients}.</p> <h2 id="investigating-the-manifold-hypothesis">Investigating the manifold hypothesis</h2> <figure> <picture> <img src="/assets/img/posts/score-based-diffusion-models/sample_dist.png" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 1.</i> Comparison between true data density and sampling </figcaption> </figure> <p>In this experiment, we have plotted the true data density of a toy distribution along with samples drawn in three ways. The i.i.d samples are drawn directly from the underlying distribution and we can see that more samples are drawn in the area of high data density. However, applying Langevin dynamics without annealing, we see that there is an almost equal number of points in the top left and bottom right corners. This is evidence that the sampling method doesn’t conform to the true distribution. Finally, by injecting and decreasing the amount of noise through the annealing process, we can recover a representative sample of the distribution.</p> <h2 id="importance-of-annealing-when-sampling-via-langevin-dynamics">Importance of annealing when sampling via Langevin Dynamics</h2> <p>To better visualize the effects of annealing when sampling via Langevin Dynamics, we generated images from a model trained on the CelebA dataset. We first tried applying Langevin Dynamics with a fixed noise and then used annealing to gradually decrease the noise.</p> <figure> <picture> <img src="/assets/img/posts/score-based-diffusion-models/annealing_ablation.png" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 2.</i> Langevin Dynamics with no annealing (top) and annealing (bottom) </figcaption> </figure> <p>Figure 2 shows that the results with annealing are significantly clearer and more varied, matching the performance of GANs in 2019.</p> <figure> <picture> <img src="/assets/img/posts/score-based-diffusion-models/left_right.png" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 3.</i> Closer comparison of no annealing (left) and annealing (right) </figcaption> </figure> <p>We notice that the image generated without annealing manages to produce the structure of a human face but fails to capture finer details such as the hair, and the surrounding backdrop. There is also little variation in color between different samples. This is in agreement with our theory that without annealing, Langevin dynamics cannot properly explore regions of lower data density.</p> <h2 id="effect-of-noise-parameters-for-annealed-langevin-dynamics">Effect of noise parameters for annealed Langevin Dynamics</h2> <p>We also investigated the effect of changing the lowest noise standard deviation \(\sigma\) while keeping the number of different noises injected fixed at \(10\). The 10 noise values are determined by an interpolation in log scale.</p> <figure> <picture> <img src="/assets/img/posts/score-based-diffusion-models/vary_sigma.png" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption"><i>Figure 4.</i> Left to right: \( \sigma_{\text{end}} = \{0.1, 0.01, 0.001\} \) </figcaption> </figure> <p>Our experiment shows that the effect of starting, ending, and the interval between noise values has a significant effect on the convergence of annealed Langevin sampling.</p> <h1 id="discussion-and-future-work">Discussion and Future Work</h1> <p>Having completed a survey of score-based diffusion models, and having run some experiments on them, we now turn our attention to discussing the pros and cons of this approach.</p> <p>As mentioned previously in this paper, the main draw of score-based diffusion models is that it has shown to be capable of generating impressive high-quality samples that is on-par with the state-of-the-art with GANs. We hence focus on its limitations and how they might be overcome, drawing from work in \cite{survey-generative-diffusion-model}.</p> <h2 id="computation-cost">Computation Cost</h2> <p>A common refrain of score-based diffusion model is the high computational complexity in both training and sampling. This is because it requires thousands of small diffusion steps in order to ensure that the forward and reverse SDEs hold in their approximations \cite{truncated-diffusion-models}. If the diffusion steps are too large, then the Gaussian noise assumption may not hold, resulting in poor score estimates. % of computing the score function at each step of the diffusion process, This makes it significantly more expensive than other generative methods like GANs and VAEs. To this end, there are some directions being explored to improve its computation cost.</p> <p>The first technique seeks to reduce the number of sampling steps required by a method known as knowledge distillation \cite{data-free-knowledge-distillation}. In knowledge distillation, knowledge is transferred from a larger and more complex model (called the teacher), to one that is smaller and simpler (called the student). This technique has found success in other domains such as image classification, and has also been shown to result in improvements in diffusion models \cite{distillation-sampling}. It would be interesting to see how far we can take this optimization.</p> <p>Another technique known as truncated diffusion probabilistic modeling (TDPM) \cite{truncated-diffusion-models}. In this approach, instead of considering the diffusion process until it becomes pure noise, the process is stopped once it reaches a hidden noisy-data distribution that can be learnt by an auto-encoder by adversarial training. Then in order to produce samples, a sample is first drawn from the learnt noisy-data distribution, before being passed through the reverse-SDE diffusion steps.</p> <p>It also suffers from poor explainability and interpretability, but this is a common problem across other generative models.</p> <p>\cite{generative-modeling-sde} also notes that it is currently difficult to tune the myriad of hyperparameters introduced by the choice of noise levels and specific samplers chosen, and new methods to automatically select and tune these hyperparameters would make score-based diffusion models more easily deployable in practice.</p> <h2 id="modality-diversity">Modality Diversity</h2> <p>Diffusion models have mostly only seen applications for generating image data, and its potential for generating other data modalities has not been as thoroughly investigated. \cite{denoising-discrete} introduces Discrete Denoising Diffusion Probabilistic Models (D3PMs), which develops a diffusion process for corrupting text data into noise. It would be interesting to see how well diffusion models can be stretched to perform compared to state-of-the-art transformer models in text generation.</p> <h2 id="dimensionality-reduction">Dimensionality Reduction</h2> <p>Dimensionality reduction is another technique that can be used to speed up training and sampling speeds of diffusion models. Diffusion models are typically trained directly in data space. \cite{score-based-latent-space} instead proposes for them to be trained in latent space, which results in dimensionality reduction in the representation learnt, and also potentially increases the expressiveness of the framework. In a similar vein, \cite{dimensionality-varying-diffusion-process} argues that due to redundancy in spatial data, it is not necessary to learn in data space, and instead proposes a dimensionality-varying diffusion process (DVDP), where the dimensionality of the signal is dynamically adjusted during the both the diffusion and denoising process.</p> <h1 id="conclusion">Conclusion</h1> <p>We showed that score matching presents a promising new direction for generative models, which avoids many of the limitations of other approaches such as training instability and mode collapse in GANs, and poor approximation guarantees in variational inference. While score matching has several flaws, such as suffering from the manifold hypothesis and requiring an expensive Langevin dynamics process in order to draw samples, successive work has done well in addressing these limitations to make score matching on diffusion models a viable contender to displace GANs as the state-of-the-art for generative modeling.</p> <p>Our experiments in this paper help to provide empirical context to the theoretical results we have derived. Most notably, we have shown how annealing is an essential part of sampling via Langevin dynamics.</p> <p>Finally, we discuss some future directions that can help to improve the viability of using score-based diffusion models, which includes improving its computational cost in both training and sampling and increasing the diversity of applicable modalities.</p> <h1 id="acknowledgements">Acknowledgements</h1> <p>Joint work with Owen Wang for the final course project of <a href="https://www.cs.cmu.edu/~pradeepr/716/">10-716 Advanced Machine Learning: Theory and Methods</a>.</p> <h1 id="references">References</h1> <ul> <li>Austin, J., Johnson, D. D., Ho, J., Tarlow, D., and van den Berg, R. <a href="https://arxiv.org/abs/2107.03006">Structured denoising diffusion models in discrete state-spaces.</a> CoRR, abs/2107.03006, 2021. URL https://arxiv.org/abs/2107.03006.</li> <li>Cao, H., Tan, C., Gao, Z., Chen, G., Heng, P.-A., and Li, S. Z. A survey on generative diffusion model, 2022.</li> <li>Ho, J., Jain, A., and Abbeel, P. <a href="https://arxiv.org/abs/2006.11239">Denoising diffusion probabilistic models</a>. CoRR, abs/2006.11239, 2020. URL https://arxiv.org/abs/2006.11239.</li> <li>Hyva ̈rinen, A. <a href="http://jmlr.org/papers/v6/hyvarinen05a.html">Estimation of non-normalized statistical models by score matching</a>. Journal of Machine Learning Research, 6(24):695–709, 2005. URL http://jmlr.org/papers/v6/hyvarinen05a.html.</li> <li>Lopes, R. G., Fenu, S., and Starner, T. <a href="http://arxiv.org/abs/1710.07535">Data-free knowledge distillation for deep neural networks</a>. CoRR, abs/1710.07535, <ol> <li>URL http://arxiv.org/abs/1710.07535.</li> </ol> </li> <li>Salimans, T. and Ho, J. <a href="https://arxiv.org/abs/2202.00512">Progressive distillation for fast sampling of diffusion models</a>. CoRR, abs/2202.00512, 2022. URL https://arxiv.org/abs/2202.00512.</li> <li>Song, Y. and Ermon, S. <a href="http://arxiv.org/abs/1907.05600">Generative modeling by estimating gradients of the data distribution</a>. CoRR, abs/1907.05600, 2019. URL http://arxiv.org/abs/1907.05600.</li> <li>Song, Y., Garg, S., Shi, J., and Ermon, S. <a href="http://arxiv.org/abs/1905.07088">Sliced score matching: A scalable approach to density and score estimation</a>. CoRR, abs/1905.07088, 2019. URL http://arxiv.org/abs/1905.07088.</li> <li>Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B. <a href="https://arxiv.org/abs/2011.13456">Score-based generative modeling through stochastic differential equations</a>. ICLR, abs/1907.05600, 2021. URL https://arxiv.org/abs/2011.13456.</li> <li>Vahdat, A., Kreis, K., and Kautz, J. Score-based generative modeling in latent space, 2021.</li> <li>Welling, M. and Teh, Y. W. Bayesian learning via stochastic gradient langevin dynamics. In Proceedings of the 28th International Conference on International Conference on Machine Learning, ICML’11, pp. 681–688, Madison, WI, USA, 2011. Omnipress. ISBN 9781450306195.</li> <li>Zhang, H., Feng, R., Yang, Z., Huang, L., Liu, Y., Zhang, Y., Shen, Y., Zhao, D., Zhou, J., and Cheng, F. Dimensionality- varying diffusion process, 2022.</li> <li>Zheng, H., He, P., Chen, W., and Zhou, M. Truncated diffusion probabilistic models and diffusion-based adversarial auto-encoders, 2022.</li> </ul>]]></content><author><name>fanpu</name></author><category term="machine-learning"/><summary type="html"><![CDATA[Score-based diffusion models are a promising direction for generative models, as they improve on both likelihood-based approaches like variational autoencoders, as well as adversarial methods like Generative Adversarial Networks (GANs). In this blog post, we survey recent developments in the field centered around the line of results developed in (Song & Ermon, 2019), analyze the current strengths and limitations of score-based diffusion models, and discuss possible future directions that can address its drawbacks.]]></summary></entry><entry><title type="html">My Experiences as a First-Time TA in CMU</title><link href="https://fanpu.io/blog/2023/my-experiences-as-a-first-time-ta/" rel="alternate" type="text/html" title="My Experiences as a First-Time TA in CMU"/><published>2023-05-25T00:00:00+00:00</published><updated>2023-05-25T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/my-experiences-as-a-first-time-ta</id><content type="html" xml:base="https://fanpu.io/blog/2023/my-experiences-as-a-first-time-ta/"><![CDATA[<p>This semester was the first time that I was a teaching assistant (TA) for a class, which was for <a href="https://andrejristeski.github.io/10708-S23/">10-708 Probabilistic Graphical Models</a> under professor Andrej Risteski. I really enjoyed the experience overall, and being able to lead two recitations for the class was one of the highlights of the semester for me. The extensive interactions with students during office hours and on Piazza made me more aware of my own behaviors as a student in other classes, and having to read and grade many proofs also gave me insights on how to write clearer and more readable proofs from both positive and negative examples.</p> <p>In this post, I will share my personal journey of being a TA, from the unique perspective of being a TA for a graduate machine learning class in the Machine Learning Department. I will also share many of my observations (not intended to be prescriptive or suggestive in any way, I just found it interesting), some dos and donts of being a student to get help more easily and also to make life for course staff easier, and conclude with some remarks on why you might want to TA. I hope that this post will shed light on and provide a more complete picture of the TA experience for those who may be thinking about it, especially as TA culture is a really big thing in the School of Computer Science in CMU.</p> <h2 id="previous-attempts-to-ta">Previous Attempts to TA</h2> <p>Prior to this semester, I had applied once to be a TA for 15-410 Design and Implementation of Operating Systems for the Fall semester in my junior year, having taken the class and found it extremely transformative the semester before. Unfortunately, I was not selected to be one of the TAs, which was somewhat discouraging but also understandable as I did not have any prior TA experience and was still quite early in my academic career (all the other TAs selected were seniors/graduate students) and I gave up on the idea of TA-ing for a while.</p> <p>After that, I gradually developed an interest in computer science theory, and I seriously considered the idea of being a TA 15-455 Undergraduate Complexity Theory during my senior year. I wanted to do it under professor Ryan O’Donnell, who was by far my favorite CS theory professor, but he was not the instructor for the class for any of the semesters, and that plus my intended course load meant I ended up not applying for any TA roles again.</p> <p>In hindsight, I realized that I was really picky in choosing a course to TA. I approached it with the same attitude as if I were going to join a company full-time: I had to really feel passionate about the class and its materials, I had to like my boss (the instructor), I had to feel sufficiently ready to know I could excel in my role and have enough bandwidth for it… in reality, since it was only a single-semester commitment, it was not really such a make-or-break decision. However, being a TA also does represent a significant opportunity cost in terms of other things that you could be doing on campus, so it should not be taken too lightly as well.</p> <h2 id="being-a-ta-for-10-708">Being a TA for 10-708</h2> <p>Halfway through the Fall’22 semester, I realized that I really enjoyed one of my classes 10-708 Probabilistic Graphical Models, to the extent that I get excited when it was Tuesdays or Thursdays because we would have lectures. The course is broadly about the theory of probabilistic graphical models, a framework used for solving a wide spectrum of problems in machine learning, artificial intelligence, computer vision, natural language processing, and so on. Examples include undirected graphical models like Markov Random Fields, directed graphical models like Bayesian networks, variational methods, Markov Chain Monte Carlo, deep generative models, causality, and so on. The course was rigorous and proof-heavy, drawing on many techniques used in computer science theory, math, and statistics.</p> <p>A few classes after this realization, I summoned up the courage after class to ask the professor if he is looking for any TAs next semester, and that I would be really excited if I could TA for the class. I was not really sure if I am qualified for the role, as prior to this semester I had only taken two other non-intro machine learning classes, and I often felt very out of my depth during lectures. Furthermore, I had no prior TA experience.</p> <p>Andrej was really nice</p> <h2 id="setting-a-new-homework-problem">Setting a New Homework Problem</h2> <p>I volunteered to set a new homework problem for our second assignment on Markov Chain Monte Carlo methods. Previously, we had a problem that required students to calculate the expected time to move from one node to some other node in a Markov Chain for 3 different graphs, each with varying degrees of “connectedness”: a clique, a line graph, and a dumbbell-shaped graph. By computing this expected time, students would be able to get a sense of how long it would take for the Markov Chain to mix, based on the degree of the “connectedness” of the graphs. This was important, since one of the key limitations of Markov Chain Monte Carlo methods was that it was hard in practice to determine when the Markov Chain has converged to a stationary distribution, and therefore having some intuition about how the properties of the graph would influence that is very helpful.</p> <p>However, this was a relatively tedious problem involving computing many recurrent expectations, and many students who were otherwise technically strong got tripped up when they attempted to take limits of iterating the Markov Chain instead. To make the problem more insightful and to provide a more general result, I set about designing a new problem based on bounding the mixing times of Markov Chains based on the difference between the top two eigenvalues of the graph, i.e the spectral gap.</p> <h2 id="leading-my-first-recitation">Leading My First Recitation</h2> <h2 id="some-personal-observations">Some Personal Observations</h2> <h3 id="impressive-students">Impressive Students</h3> <p>The first thing that struck me was how good the students were. There were many students in the class who have significantly more background than me in machine learning. I don’t think I ever had any PhD students in machine learning ever come to my office hours, but I definitely had PhD students in other fields that depended on tools from machine learning, as well as a lot of students from the MSML and MCDS programs. Many of them are actively engaged in research, and some of them have even worked as machine learning engineers full-time for several years before enrolling in their programs. They were sharp, and there were a couple of times during office hours where I was immediately corrected when I said something that did not make sense.</p> <p>Given the broad appeal of the class, there were also some students from non-traditional backgrounds that were less prepared. As graduate students are responsible for ensuring that they meet the course requirements themselves since most of them did their undergrad elsewhere, there were some students that did not really have sufficient background and it was difficult to help them in a pedagogically useful manner since the chasm between their current knowledge and what is required was simply too large.</p> <p>I usually hosted one hour of office hours each week, with additional office hours on the week the assignment was due for the assignments that I am in charge of.</p> <h3 id="office-hours-preparation">Office Hours Preparation</h3> <p>Unfortunately I did not really have time to prepare much before my office hours. In contrast, of my friends who were TAs for other classes would work through the entire assignment to familiarize themselves with the problems and to get a sense of the places where students would likely get stuck in order to prepare for their OH.</p> <p>However, it still mostly worked out fine as most of the proof-based problems and programming problems were similar from the previous semester when I took it. Furthermore, as each assignment was released for two weeks, there were usually far fewer students at OH during the first week, meaning I had more time to spend on each student and to regain context on the trickier problems.</p> <p>and so it did not take too much time to regain context, though I still felt apologetic when I had to take a few minutes to think</p> <h3 id="types-of-questions">Types of Questions</h3> <p>Almost all the students who came to office hours were there to ask about homework questions. Occasionally, there were also questions about the direction and content of their course projects. This was not too surprising, as it makes sense that they would prefer to go to the professor’s office hours to ask about conceptual questions.</p> <h3 id="grading">Grading</h3> <p>I really enjoyed grading some of the proof-based questions that allowed creativity in how it could be approached.</p> <h3 id="asking">Asking</h3> <p>When students</p> <h2 id="how-to-be-a-good-student">How To Be A Good Student</h2> <h3 id="ask">Ask</h3> <p>One large component of the course is a semester-long project that involves doing research in groups related to probabilistic graphical models.</p> <p>The topics that the groups assigned to me chose were very diverse and ranged from novel approaches to multi-agent reinforcement learning as evaluated on StarCraft, to predicting the pathogenicity of protein variants using graphical models.</p> <p>These could be PhD students</p> <p>It felt very much different from wh</p> <p>Students </p> <p>and it was not as stressful or all-consuming as I had worried.</p> <p>which was surprising given that I had been already thinking about doing so for quite a number of semesters, but could not find a class that I felt really passionate about.</p> ]]></content><author><name>fanpu</name></author><category term="general"/><category term="teaching"/><category term="cmu"/><summary type="html"><![CDATA[This semester was the first time that I was a teaching assistant (TA) for a class, which was for [10-708 Probabilistic Graphical Models](https://andrejristeski.github.io/10708-S23/) under professor Andrej Risteski. I really enjoyed the experience overall, and being able to lead two recitations for the class was one of the highlights of the semester for me. The extensive interactions with students during office hours and on Piazza made me more aware of my own behaviors as a student in other classes, and having to read and grade many proofs also gave me insights on how to write clearer and more readable proofs from both positive and negative examples. In this post, I will share my personal journey of being a TA, from the unique perspective of being a TA for a graduate machine learning class in the Machine Learning Department. I will also share many of my observations (not intended to be prescriptive or suggestive in any way, I just found it interesting), some dos and donts of being a student to get help more easily and also to make life for course staff easier, and conclude with some remarks on why you might want to TA. I hope that this post will shed light on and provide a more complete picture of the TA experience for those who may be thinking about it, especially as TA culture is a really big thing in the School of Computer Science in CMU.]]></summary></entry><entry><title type="html">The CMU Steam Tunnels</title><link href="https://fanpu.io/blog/2023/cmu-steam-tunnels/" rel="alternate" type="text/html" title="The CMU Steam Tunnels"/><published>2023-05-23T00:00:00+00:00</published><updated>2023-05-23T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/cmu-steam-tunnels</id><content type="html" xml:base="https://fanpu.io/blog/2023/cmu-steam-tunnels/"><![CDATA[<h1 id="todo-find-photos">TODO: find photos</h1>]]></content><author><name>fanpu</name></author><category term="general"/><category term="cmu"/><summary type="html"><![CDATA[TODO: find photos]]></summary></entry><entry><title type="html">Internship Advice and Common Questions</title><link href="https://fanpu.io/blog/2023/internship-advice/" rel="alternate" type="text/html" title="Internship Advice and Common Questions"/><published>2023-05-23T00:00:00+00:00</published><updated>2023-05-23T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/internship-advice</id><content type="html" xml:base="https://fanpu.io/blog/2023/internship-advice/"><![CDATA[<h2 id="freshmen-internships">Freshmen Internships</h2> <p>Make no mistake, the odds are heavily stacked against you during your first year of college. Most companies are (understandably) looking for candidates who will be able to start a year or two after their internships, and therefore it is challenging to even get any callbacks. However, there are a couple of things that you can consider do make your summer rich and rewarding.</p> <h3 id="1-working-at-startups">1. Working at Startups</h3> <p>Startups are always hungry for talent. They are traditionally overlooked by most applicants who are looking for a more stable, well-known, or higher-playing place, but in fact can offer an unparalleled experience in terms of the breadth of experience across various functions that you will gain, the impact that you can leave (even as an intern), and friendships that you will make.</p> <h3 id="2-summer-school">2. Summer School</h3> <p>Another popular option is to take summer classes and to get ahead of your peers. At CMU, this is most commonly classes like 15-122, 150150, and 15-213. Being able to clear 15-213 early is especially valuable as it is a gatekeeper class that will unlock all systems classes, in addition to many other classes with significant programming projects that list 15-213 as a pre-requisite.</p> <h3 id="3">3.</h3> <p></p> <p>However, do not despair because there are also many other options available to you which you may not have considered otherwise.</p> <h2 id="international-students">International Students</h2> <h2 id="swe-or-trading">SWE or Trading</h2>]]></content><author><name>fanpu</name></author><category term="general"/><category term="cmu"/><summary type="html"><![CDATA[Freshmen Internships Make no mistake, the odds are heavily stacked against you during your first year of college. Most companies are (understandably) looking for candidates who will be able to start a year or two after their internships, and therefore it is challenging to even get any callbacks. However, there are a couple of things that you can consider do make your summer rich and rewarding.]]></summary></entry><entry><title type="html">My Booth Building Experience during Spring Carnival</title><link href="https://fanpu.io/blog/2023/my-booth-building-experience-during-spring-carnival/" rel="alternate" type="text/html" title="My Booth Building Experience during Spring Carnival"/><published>2023-05-23T00:00:00+00:00</published><updated>2023-05-23T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/my-booth-building-experience-during-spring-carnival</id><content type="html" xml:base="https://fanpu.io/blog/2023/my-booth-building-experience-during-spring-carnival/"><![CDATA[<h1 id="todo-find-photos-tell-a-story">TODO: find photos, tell a story</h1> <h1 id="mechanical-team">Mechanical team</h1> <h1 id="cutting-wood">Cutting wood</h1> <h1 id="disassembling-frames">Disassembling frames</h1> <h1 id="first-org-to-pass-electrical">First org to pass electrical</h1> <h1 id="hard-hats">Hard hats</h1> <h1 id="watch-shift-scc-trailer-catching-violators">Watch shift, SCC trailer: catching violators</h1> <h1 id="celebration-dinner">celebration dinner</h1>]]></content><author><name>fanpu</name></author><category term="general"/><category term="cmu"/><summary type="html"><![CDATA[TODO: find photos, tell a story]]></summary></entry><entry><title type="html">Reflections on my Time in CMU</title><link href="https://fanpu.io/blog/2023/reflections-on-my-time-in-cmu/" rel="alternate" type="text/html" title="Reflections on my Time in CMU"/><published>2023-05-23T00:00:00+00:00</published><updated>2023-05-23T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/reflections-on-my-time-in-cmu</id><content type="html" xml:base="https://fanpu.io/blog/2023/reflections-on-my-time-in-cmu/"><![CDATA[]]></content><author><name>fanpu</name></author><category term="general"/><category term="cmu"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Advice I Wish I Knew As A Freshmen</title><link href="https://fanpu.io/blog/2023/advice-i-wish-i-knew/" rel="alternate" type="text/html" title="Advice I Wish I Knew As A Freshmen"/><published>2023-05-21T00:00:00+00:00</published><updated>2023-05-21T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/advice-i-wish-i-knew</id><content type="html" xml:base="https://fanpu.io/blog/2023/advice-i-wish-i-knew/"><![CDATA[<h2 id="swe-or-trading">SWE or Trading</h2> <h2 id="swe-or-trading-1">SWE or Trading</h2> <h2 id="graduate-classes">Graduate Classes</h2> <p>There is a natural hesitation towards taking graduate classes.</p> <p>##</p>]]></content><author><name>fanpu</name></author><category term="general"/><category term="cmu"/><summary type="html"><![CDATA[SWE or Trading]]></summary></entry><entry><title type="html">Practical Systems Debugging</title><link href="https://fanpu.io/blog/2023/practical-systems-debugging/" rel="alternate" type="text/html" title="Practical Systems Debugging"/><published>2023-05-19T00:00:00+00:00</published><updated>2023-05-19T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/practical-systems-debugging</id><content type="html" xml:base="https://fanpu.io/blog/2023/practical-systems-debugging/"><![CDATA[<p>Given the scale and complexity of the systems that we work with today, unless we can provably verify that each of the individual components of the system behaves as expected and can never go wrong, it is inevitable that there will be bugs. Having solid debugging skills is one of the most valuable skills of a software engineer, and the process of debugging itself often reveals new perspectives and insight into your code and its design that can inform its subsequent re-design.</p> <p>For the more challenging course projects, expect to spend significantly more time debugging and tuning your code than in writing the initial prototype itself. These assignments are designed to require writing tricky code, and to keep you outside your comfort zone.</p> <p>Through these experiences, you will (be forced to) learn and master an arsenal of debugging skills:</p> <ul> <li>The humble print statement is a versatile and formidable tool, and its beauty is not in whether you use it but how you use it. You’ll gain intuition for what are the appropriate things to print, how they should be formatted, when they should be invoked, and what information you should be trying to learn from its output. For larger projects, you may even write your own logging utility with several log levels.</li> <li>Debuggers like GDB are invaluable for low-level systems development, and for diagnosing segmentation faults and memory corruption. Jumping between stack frames allows you to easily view the calling context and the values of its variables, without having to resort to a deluge of print statements. Being able to see the contents of registers is essential for operating systems and compiler development. You can also easily view the memory layout of your data structures, allowing you to for instance verify that fields are aligned in memory as you expected, and to view raw byte values that may not be convenient to print due to the presence of 0 bytes. The ability to watch addresses for write changes when debugging unexpected memory corruptions also comes in extremely handy, which would be very difficult to trace otherwise. Utilities like the record and replay framework <a href="https://github.com/rr-debugger/rr">rr</a> even allow you to perform reverse-execution, allowing you to re-trace what happened to the program right before a segfault.</li> <li>Tools like <a href="TODO-add-here">Valgrind</a> allows you to easily detect memory leaks, double frees, and use-after-free bugs with minimal effort.</li> <li>Appropriate use of assertions to ensure that data structure invariants are preserved. This helps you to catch violations early on (fail fast principle), instead of facing an obscure bug that has become unrecognizable much further down the line. The complexity of these data structures means that you will often have to write a function to check its invariants. The usage of these assertions in turn means that you will re-design your code such that the invariants are preserved across function boundaries, making them better designed and easier to reason about.</li> <li>Developing a robust “thought process” for debugging. System programming novices tend to get discouraged when they encounter a bug that they have no idea where it comes from, because “obviously my code is correct”. Debugging is very much like doing science: you come up with a promising hypothesis on what the issue could be, and then proceed to test it using one of the strategies mentioned above. When you don’t have any or run out of such hypotheses, you will have no idea where to look. Some general guidelines: <ol> <li>TODO TODO</li> </ol> </li> <li>When all else fails, going for the nuclear option of re-writing everything from scratch and making minimal references to the old code. It is likely that there was some previous misconception that was deeply embedded in the code that you may no longer hold but still remains,</li> </ul>]]></content><author><name>fanpu</name></author><category term="general"/><category term="cmu"/><summary type="html"><![CDATA[Given the scale and complexity of the systems that we work with today, unless we can provably verify that each of the individual components of the system behaves as expected and can never go wrong, it is inevitable that there will be bugs. Having solid debugging skills is one of the most valuable skills of a software engineer, and the process of debugging itself often reveals new perspectives and insight into your code and its design that can inform its subsequent re-design.]]></summary></entry><entry><title type="html">Why Study Computer Systems</title><link href="https://fanpu.io/blog/2023/why-study-computer-systems/" rel="alternate" type="text/html" title="Why Study Computer Systems"/><published>2023-05-18T00:00:00+00:00</published><updated>2023-05-18T00:00:00+00:00</updated><id>https://fanpu.io/blog/2023/why-study-computer-systems</id><content type="html" xml:base="https://fanpu.io/blog/2023/why-study-computer-systems/"><![CDATA[<h1 id="todo-fanpu-check-all-todos-before-publishing">TODO fanpu: check all TODOs before publishing</h1> <p>Computer systems is the art and science of designing and building performant, reliable, and secure systems. The remarkable development of computer systems has brought about the third industrial revolution and created the greatest economic opportunities of our times. From operating systems, to compilers that form the genesis of all our software, to the Internet and distributed systems powering services that we rely on daily, it is hard to imagine any aspect of our lives that has not been transformed in one way or another due to computer systems.</p> <p>In this post, I talk about why one should study Computer Systems. The context of the post is specifically targeted at underclassmen studying Computer Science at Carnegie Mellon University deciding which concentration to pursue as part of their degree requirements, but the underlying ideas and principles are general and will be helpful regardless of your background.</p> <h2 id="the-computer-systems-concentration">The Computer Systems Concentration</h2> <p>This section will briefly introduce the Computer Systems concentration, and what to expect from system classes at CMU. Feel free to skip this section if you are not a CMU student.</p> <p>The concentration in Computer Systems is one of the many concentrations offered to Computer Science majors in the School of Computer Science at CMU. At CMU, CS majors are required to fulfill either a concentration or additional minor in addition to their major requirements.</p> <p>The Computer Systems concentration is by far the most popular concentration, owing to its generality and broad appeal as it covers a wide range of topics, and also due to its practicality, what it teaches permeates real-world systems that people build and work with in industry, and often come up during technical interviews.</p> <p>In this post, I will talk about the Computer Systems concentration, what you will gain by pursuing one, and the people for which this would be a good fit. I would like to remark that the content of this post is based on my personal experiences and opinions, and other people could have very different experiences and takeaways. I decided to write this post as many juniors in SCS have asked me about the different concentrations and my opinions of them, and I hope that sharing these to a wider audience publicly will help to benefit more students in the future. Roughly speaking, to complete the Computer Systems concentration, you will have to take 2 core systems classes, and 2-3 other classes also considered to live within the systems domain.</p> <p>Most system classes carry a significant project component, where you will spend most of your time of the class on, and where the majority of your grades will be determined. For instance, in 15-445 Database Systems you will have multiple projects that will involve building different parts of a database system, starting from the buffer pool manager to manage and optimize usage of your pages requested from the OS, and culminating in support for concurrent query execution and transactions.</p> <p>Usually, there will also be written homeworks and exams, though those will be relatively light compared to the projects. The questions on exams will usually be similar to those on homeworks, and the course staff will usually also provide previous year practice problems which are quite similar in content and style to the actual exams. Mastery of knowledge gained from the projects is necessary but not sufficient - exams will also tend to cover more of the theoretical or design-oriented concepts that are difficult to incorporate into a course project, so you will still have to review lecture slides in preparation. Overall, this means that exams in systems classes are usually a low-stress affair and you should expect to do fairly well if you prepare and do a good job on the projects.</p> <h2 id="what-you-will-gain-from-a-concentration-in-computer-systems">What you will gain from a concentration in Computer Systems</h2> <p>The Computer Systems concentration was the first concentration that I fulfilled (the other being Algorithms and Complexity). I had decided to go for it relatively early on, because it seemed to be so useful and applicable to such a wide variety of roles in industry. However, little did I know that there was a whole lot more than simply this vague notion that it would “be useful”, which I hope to share in this section.</p> <h3 id="dirty-systems-programming-skills">Dirty Systems Programming Skills</h3> <p>In the words of Andy Pavlo, you will learn <strong>dirty systems programming skills</strong> that will help you get the job done no matter what the scenario. You will become intimately familiar with a large portion of the POSIX interface, understand and be able to apply locking and concurrency mechanisms to appropriate scenarios, know tricks for optimizing performance based on assumptions on how the system was built.</p> <p>TODO: fanpu this should require more elaboration</p> <h3 id="an-arsenal-of-debugging-skills">An Arsenal of Debugging Skills</h3> <p>Given the scale and complexity of the systems that we work with today, unless we provably verify that each of the individual components of the system behaves as expected and can never go wrong, it is <em>inevitable</em> that there will be bugs. Having solid debugging skills is one of the most valuable skills of a software engineer, and the process of debugging itself often reveals new perspectives and insight into your code and its design that can inform its subsequent re-design.</p> <p>For the more challenging course projects, expect to spend significantly more time debugging and tuning your code than in writing the initial prototype itself. These assignments are designed to require writing tricky code, and to keep you outside your comfort zone.</p> <p>Through these experiences, you will (be forced to) learn and master an arsenal of debugging skills:</p> <ul> <li>The humble print statement is a versatile and formidable tool, and its beauty is not in whether you use it but how you use it. You’ll gain intuition for what are the appropriate things to print, how they should be formatted, when they should be invoked, and what information you should be trying to learn from its output. For larger projects, you may even write your own logging utility with several log levels.</li> <li>Debuggers like GDB are invaluable for low-level systems development, and for diagnosing segmentation faults and memory corruption. Jumping between stack frames allows you to easily view the calling context and the values of its variables, without having to resort to a deluge of print statements. Being able to see the contents of registers is essential for operating systems and compiler development. You can also easily view the memory layout of your data structures, allowing you to for instance verify that fields are aligned in memory as you expected, and to view raw byte values that may not be convenient to print due to the presence of 0 bytes. The ability to watch addresses for write changes when debugging unexpected memory corruptions also comes in extremely handy, which would be very difficult to trace otherwise. Utilities like the record and replay framework <a href="https://github.com/rr-debugger/rr">rr</a> even allow you to perform reverse-execution, allowing you to re-trace what happened to the program right before a segfault.</li> <li>Tools like <a href="TODO-add-here">Valgrind</a> allows you to easily detect memory leaks, double frees, and use-after-free bugs with minimal effort.</li> <li>Appropriate use of assertions to ensure that data structure invariants are preserved. This helps you to catch violations early on (fail fast principle), instead of facing an obscure bug that has become unrecognizable much further down the line. The complexity of these data structures means that you will often have to write a function to check its invariants. The usage of these assertions in turn means that you will re-design your code such that the invariants are preserved across function boundaries, making them better designed and easier to reason about.</li> <li>Developing a robust “thought process” for debugging. System programming novices tend to get discouraged when they encounter a bug that they have no idea where it comes from, because “obviously my code is correct”. Debugging is very much like doing science: you come up with a promising hypothesis on what the issue could be, and then proceed to test it using one of the strategies mentioned above. When you don’t have any or run out of such hypotheses, you will have no idea where to look. Some general guidelines: <ol> <li></li> </ol> </li> <li>When all else fails, going for the nuclear option of re-writing everything from scratch and making minimal references to the old code. It is likely that there was some previous misconception that was deeply embedded in the code that you may no longer hold but still remains,</li> </ul> <h3 id="programming-and-debugging-resilience">Programming and Debugging Resilience</h3> <p>While the number of lines of code is not the best measure of software complexity for many well-known reasons, systems course projects can <em>easily</em> run into thousands, if not tens of thousands of lines of code due to their requirements and complexity. Being able to write so much code, and more importantly <em>correct and robust</em> code, in a time-constrained environment with frequent distractions and external obligations is <em>difficult</em>. Summoning the internal motivation to begin writing a kernel from scratch from a <code class="language-plaintext highlighter-rouge">kernel.c</code> file containing nothing but a single infinite while loop is <em>difficult</em>. Designing and planning out the different components of a large system without knowing exactly what challenges you might face or what unintentional pathological interactions might arise is <em>difficult</em>. The zero-to-one phase of systems development where nothing works at all until when a minimal core set of components has been developed is daunting and requires faith in your abilities and code, since you are unable to develop incrementally or test anything until everything comes together. Coming back to your old code and re-orienting yourself to where you were previously and determining what needs to be done next is <em>difficult</em> (in some cases, it took me almost an hour re-gain my context). In short, it is <em>darn hard</em> to build systems, and it is the lifetime goal of practitioners to build <em>good</em> systems.</p> <p>Through the trials and tribulations of the many course projects that you will undertake, you will face and overcome these challenges again and again, and build confidence in your own abilities. You will build the stamina for writing challenging and tricky code for many hours with intense focus. You will gain the mental resilience and patience to track down the most subtle and transient bugs. When things get tough, you’ll be able to tell yourself that <strong>you did it before, and you’ll do it again</strong>.</p> <h3 id="a-doctor-but-not-that-kind">A Doctor, But Not That Kind</h3> <p>Doctors diagnose and prescribe treatment for sick patients. Similarly, as someone who has spent a lot of time with computer systems, you will also become proficient in figuring out why systems are slow or misbehaving, and how to remedy it.</p> <p>However, this requires an understanding of not just the specific part that you are working with, but of how the entire system interacts as a whole, plus the layer below the abstraction boundary that you are working with. [TODO: insert doctor example here]. In a similar vein, the breadth of exposure that system courses will offer you will allow you to understand and come up with ways to evaluate where things could be going wrong. For instance, suppose you realize that a RPC call occasionally takes an exceptionally long time. Could this be due to periodic network congestion resulting in dropped packets and repeated retries due to some other scheduled network-heavy activities by other services? Or perhaps an expired edge cache that required additional network hops to query the original overloaded server, which then suffered many page faults as it attempts to re-compute the results? It helps to understand the system from many different levels of abstraction to obtain a full picture.</p> <h3 id="performance-engineering">Performance Engineering</h3> <h3 id="from-principles-to-practice">From Principles to Practice</h3> <p>Something that may be initially surprising to many people is how the system classes at CMU do not teach you how to use many of the standard tools in industry, but rather focuses on principles and design trade-offs. This may appear to put students at a disadvantage for internship searches and technical interviews, but is in fact a deliberate and pedagogically crucial choice.</p> <p>The role of these classes is not to teach you how to use these tools and frameworks, but to understand the timeless principles and ideas behind how they were designed and why they were designed in this manner. Once you understand and see the bigger picture, you will realize that all of these industrial frameworks are imperfect and oftentimes lazy (for implementational convenience) instantiations of one possible design of the system, out of many other possible competing designs with different trade-offs.</p> <p>With this theoretical knowledge of how different systems are designed, learning a new framework becomes easy since it is just a matter of matching concepts to their implementations. In fact, even before starting you will already know roughly what kinds of APIs you need to achieve your goals, and the options and settings you expect to be available. The one slight complication is that what is done in practice is always messier than what is prescribed in theory, and therefore there will likely be more dials and knobs to configure, and more edge cases to consider.</p> <p>Practitioners who do not understand, or are not aware of the theory and principles behind systems tend to compare one system against another based on benchmarks such as their available features, speed, popularity, ecosystem support, and so on. However, when you understand the theory, you will begin to view each system from the use cases it was optimized for, and the design principles behind them that allows them to perform well under these use cases. You realize that there is no <em>best</em> way of doing things, only a <em>better</em> way based on balancing compromises.</p> <h3 id="preparation-for-senior-technical-roles">Preparation for Senior Technical Roles</h3> <p>There will come a time where you would probably</p> <p>If you want to be work on Google’s globally-distributed database called <a href="https://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf">Google Spanner</a>, or</p> <h3 id="the-joy-of-understanding">The Joy of Understanding</h3> <blockquote> <p>For, verily, great love springs from great knowledge of the beloved object, and if you little know it, you will be able to love it only little or not at all. <em>- Leonardo da Vinci</em></p> </blockquote>]]></content><author><name>fanpu</name></author><category term="general"/><category term="cmu"/><summary type="html"><![CDATA[TODO fanpu: check all TODOs before publishing]]></summary></entry></feed>