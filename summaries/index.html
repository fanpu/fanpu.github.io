<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> ML Paper Summaries | Fan Pu Zeng </title> <meta name="author" content="Fan Pu Zeng"> <meta name="description" content=""> <meta name="keywords" content="fanpu, fan pu, fanpu zeng, fan pu zeng, zengfanpu, fanpuzeng, fzeng, CMU, cmu, carnegie mellon, cmu courses, school of computer science, scs, machine learning, computer science, ml, theory, courses, course reviews, CS, Jane Street"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon_new.ico?426605099301e95aedae716cc398b951"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://fanpu.io/summaries/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Fan Pu</span> Zeng </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/courses/">CMU Course Reviews </a> </li> <li class="nav-item "> <a class="nav-link" href="/cmu-online/">CMU Online </a> </li> <li class="nav-item active"> <a class="nav-link" href="/summaries/">ML Paper Summaries <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">ML Paper Summaries</h1> <p class="post-description"></p> </header> <article> <p>Summaries and critiques of papers (mostly in machine learning) Iâ€™ve read in detail. This is not a summary of the traditional sense which will carefully go over all the major concepts in the paper (due to time constraints); instead, it will be rather concise and only contain the key points that I find interesting, with the expectation that the reader already has some familiarity with the paper.</p> <p>This serves to both catalog my own reading and academic progress, and may also be of interest to others to find interesting papers to check out.</p> <p>The format is inspired by the <a href="https://www.cs.cmu.edu/~15712/summaries.html" rel="external nofollow noopener" target="_blank">paper summaries</a> of a class I took.</p> <div style="display: none"> $$ \newcommand{\bone}{\mathbf{1}} \newcommand{\bbeta}{\mathbf{\beta}} \newcommand{\bdelta}{\mathbf{\delta}} \newcommand{\bepsilon}{\mathbf{\epsilon}} \newcommand{\blambda}{\mathbf{\lambda}} \newcommand{\bomega}{\mathbf{\omega}} \newcommand{\bpi}{\mathbf{\pi}} \newcommand{\bphi}{\mathbf{\phi}} \newcommand{\bvphi}{\mathbf{\varphi}} \newcommand{\bpsi}{\mathbf{\psi}} \newcommand{\bsigma}{\mathbf{\sigma}} \newcommand{\btheta}{\mathbf{\theta}} \newcommand{\btau}{\mathbf{\tau}} \newcommand{\ba}{\mathbf{a}} \newcommand{\bb}{\mathbf{b}} \newcommand{\bc}{\mathbf{c}} \newcommand{\bd}{\mathbf{d}} \newcommand{\be}{\mathbf{e}} \newcommand{\boldf}{\mathbf{f}} \newcommand{\bg}{\mathbf{g}} \newcommand{\bh}{\mathbf{h}} \newcommand{\bi}{\mathbf{i}} \newcommand{\bj}{\mathbf{j}} \newcommand{\bk}{\mathbf{k}} \newcommand{\bell}{\mathbf{\ell}} \newcommand{\bm}{\mathbf{m}} \newcommand{\bn}{\mathbf{n}} \newcommand{\bo}{\mathbf{o}} \newcommand{\bp}{\mathbf{p}} \newcommand{\bq}{\mathbf{q}} \newcommand{\br}{\mathbf{r}} \newcommand{\bs}{\mathbf{s}} \newcommand{\bt}{\mathbf{t}} \newcommand{\bu}{\mathbf{u}} \newcommand{\bv}{\mathbf{v}} \newcommand{\bw}{\mathbf{w}} \newcommand{\bx}{\mathbf{x}} \newcommand{\by}{\mathbf{y}} \newcommand{\bz}{\mathbf{z}} \newcommand{\bA}{\mathbf{A}} \newcommand{\bB}{\mathbf{B}} \newcommand{\bC}{\mathbf{C}} \newcommand{\bD}{\mathbf{D}} \newcommand{\bE}{\mathbf{E}} \newcommand{\bF}{\mathbf{F}} \newcommand{\bG}{\mathbf{G}} \newcommand{\bH}{\mathbf{H}} \newcommand{\bI}{\mathbf{I}} \newcommand{\bJ}{\mathbf{J}} \newcommand{\bK}{\mathbf{K}} \newcommand{\bL}{\mathbf{L}} \newcommand{\bM}{\mathbf{M}} \newcommand{\bN}{\mathbf{N}} \newcommand{\bP}{\mathbf{P}} \newcommand{\bQ}{\mathbf{Q}} \newcommand{\bR}{\mathbf{R}} \newcommand{\bS}{\mathbf{S}} \newcommand{\bT}{\mathbf{T}} \newcommand{\bU}{\mathbf{U}} \newcommand{\bV}{\mathbf{V}} \newcommand{\bW}{\mathbf{W}} \newcommand{\bX}{\mathbf{X}} \newcommand{\bY}{\mathbf{Y}} \newcommand{\bZ}{\mathbf{Z}} \newcommand{\bsa}{\boldsymbol{a}} \newcommand{\bsb}{\boldsymbol{b}} \newcommand{\bsc}{\boldsymbol{c}} \newcommand{\bsd}{\boldsymbol{d}} \newcommand{\bse}{\boldsymbol{e}} \newcommand{\bsoldf}{\boldsymbol{f}} \newcommand{\bsg}{\boldsymbol{g}} \newcommand{\bsh}{\boldsymbol{h}} \newcommand{\bsi}{\boldsymbol{i}} \newcommand{\bsj}{\boldsymbol{j}} \newcommand{\bsk}{\boldsymbol{k}} \newcommand{\bsell}{\boldsymbol{\ell}} \newcommand{\bsm}{\boldsymbol{m}} \newcommand{\bsn}{\boldsymbol{n}} \newcommand{\bso}{\boldsymbol{o}} \newcommand{\bsp}{\boldsymbol{p}} \newcommand{\bsq}{\boldsymbol{q}} \newcommand{\bsr}{\boldsymbol{r}} \newcommand{\bss}{\boldsymbol{s}} \newcommand{\bst}{\boldsymbol{t}} \newcommand{\bsu}{\boldsymbol{u}} \newcommand{\bsv}{\boldsymbol{v}} \newcommand{\bsw}{\boldsymbol{w}} \newcommand{\bsx}{\boldsymbol{x}} \newcommand{\bsy}{\boldsymbol{y}} \newcommand{\bsz}{\boldsymbol{z}} \newcommand{\bsA}{\boldsymbol{A}} \newcommand{\bsB}{\boldsymbol{B}} \newcommand{\bsC}{\boldsymbol{C}} \newcommand{\bsD}{\boldsymbol{D}} \newcommand{\bsE}{\boldsymbol{E}} \newcommand{\bsF}{\boldsymbol{F}} \newcommand{\bsG}{\boldsymbol{G}} \newcommand{\bsH}{\boldsymbol{H}} \newcommand{\bsI}{\boldsymbol{I}} \newcommand{\bsJ}{\boldsymbol{J}} \newcommand{\bsK}{\boldsymbol{K}} \newcommand{\bsL}{\boldsymbol{L}} \newcommand{\bsM}{\boldsymbol{M}} \newcommand{\bsN}{\boldsymbol{N}} \newcommand{\bsP}{\boldsymbol{P}} \newcommand{\bsQ}{\boldsymbol{Q}} \newcommand{\bsR}{\boldsymbol{R}} \newcommand{\bsS}{\boldsymbol{S}} \newcommand{\bsT}{\boldsymbol{T}} \newcommand{\bsU}{\boldsymbol{U}} \newcommand{\bsV}{\boldsymbol{V}} \newcommand{\bsW}{\boldsymbol{W}} \newcommand{\bsX}{\boldsymbol{X}} \newcommand{\bsY}{\boldsymbol{Y}} \newcommand{\bsZ}{\boldsymbol{Z}} \newcommand{\calA}{\mathcal{A}} \newcommand{\calB}{\mathcal{B}} \newcommand{\calC}{\mathcal{C}} \newcommand{\calD}{\mathcal{D}} \newcommand{\calE}{\mathcal{E}} \newcommand{\calF}{\mathcal{F}} \newcommand{\calG}{\mathcal{G}} \newcommand{\calH}{\mathcal{H}} \newcommand{\calI}{\mathcal{I}} \newcommand{\calJ}{\mathcal{J}} \newcommand{\calK}{\mathcal{K}} \newcommand{\calL}{\mathcal{L}} \newcommand{\calM}{\mathcal{M}} \newcommand{\calN}{\mathcal{N}} \newcommand{\calO}{\mathcal{O}} \newcommand{\calP}{\mathcal{P}} \newcommand{\calQ}{\mathcal{Q}} \newcommand{\calR}{\mathcal{R}} \newcommand{\calS}{\mathcal{S}} \newcommand{\calT}{\mathcal{T}} \newcommand{\calU}{\mathcal{U}} \newcommand{\calV}{\mathcal{V}} \newcommand{\calW}{\mathcal{W}} \newcommand{\calX}{\mathcal{X}} \newcommand{\calY}{\mathcal{Y}} \newcommand{\calZ}{\mathcal{Z}} \newcommand{\R}{\mathbb{R}} \newcommand{\C}{\mathbb{C}} \newcommand{\N}{\mathbb{N}} \newcommand{\Z}{\mathbb{Z}} \newcommand{\F}{\mathbb{F}} \newcommand{\Q}{\mathbb{Q}} \DeclareMathOperator*{\argmax}{arg\,max} \DeclareMathOperator*{\argmin}{arg\,min} \newcommand{\nnz}[1]{\mbox{nnz}(#1)} \newcommand{\dotprod}[2]{\langle #1, #2 \rangle} \newcommand{\ignore}[1]{} \let\Pr\relax \DeclareMathOperator*{\Pr}{\mathbf{Pr}} \newcommand{\E}{\mathbb{E}} \DeclareMathOperator*{\Ex}{\mathbf{E}} \DeclareMathOperator*{\Var}{\mathbf{Var}} \DeclareMathOperator*{\Cov}{\mathbf{Cov}} \DeclareMathOperator*{\stddev}{\mathbf{stddev}} \DeclareMathOperator*{\avg}{avg} \DeclareMathOperator{\poly}{poly} \DeclareMathOperator{\polylog}{polylog} \DeclareMathOperator{\size}{size} \DeclareMathOperator{\sgn}{sgn} \DeclareMathOperator{\dist}{dist} \DeclareMathOperator{\vol}{vol} \DeclareMathOperator{\spn}{span} \DeclareMathOperator{\supp}{supp} \DeclareMathOperator{\tr}{tr} \DeclareMathOperator{\Tr}{Tr} \DeclareMathOperator{\codim}{codim} \DeclareMathOperator{\diag}{diag} \newcommand{\PTIME}{\mathsf{P}} \newcommand{\LOGSPACE}{\mathsf{L}} \newcommand{\ZPP}{\mathsf{ZPP}} \newcommand{\RP}{\mathsf{RP}} \newcommand{\BPP}{\mathsf{BPP}} \newcommand{\P}{\mathsf{P}} \newcommand{\NP}{\mathsf{NP}} \newcommand{\TC}{\mathsf{TC}} \newcommand{\AC}{\mathsf{AC}} \newcommand{\SC}{\mathsf{SC}} \newcommand{\SZK}{\mathsf{SZK}} \newcommand{\AM}{\mathsf{AM}} \newcommand{\IP}{\mathsf{IP}} \newcommand{\PSPACE}{\mathsf{PSPACE}} \newcommand{\EXP}{\mathsf{EXP}} \newcommand{\MIP}{\mathsf{MIP}} \newcommand{\NEXP}{\mathsf{NEXP}} \newcommand{\BQP}{\mathsf{BQP}} \newcommand{\distP}{\mathsf{dist\textbf{P}}} \newcommand{\distNP}{\mathsf{dist\textbf{NP}}} \newcommand{\eps}{\epsilon} \newcommand{\lam}{\lambda} \newcommand{\dleta}{\delta} \newcommand{\simga}{\sigma} \newcommand{\vphi}{\varphi} \newcommand{\la}{\langle} \newcommand{\ra}{\rangle} \newcommand{\wt}[1]{\widetilde{#1}} \newcommand{\wh}[1]{\widehat{#1}} \newcommand{\ol}[1]{\overline{#1}} \newcommand{\ul}[1]{\underline{#1}} \newcommand{\ot}{\otimes} \newcommand{\zo}{\{0,1\}} \newcommand{\co}{:} %\newcommand{\co}{\colon} \newcommand{\bdry}{\partial} \newcommand{\grad}{\nabla} \newcommand{\transp}{^\intercal} \newcommand{\inv}{^{-1}} \newcommand{\symmdiff}{\triangle} \newcommand{\symdiff}{\symmdiff} \newcommand{\half}{\tfrac{1}{2}} \newcommand{\bbone}{\mathbbm 1} \newcommand{\Id}{\bbone} \newcommand{\SAT}{\mathsf{SAT}} \newcommand{\bcalG}{\boldsymbol{\calG}} \newcommand{\calbG}{\bcalG} \newcommand{\bcalX}{\boldsymbol{\calX}} \newcommand{\calbX}{\bcalX} \newcommand{\bcalY}{\boldsymbol{\calY}} \newcommand{\calbY}{\bcalY} \newcommand{\bcalZ}{\boldsymbol{\calZ}} \newcommand{\calbZ}{\bcalZ} $$ </div> <hr> <ol> <li> <a href="/summaries/2025-01-06-bge-m3-embedding-multi-lingual-multi-functionality-multi-granularity-text-embeddings-through-self-knowledge-distillation/"> (Jan 6, 2025) BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation </a> </li> <li> <a href="/summaries/2024-11-04-ragas-automated-evaluation-of-retrieval-augmented-generation/"> (Nov 4, 2024) RAGAS: Automated Evaluation of Retrieval Augmented Generation </a> </li> <li> <a href="/summaries/2024-10-12-training-language-models-to-self-correct-via-reinforcement-learning/"> (Oct 12, 2024) Training Language Models to Self-Correct via Reinforcement Learning </a> </li> <li> <a href="/summaries/2024-10-12-easy-to-hard-generalization-scalable-alignment-beyond-human-supervision/"> (Oct 12, 2024) Easy-to-Hard Generalization: Scalable Alignment Beyond Human Supervision </a> </li> <li> <a href="/summaries/2024-10-07-unsupervised-dense-information-retrieval-with-contrastive-learning/"> (Oct 7, 2024) Unsupervised Dense Information Retrieval with Contrastive Learning </a> </li> <li> <a href="/summaries/2024-10-05-generate-rather-than-retrieve-large-language-models-are-strong-context-generators/"> (Oct 5, 2024) Generate rather than Retrieve: Large Language Models are Strong Context Generators </a> </li> <li> <a href="/summaries/2024-10-03-interleaving-retrieval-with-chain-of-thought-reasoning-for-knowledge-intensive-multi-step-questions/"> (Oct 3, 2024) Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions </a> </li> <li> <a href="/summaries/2024-10-03-enhancing-retrieval-augmented-large-language-models-with-iterative-retrieval-generation-synergy/"> (Oct 3, 2024) Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy </a> </li> <li> <a href="/summaries/2024-10-03-asqa-factoid-questions-meet-long-form-answers/"> (Oct 3, 2024) ASQA: Factoid Questions Meet Long-Form Answers </a> </li> <li> <a href="/summaries/2024-10-02-open-source-large-language-models-are-strong-zero-shot-query-likelihood-models-for-document-ranking/"> (Oct 2, 2024) Open-source Large Language Models are Strong Zero-shot Query Likelihood Models for Document Ranking </a> </li> <li> <a href="/summaries/2024-09-29-lost-in-the-middle-how-language-models-use-long-contexts/"> (Sep 29, 2024) Lost in the Middle: How Language Models Use Long Contexts </a> </li> <li> <a href="/summaries/2024-09-29-inpars-data-augmentation-for-information-retrieval-using-large-language-models/"> (Sep 29, 2024) InPars: Data Augmentation for Information Retrieval using Large Language Models </a> </li> <li> <a href="/summaries/2024-09-27-precise-zero-shot-dense-retrieval-without-relevance-labels/"> (Sep 27, 2024) Precise Zero-Shot Dense Retrieval without Relevance Labels (HyDE) </a> </li> <li> <a href="/summaries/2024-09-23-dense-x-retrieval-what-retrieval-granularity-should-we-use/"> (Sep 23, 2024) Dense X Retrieval: What Retrieval Granularity Should We Use? </a> </li> <li> <a href="/summaries/2024-09-22-query-rewriting-for-retrieval-augmented-large-language-models/"> (Sep 22, 2024) Query Rewriting for Retrieval-Augmented Large Language Models </a> </li> <li> <a href="/summaries/2024-09-22-lift-yourself-up-retrieval-augmented-text-generation-with-self-memory/"> (Sep 22, 2024) Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory </a> </li> <li> <a href="/summaries/2024-08-05-reconciling-modern-machine-learning-practice-and-the-bias-variance-trade-off/"> (Aug 5, 2024) Reconciling modern machine learning practice and the bias-variance trade-off </a> </li> <li> <a href="/summaries/2024-08-05-deep-double-descent-where-bigger-models-and-more-data-hurt/"> (Aug 5, 2024) Deep Double Descent: Where Bigger Models and More Data Hurt </a> </li> <li> <a href="/summaries/2024-07-28-domain-adjusted-regression-or-erm-may-already-learn-features-sufficient-for-out-of-distribution-generalization/"> (Jul 28, 2024) Domain-Adjusted Regression or: ERM May Already Learn Features Sufficient for Out-of-Distribution Generalization </a> </li> <li> <a href="/summaries/2024-07-27-editing-a-classifier-by-rewriting-its-prediction-rules/"> (Jul 27, 2024) Editing a classifier by rewriting its prediction rules </a> </li> <li> <a href="/summaries/2024-07-25-distilling-the-knowledge-in-a-neural-network/"> (Jul 25, 2024) Distilling the Knowledge in a Neural Network </a> </li> <li> <a href="/summaries/2024-07-23-constitutional-ai-harmlessness-from-ai-feedback/"> (Jul 23, 2024) Constitutional AI: Harmlessness from AI Feedback </a> </li> <li> <a href="/summaries/2024-07-21-weak-to-strong-generalization-eliciting-strong-capabilities-with-weak-supervision/"> (Jul 21, 2024) Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision </a> </li> <li> <a href="/summaries/2024-07-14-optimizing-instructions-and-demonstrations-for-multi-stage-language-model-programs/"> (Jul 14, 2024) Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs </a> </li> <li> <a href="/summaries/2024-07-13-large-language-models-as-optimizers/"> (Jul 13, 2024) Large Language Models as Optimizers </a> </li> <li> <a href="/summaries/2024-04-26-prefix-tuning-optimizing-continuous-prompts-for-generation/"> (Apr 26, 2024) Prefix-Tuning: Optimizing Continuous Prompts for Generation </a> </li> <li> <a href="/summaries/2024-03-31-lora-low-rank-adaptation-of-large-language-models/"> (Mar 31, 2024) LoRA: Low-Rank Adaptation of Large Language Models </a> </li> <li> <a href="/summaries/2024-03-27-longrope-extending-llm-context-window-beyond-2-million-tokens/"> (Mar 27, 2024) LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens </a> </li> <li> <a href="/summaries/2024-03-23-training-compute-optimal-large-language-models/"> (Mar 23, 2024) Training Compute-Optimal Large Language Models </a> </li> <li> <a href="/summaries/2024-03-23-scaling-laws-for-neural-language-models/"> (Mar 23, 2024) Scaling Laws for Neural Language Models </a> </li> <li> <a href="/summaries/2024-03-15-dspy-compiling-declarative-language-model-calls-into-self-improving-pipelines/"> (Mar 15, 2024) DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines </a> </li> <li> <a href="/summaries/2024-02-22-colbert-efficient-and-effective-passage-search-via-contextualized-late-interaction-over-bert/"> (Feb 22, 2024) ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT </a> </li> <li> <a href="/summaries/2024-02-19-matryoshka-representation-learning/"> (Feb 19, 2024) Matryoshka Representation Learning </a> </li> <li> <a href="/summaries/2023-12-12-large-language-models-for-software-engineering-survey-and-open-problems/"> (Dec 12, 2023) Large Language Models for Software Engineering: Survey and Open Problems </a> </li> <li> <a href="/summaries/2023-11-03-high-resolution-image-synthesis-with-latent-diffusion-models/"> (Nov 3, 2023) High-Resolution Image Synthesis with Latent Diffusion Models </a> </li> <li> <a href="/summaries/2023-10-31-universal-and-transferable-adversarial-attacks-on-aligned-language-models/"> (Oct 31, 2023) Universal and Transferable Adversarial Attacks on Aligned Language Models </a> </li> <li> <a href="/summaries/2023-10-22-zero-shot-image-to-image-translation/"> (Oct 22, 2023) Zero-shot Image-to-Image Translation </a> </li> <li> <a href="/summaries/2023-10-17-instructpix2pix-learning-to-follow-image-editing-instructions/"> (Oct 17, 2023) InstructPix2Pix: Learning to Follow Image Editing Instructions </a> </li> <li> <a href="/summaries/2023-10-15-an-image-is-worth-one-word-personalizing-text-to-image-generation-using-textual-inversion/"> (Oct 15, 2023) An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion </a> </li> <li> <a href="/summaries/2023-10-04-on-the-dangers-of-stochastic-parrots-can-language-models-be-too-big/"> (Oct 4, 2023) On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? </a> </li> <li> <a href="/summaries/2023-09-26-repository-level-prompt-generation-for-large-language-models-of-code/"> (Sep 26, 2023) Repository-Level Prompt Generation for Large Language Models of Code </a> </li> <li> <a href="/summaries/2023-09-24-rethinking-the-role-of-demonstrations-what-makes-in-context-learning-work/"> (Sep 24, 2023) Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? </a> </li> <li> <a href="/summaries/2023-09-23-calibrate-before-use-improving-few-shot-performance-of-language-models/"> (Sep 23, 2023) Calibrate Before Use: Improving Few-Shot Performance of Language Models </a> </li> <li> <a href="/summaries/2023-09-10-understanding-deep-learning-requires-rethinking-generalization/"> (Sep 10, 2023) Understanding Deep Learning Requires Rethinking Generalization </a> </li> <li> <a href="/summaries/2023-09-09-the-implicit-bias-of-gradient-descent-on-separable-data/"> (Sep 9, 2023) The Implicit Bias of Gradient Descent on Separable Data </a> </li> <li> <a href="/summaries/2023-09-07-gradient-descent-provably-optimizes-over-parameterized-neural-networks/"> (Sep 7, 2023) Gradient Descent Provably Optimizes Over-parameterized Neural Networks </a> </li> <li> <a href="/summaries/2023-09-04-loss-landscapes-and-optimization-in-over-parameterized-non-linear-systems-and-neural-networks/"> (Sep 4, 2023) Loss Landscapes and Optimization in Over-Parameterized Non-Linear Systems and Neural Networks </a> </li> <li> <a href="/summaries/2023-08-29-extracting-training-data-from-large-language-models/"> (Aug 29, 2023) Extracting Training Data from Large Language Models </a> </li> <li> <a href="/summaries/2023-08-27-a-watermark-for-large-language-models/"> (Aug 27, 2023) A Watermark for Large Language Models </a> </li> <li> <a href="/summaries/2023-08-25-efficiently-modeling-long-sequences-with-structured-state-spaces/"> (Aug 25, 2023) Efficiently Modeling Long Sequences with Structured State Spaces </a> </li> <li> <a href="/summaries/2023-08-22-exploring-the-limits-of-transfer-learning-with-a-unified-text-to-text-transformer/"> (Aug 22, 2023) Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer </a> </li> <li> <a href="/summaries/2023-08-22-accurate-detection-of-wake-word-start-and-end-using-a-cnn/"> (Aug 22, 2023) Accurate Detection of Wake Word Start and End Using a CNN </a> </li> <li> <a href="/summaries/2023-08-19-transformers-in-speech-processing-a-survey/"> (Aug 19, 2023) Transformers in Speech Processing: A Survey </a> </li> <li> <a href="/summaries/2023-08-11-metagpt-meta-programming-for-multi-agent-collaborative-framework/"> (Aug 11, 2023) MetaGPT: Meta Programming for Multi-Agent Collaborative Framework </a> </li> <li> <a href="/summaries/2023-08-11-improving-language-understanding-by-generative-pre-training/"> (Aug 11, 2023) Improving Language Understanding by Generative Pre-Training (GPT) </a> </li> <li> <a href="/summaries/2023-08-11-generative-agents-interactive-simulacra-of-human-behavior/"> (Aug 11, 2023) Generative Agents: Interactive Simulacra of Human Behavior </a> </li> <li> <a href="/summaries/2023-08-10-simple-synthetic-data-reduces-sycophancy-in-large-language-models/"> (Aug 10, 2023) Simple synthetic data reduces sycophancy in large language models </a> </li> <li> <a href="/summaries/2023-08-10-language-models-are-unsupervised-multitask-learners/"> (Aug 10, 2023) Language Models are Unsupervised Multitask Learners (GPT-2) </a> </li> <li> <a href="/summaries/2023-08-10-dense-passage-retrieval-for-open-domain-question-answering/"> (Aug 10, 2023) Dense Passage Retrieval for Open-Domain Question Answering </a> </li> <li> <a href="/summaries/2023-08-09-bart-denoising-sequence-to-sequence-pre-training-for-natural-language-generation-translation-and-comprehension/"> (Aug 9, 2023) BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension </a> </li> <li> <a href="/summaries/2023-08-06-evaluating-large-language-models-trained-on-code/"> (Aug 6, 2023) Evaluating Large Language Models Trained on Code (Codex) </a> </li> <li> <a href="/summaries/2023-08-05-training-language-models-to-follow-instructions-with-human-feedback/"> (Aug 5, 2023) Training language models to follow instructions with human feedback (InstructGPT) </a> </li> <li> <a href="/summaries/2023-08-03-chain-of-thought-prompting-elicits-reasoning-in-large-language-models/"> (Aug 3, 2023) Chain-of-Thought Prompting Elicits Reasoning in Large Language Models </a> </li> <li> <a href="/summaries/2023-08-03-bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding/"> (Aug 3, 2023) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding </a> </li> <li> <a href="/summaries/2023-08-02-foundations-and-trends-in-multimodal-machine-learning-principles--challenges-and-open-questions/"> (Aug 2, 2023) Foundations and Trends in Multimodal Machine Learning: Principles, Challenges, and Open Questions </a> </li> <li> <a href="/summaries/2023-08-02-deep-contextualized-word-representations/"> (Aug 2, 2023) Deep contextualized word representations (ELMo) </a> </li> </ol> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2025 Fan Pu Zeng. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: January 12, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script src="/assets/js/tooltips-setup.js?53023e960fbc64cccb90d32e9363de2b"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-S3VHEYH05S"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-S3VHEYH05S');
  </script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>