<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Distilling the Knowledge in a Neural Network | Fan Pu  Zeng</title>
    <meta name="author" content="Fan Pu  Zeng">
    <meta name="description" content="Homepage
">
    <meta name="keywords" content="fanpu, fan pu, fanpu zeng, fan pu zeng, zengfanpu, fanpuzeng, fzeng, CMU, cmu, carnegie mellon, cmu courses, school of computer science, scs, machine learning, computer science, ml, theory, courses, course reviews, CS, Jane Street">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/favicon_new.ico">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://fanpu.io/summaries/2024-07-25-distilling-the-knowledge-in-a-neural-network/">
    <!-- Dark Mode -->
    

    <!-- Twitter cards -->
    <meta name="twitter:site" content="@FanPu_Zeng">
    <meta name="twitter:creator" content="@">
    <meta name="og:title" content="Distilling the Knowledge in a Neural Network">

    
    <meta name="twitter:card" content="summary">
    <meta name="og:image" content="">
    

    
    <meta name="og:description" content="Homepage
">
    

    <!-- end of Twitter cards -->
  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Fan PuÂ </span>Zeng</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">Blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/courses/">CMU Course Reviews</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cmu-online/">CMU Online</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/summaries/">ML Paper Summaries</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">Repositories</a>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- _layouts/summary.html -->



<div style="display:none">
    $$
    \newcommand{\bone}{\mathbf{1}}
    \newcommand{\bbeta}{\mathbf{\beta}}
    \newcommand{\bdelta}{\mathbf{\delta}}
    \newcommand{\bepsilon}{\mathbf{\epsilon}}
    \newcommand{\blambda}{\mathbf{\lambda}}
    \newcommand{\bomega}{\mathbf{\omega}}
    \newcommand{\bpi}{\mathbf{\pi}}
    \newcommand{\bphi}{\mathbf{\phi}}
    \newcommand{\bvphi}{\mathbf{\varphi}}
    \newcommand{\bpsi}{\mathbf{\psi}}
    \newcommand{\bsigma}{\mathbf{\sigma}}
    \newcommand{\btheta}{\mathbf{\theta}}
    \newcommand{\btau}{\mathbf{\tau}}
    \newcommand{\ba}{\mathbf{a}}
    \newcommand{\bb}{\mathbf{b}}
    \newcommand{\bc}{\mathbf{c}}
    \newcommand{\bd}{\mathbf{d}}
    \newcommand{\be}{\mathbf{e}}
    \newcommand{\boldf}{\mathbf{f}}
    \newcommand{\bg}{\mathbf{g}}
    \newcommand{\bh}{\mathbf{h}}
    \newcommand{\bi}{\mathbf{i}}
    \newcommand{\bj}{\mathbf{j}}
    \newcommand{\bk}{\mathbf{k}}
    \newcommand{\bell}{\mathbf{\ell}}
    \newcommand{\bm}{\mathbf{m}}
    \newcommand{\bn}{\mathbf{n}}
    \newcommand{\bo}{\mathbf{o}}
    \newcommand{\bp}{\mathbf{p}}
    \newcommand{\bq}{\mathbf{q}}
    \newcommand{\br}{\mathbf{r}}
    \newcommand{\bs}{\mathbf{s}}
    \newcommand{\bt}{\mathbf{t}}
    \newcommand{\bu}{\mathbf{u}}
    \newcommand{\bv}{\mathbf{v}}
    \newcommand{\bw}{\mathbf{w}}
    \newcommand{\bx}{\mathbf{x}}
    \newcommand{\by}{\mathbf{y}}
    \newcommand{\bz}{\mathbf{z}}
    \newcommand{\bA}{\mathbf{A}}
    \newcommand{\bB}{\mathbf{B}}
    \newcommand{\bC}{\mathbf{C}}
    \newcommand{\bD}{\mathbf{D}}
    \newcommand{\bE}{\mathbf{E}}
    \newcommand{\bF}{\mathbf{F}}
    \newcommand{\bG}{\mathbf{G}}
    \newcommand{\bH}{\mathbf{H}}
    \newcommand{\bI}{\mathbf{I}}
    \newcommand{\bJ}{\mathbf{J}}
    \newcommand{\bK}{\mathbf{K}}
    \newcommand{\bL}{\mathbf{L}}
    \newcommand{\bM}{\mathbf{M}}
    \newcommand{\bN}{\mathbf{N}}
    \newcommand{\bP}{\mathbf{P}}
    \newcommand{\bQ}{\mathbf{Q}}
    \newcommand{\bR}{\mathbf{R}}
    \newcommand{\bS}{\mathbf{S}}
    \newcommand{\bT}{\mathbf{T}}
    \newcommand{\bU}{\mathbf{U}}
    \newcommand{\bV}{\mathbf{V}}
    \newcommand{\bW}{\mathbf{W}}
    \newcommand{\bX}{\mathbf{X}}
    \newcommand{\bY}{\mathbf{Y}}
    \newcommand{\bZ}{\mathbf{Z}}

    \newcommand{\bsa}{\boldsymbol{a}}
    \newcommand{\bsb}{\boldsymbol{b}}
    \newcommand{\bsc}{\boldsymbol{c}}
    \newcommand{\bsd}{\boldsymbol{d}}
    \newcommand{\bse}{\boldsymbol{e}}
    \newcommand{\bsoldf}{\boldsymbol{f}}
    \newcommand{\bsg}{\boldsymbol{g}}
    \newcommand{\bsh}{\boldsymbol{h}}
    \newcommand{\bsi}{\boldsymbol{i}}
    \newcommand{\bsj}{\boldsymbol{j}}
    \newcommand{\bsk}{\boldsymbol{k}}
    \newcommand{\bsell}{\boldsymbol{\ell}}
    \newcommand{\bsm}{\boldsymbol{m}}
    \newcommand{\bsn}{\boldsymbol{n}}
    \newcommand{\bso}{\boldsymbol{o}}
    \newcommand{\bsp}{\boldsymbol{p}}
    \newcommand{\bsq}{\boldsymbol{q}}
    \newcommand{\bsr}{\boldsymbol{r}}
    \newcommand{\bss}{\boldsymbol{s}}
    \newcommand{\bst}{\boldsymbol{t}}
    \newcommand{\bsu}{\boldsymbol{u}}
    \newcommand{\bsv}{\boldsymbol{v}}
    \newcommand{\bsw}{\boldsymbol{w}}
    \newcommand{\bsx}{\boldsymbol{x}}
    \newcommand{\bsy}{\boldsymbol{y}}
    \newcommand{\bsz}{\boldsymbol{z}}
    \newcommand{\bsA}{\boldsymbol{A}}
    \newcommand{\bsB}{\boldsymbol{B}}
    \newcommand{\bsC}{\boldsymbol{C}}
    \newcommand{\bsD}{\boldsymbol{D}}
    \newcommand{\bsE}{\boldsymbol{E}}
    \newcommand{\bsF}{\boldsymbol{F}}
    \newcommand{\bsG}{\boldsymbol{G}}
    \newcommand{\bsH}{\boldsymbol{H}}
    \newcommand{\bsI}{\boldsymbol{I}}
    \newcommand{\bsJ}{\boldsymbol{J}}
    \newcommand{\bsK}{\boldsymbol{K}}
    \newcommand{\bsL}{\boldsymbol{L}}
    \newcommand{\bsM}{\boldsymbol{M}}
    \newcommand{\bsN}{\boldsymbol{N}}
    \newcommand{\bsP}{\boldsymbol{P}}
    \newcommand{\bsQ}{\boldsymbol{Q}}
    \newcommand{\bsR}{\boldsymbol{R}}
    \newcommand{\bsS}{\boldsymbol{S}}
    \newcommand{\bsT}{\boldsymbol{T}}
    \newcommand{\bsU}{\boldsymbol{U}}
    \newcommand{\bsV}{\boldsymbol{V}}
    \newcommand{\bsW}{\boldsymbol{W}}
    \newcommand{\bsX}{\boldsymbol{X}}
    \newcommand{\bsY}{\boldsymbol{Y}}
    \newcommand{\bsZ}{\boldsymbol{Z}}

    \newcommand{\calA}{\mathcal{A}}
    \newcommand{\calB}{\mathcal{B}}
    \newcommand{\calC}{\mathcal{C}}
    \newcommand{\calD}{\mathcal{D}}
    \newcommand{\calE}{\mathcal{E}}
    \newcommand{\calF}{\mathcal{F}}
    \newcommand{\calG}{\mathcal{G}}
    \newcommand{\calH}{\mathcal{H}}
    \newcommand{\calI}{\mathcal{I}}
    \newcommand{\calJ}{\mathcal{J}}
    \newcommand{\calK}{\mathcal{K}}
    \newcommand{\calL}{\mathcal{L}}
    \newcommand{\calM}{\mathcal{M}}
    \newcommand{\calN}{\mathcal{N}}
    \newcommand{\calO}{\mathcal{O}}
    \newcommand{\calP}{\mathcal{P}}
    \newcommand{\calQ}{\mathcal{Q}}
    \newcommand{\calR}{\mathcal{R}}
    \newcommand{\calS}{\mathcal{S}}
    \newcommand{\calT}{\mathcal{T}}
    \newcommand{\calU}{\mathcal{U}}
    \newcommand{\calV}{\mathcal{V}}
    \newcommand{\calW}{\mathcal{W}}
    \newcommand{\calX}{\mathcal{X}}
    \newcommand{\calY}{\mathcal{Y}}
    \newcommand{\calZ}{\mathcal{Z}}

    \newcommand{\R}{\mathbb{R}}
    \newcommand{\C}{\mathbb{C}}
    \newcommand{\N}{\mathbb{N}}
    \newcommand{\Z}{\mathbb{Z}}
    \newcommand{\F}{\mathbb{F}}
    \newcommand{\Q}{\mathbb{Q}}

    \DeclareMathOperator*{\argmax}{arg\,max}
    \DeclareMathOperator*{\argmin}{arg\,min}
    \newcommand{\nnz}[1]{\mbox{nnz}(#1)}
    \newcommand{\dotprod}[2]{\langle #1, #2 \rangle}

    \newcommand{\ignore}[1]{}

    \let\Pr\relax
    \DeclareMathOperator*{\Pr}{\mathbf{Pr}}
    \newcommand{\E}{\mathbb{E}}
    \DeclareMathOperator*{\Ex}{\mathbf{E}}
    \DeclareMathOperator*{\Var}{\mathbf{Var}}
    \DeclareMathOperator*{\Cov}{\mathbf{Cov}}
    \DeclareMathOperator*{\stddev}{\mathbf{stddev}}
    \DeclareMathOperator*{\avg}{avg}

    \DeclareMathOperator{\poly}{poly}
    \DeclareMathOperator{\polylog}{polylog}
    \DeclareMathOperator{\size}{size}
    \DeclareMathOperator{\sgn}{sgn}
    \DeclareMathOperator{\dist}{dist}
    \DeclareMathOperator{\vol}{vol}
    \DeclareMathOperator{\spn}{span}
    \DeclareMathOperator{\supp}{supp}
    \DeclareMathOperator{\tr}{tr}
    \DeclareMathOperator{\Tr}{Tr}
    \DeclareMathOperator{\codim}{codim}
    \DeclareMathOperator{\diag}{diag}

    \newcommand{\PTIME}{\mathsf{P}}
    \newcommand{\LOGSPACE}{\mathsf{L}}
    \newcommand{\ZPP}{\mathsf{ZPP}}
    \newcommand{\RP}{\mathsf{RP}}
    \newcommand{\BPP}{\mathsf{BPP}}
    \newcommand{\P}{\mathsf{P}}
    \newcommand{\NP}{\mathsf{NP}}
    \newcommand{\TC}{\mathsf{TC}}
    \newcommand{\AC}{\mathsf{AC}}
    \newcommand{\SC}{\mathsf{SC}}
    \newcommand{\SZK}{\mathsf{SZK}}
    \newcommand{\AM}{\mathsf{AM}}
    \newcommand{\IP}{\mathsf{IP}}
    \newcommand{\PSPACE}{\mathsf{PSPACE}}
    \newcommand{\EXP}{\mathsf{EXP}}
    \newcommand{\MIP}{\mathsf{MIP}}
    \newcommand{\NEXP}{\mathsf{NEXP}}
    \newcommand{\BQP}{\mathsf{BQP}}
    \newcommand{\distP}{\mathsf{dist\textbf{P}}}
    \newcommand{\distNP}{\mathsf{dist\textbf{NP}}}

    \newcommand{\eps}{\epsilon}
    \newcommand{\lam}{\lambda}
    \newcommand{\dleta}{\delta}
    \newcommand{\simga}{\sigma}
    \newcommand{\vphi}{\varphi}
    \newcommand{\la}{\langle}
    \newcommand{\ra}{\rangle}
    \newcommand{\wt}[1]{\widetilde{#1}}
    \newcommand{\wh}[1]{\widehat{#1}}
    \newcommand{\ol}[1]{\overline{#1}}
    \newcommand{\ul}[1]{\underline{#1}}
    \newcommand{\ot}{\otimes}
    \newcommand{\zo}{\{0,1\}}
    \newcommand{\co}{:} %\newcommand{\co}{\colon}
    \newcommand{\bdry}{\partial}
    \newcommand{\grad}{\nabla}
    \newcommand{\transp}{^\intercal}
    \newcommand{\inv}{^{-1}}
    \newcommand{\symmdiff}{\triangle} \newcommand{\symdiff}{\symmdiff}
    \newcommand{\half}{\tfrac{1}{2}}
    \newcommand{\bbone}{\mathbbm 1}
    \newcommand{\Id}{\bbone}

    \newcommand{\SAT}{\mathsf{SAT}}

    \newcommand{\bcalG}{\boldsymbol{\calG}}
    \newcommand{\calbG}{\bcalG}
    \newcommand{\bcalX}{\boldsymbol{\calX}} \newcommand{\calbX}{\bcalX}
    \newcommand{\bcalY}{\boldsymbol{\calY}} \newcommand{\calbY}{\bcalY}
    \newcommand{\bcalZ}{\boldsymbol{\calZ}} \newcommand{\calbZ}{\bcalZ}
    $$
</div>

<!-- hack to inherit CSS styles to suppress list counts -->
<div class="publications">
    <ol class="bibliography"><li>
<!-- _layouts/custom_bib.html -->
      <div class="row no-count">
        <!-- Entry bib key -->
        <div id="1503.02531v1" class="col-sm-12">
        <!-- Title -->
        <div class="title"><h2>
            <a href="http://arxiv.org/abs/1503.02531v1" rel="external nofollow noopener" target="_blank">
                Distilling the Knowledge in a Neural Network
            </a>
          </h2></div>
        <!-- Author -->
        <div class="author">
        

        Geoffrey Hinton,Â Oriol Vinyals,Â andÂ Jeff Dean</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em></em> Mar 2015
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
          <!--
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
            <a href="http://arxiv.org/abs/1503.02531v1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            
            <a href="https://arxiv.org/pdf/1503.02531v1.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
          <!-- -->
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-arxiv-id="1503.02531"></span>
          </div>

          <!-- Hidden abstract block -->
          <h3>Paper Abstract</h3>
          <div class="abstract">
            <p>A very simple way to improve the performance of almost any machine learning
algorithm is to train many different models on the same data and then to
average their predictions. Unfortunately, making predictions using a whole
ensemble of models is cumbersome and may be too computationally expensive to
allow deployment to a large number of users, especially if the individual
models are large neural nets. Caruana and his collaborators have shown that it
is possible to compress the knowledge in an ensemble into a single model which
is much easier to deploy and we develop this approach further using a different
compression technique. We achieve some surprising results on MNIST and we show
that we can significantly improve the acoustic model of a heavily used
commercial system by distilling the knowledge in an ensemble of models into a
single model. We also introduce a new type of ensemble composed of one or more
full models and many specialist models which learn to distinguish fine-grained
classes that the full models confuse. Unlike a mixture of experts, these
specialist models can be trained rapidly and in parallel.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">1503.02531v1</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Distilling the Knowledge in a Neural Network}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{1503.02531v1}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{stat.ML}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">eprintnover</span> <span class="p">=</span> <span class="s">{1503.02531}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>
</div>

<div class="post">
  <article class="post-content">
    
    <div id="markdown-content">
      <h3 id="three-important-things">Three Important Things</h3>

<h4 id="1-motivation">1. Motivation</h4>

<p>The paper opens with a really interesting analogy: insects begin with a larval
form optimized for extracting energy and nutrients from the environment, before 
metamorphosing into a completely adult form optimized for traveling and
reproduction.</p>

<p>In a similar vein, for machine learning models we have access to plentiful compute and time during the training, but become constrained by different
considerations like latency during inference. 
Given the different requirements and affordances of both phases, why should we
expect to simply use the same model for both of them?</p>

<p>To address this, the paper introduces the idea of distillation, to transfer
the knowledge of a very large/cumbersome model (possibly an ensemble of models)
to a smaller one.</p>

<h4 id="2-distillation">2. Distillation</h4>

<p>There are several ways to approach distillation.</p>

<ol>
  <li>A natural first approach would be to make the student model learn to predict
the same class probabilities as the teacher model. These are known as âsoft targetsâ (in contrast, âhard targetsâ are the ground-truth labels). Soft targets are âan effective way of communicating the regularities discovered by a model
trained on all of the data to another modelâ.</li>
  <li>In practice, the correct label usually dominates the others by
orders of magnitude. But a lot of information about the learned function can be
gleaned from the ratios of the other labels, which can provide information on
how one label might be confused for another and allow the model to draw more
conclusions.</li>
</ol>

<p>If we just use cross-entropy loss, these vital set of information will be lost
as their relative values are tiny relative to the most confident prediction and
donât contribute much to the loss.</p>

<p>To address this, the authors added a temperature parameter before the softmax,
and increased the temperature to a suitably high level until the targets are âsoftâ enough. The same temperature is used when training the small model.
The temperature is reset to 1 afterwards at test time.</p>

<p>Note that changing temperature also requires the gradient update of the 
cross-entropy loss of the softmax predictions to be scaled appropriately by
\((1/T^2)\) (via the chain rule).</p>

<p>The paper shows that the gradient of the cross-entropy loss
is approximately \(\frac{1}{NT^2}(z_i - v_i)\) using a first-order Taylor
approximation, which holds when temperature is high. By integrating this,
the loss is proportionate to \(\frac{(z_i - v_i)^2}{2}\), showing that 
the loss function is essentially matching the logits.</p>

<h4 id="3-ensembles-of-specialists">3. Ensembles of Specialists</h4>

<p>One way they applied the idea of matching soft targets with temperature is as follows.</p>

<p>Train time:</p>
<ol>
  <li>Train a big generalist model the normal way</li>
  <li>Use the generalist model to identify clusters of labels by using the covariance matrix of its predictions</li>
  <li>For each of these clusters, train a specialist model. The specialist model
only learns to classify the things in its cluster, and all other labels
are lumped into a âdustbinâ class</li>
</ol>

<p>Test time:</p>
<ol>
  <li>Run generalist model on test case sample. Take the top \(n\) most probable
classes, call this set \(k\)</li>
  <li>Take all the specialist classes that can handle anything in \(k\).
So each specialist class outputs its own logits. The goal is to optimize for the
logits \(\mathbf{q}\) that minimizes over the KL between the logits of the generalist model
and \(\mathbf{q}\)
, as well as the logits between each of the specialist classes and \(\mathbf{q}\), i.e:
 \(K L\left(\mathbf{p}^g, \mathbf{q}\right)+\sum_{m \in A_k} K L\left(\mathbf{p}^m, \mathbf{q}\right)\)</li>
  <li>Take the most probable class in \(\mathbf{q}\) as the prediction</li>
</ol>

<h3 id="most-glaring-deficiency">Most Glaring Deficiency</h3>

<p>The paper did not (and acknowledged it did not) report on the results of
actually distilling the outputs of the âcumbersomeâ ensemble of specialist models back into a small model, which felt like one of the main selling points
that they were making.</p>

<h3 id="conclusions-for-future-work">Conclusions for Future Work</h3>

<p>Distillation is now a pretty popular way to transfer the knowledge of larger/more cumbersome models into smaller ones, allowing for wins in latency and cost
during live inference.</p>

    </div>
  </article>

  <p class="post-meta">Written July 25, 2024</p>
<div id="giscus_thread" style="max-width: 800px; margin: 0 auto;">
  <script>
    let giscusTheme = localStorage.getItem("theme");
    let giscusAttributes = {
        "src": "https://giscus.app/client.js",
        "data-repo": "fanpu/website",
        "data-repo-id": "R_kgDOIpOodA",
        "data-category": "General",
        "data-category-id": "DIC_kwDOIpOodM4CTKDC",
        "data-mapping": "title",
        "data-strict": "1",
        "data-reactions-enabled": "1",
        "data-emit-metadata": "0",
        "data-input-position": "top",
        "data-theme": giscusTheme,
        "data-lang": "en",
        "crossorigin": "anonymous",
        "async": "",
    };


    let giscusScript = document.createElement("script");
    Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
    document.getElementById("giscus_thread").appendChild(giscusScript);
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a>
</noscript>
</div>
</div>


      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        Â© Copyright 2024 Fan Pu  Zeng. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme.
Last updated: October 08, 2024.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Enable Tooltips -->
  <script type="text/javascript">
  $(function () {$('[data-toggle="tooltip"]').tooltip()})
  </script>
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      loader: {load: ['[tex]/mathtools']},
      tex: {
        packages: {'[+]': ['mathtools', 'ams']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          addMenu: []
        }
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
