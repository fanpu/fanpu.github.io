---
layout: summary
title: "Efficiently Modeling Long Sequences with Structured State Spaces"
giscus_comments: true
bib_id: 2111.00396v3
---

### Three Important Things

#### 1. Structured State Space sequence model (S4)
The paper investigates improving upon the state-of-the-art performance on
sequential tasks that involve very long sequences. The current state-of-the-art
is based on Transformers models, but these suffer from severe computational
limitations such as a quadratic cost on computing cross-attention based on
sequence length.

One possible approach to doing this is known as the State Space Model (SSM), parameterized
by matrices

To this end, they introduced the Structured State Space sequence model (S4)




#### 2. Bar

#### 3. Baz

### Most Glaring Deficiency

### Conclusions for Future Work
